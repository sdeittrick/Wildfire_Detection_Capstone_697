{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "%load_ext tensorboard\n",
    "\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "\n",
    "import importlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in test_train_split custom function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import train\n",
    "importlib.reload(train)\n",
    "from train import test_train_split, train_test_model, run\n",
    "import charts\n",
    "importlib.reload(charts)\n",
    "from charts import line_chart, plot_confusion_matrix_2, plot_roc, plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From pickeled files\n",
    "For loading the images for the model simply run the the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load image files from pickles both train and test\n",
    "dir = os.getcwd()\n",
    "\n",
    "with open('{}/artifacts/{}'.format(dir, 'train_images_pkl.pkl'), 'rb') as pickle_file: #train_images_pkl_all.pkl\n",
    "    train_data = pickle.load(pickle_file)\n",
    "\n",
    "with open('{}/artifacts/{}'.format(dir, 'test_images_pkl_w_drone.pkl'), 'rb') as pickle_file: #test_images_pkl_even_ratio.pkl\n",
    "    test_data = pickle.load(pickle_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the images we can split the training set in to training, development and test images. We have imported a function that we have created for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1516, 100, 177, 3)\n",
      "(1516, 100, 177, 3)\n",
      "(100, 177, 3)\n",
      "(1516, 100, 177, 3)\n",
      "(1516, 1)\n"
     ]
    }
   ],
   "source": [
    "#splitting in to test train split for the training data\n",
    "train_images, train_labels, dev_images, dev_labels, test_images, test_labels = test_train_split(train_data)\n",
    "print(np.array(train_images).shape)\n",
    "\n",
    "#normalize the images\n",
    "train_images, dev_images, test_images = np.array(train_images) / 255.0, \\\n",
    "                                        np.array(dev_images) / 255.0, \\\n",
    "                                        np.array(test_images) / 255.0\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "train_images = tf.convert_to_tensor(train_images, dtype=tf.float32)\n",
    "train_labels = tf.convert_to_tensor(train_labels, dtype=tf.float32)\n",
    "test_images = tf.convert_to_tensor(test_images, dtype=tf.float32)\n",
    "test_labels = tf.convert_to_tensor(test_labels, dtype=tf.float32)\n",
    "\n",
    "input_shape = train_images.shape[1:]\n",
    "print(input_shape)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 100, 177, 3)\n",
      "(71, 100, 177, 3)\n",
      "(100, 177, 3)\n"
     ]
    }
   ],
   "source": [
    "hold_out_images, hold_out_labels = zip(*test_data)\n",
    "\n",
    "#normalize the images\n",
    "hold_out_images = np.array(hold_out_images) / 255.0\n",
    "hold_out_images = tf.convert_to_tensor(hold_out_images , dtype=tf.float32)\n",
    "input_shape = hold_out_images.shape[1:]\n",
    "\n",
    "print(hold_out_images.shape)\n",
    "print(hold_out_images.shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "#! rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'Nadam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 24s 467ms/step - loss: 0.8800 - accuracy: 0.5851 - f1_m: 0.6586 - precision_m: 0.5688 - recall_m: 0.8046 - val_loss: 0.5919 - val_accuracy: 0.6684 - val_f1_m: 0.6991 - val_precision_m: 0.5635 - val_recall_m: 0.9275\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 23s 470ms/step - loss: 0.6562 - accuracy: 0.6774 - f1_m: 0.6985 - precision_m: 0.5803 - recall_m: 0.9044 - val_loss: 0.4521 - val_accuracy: 0.7526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 22s 462ms/step - loss: 0.5016 - accuracy: 0.7672 - f1_m: 0.7066 - precision_m: 0.5674 - recall_m: 0.9495 - val_loss: 0.4188 - val_accuracy: 0.7947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.3984 - accuracy: 0.8331 - f1_m: 0.7150 - precision_m: 0.5714 - recall_m: 0.9651 - val_loss: 0.2932 - val_accuracy: 0.8737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.3492 - accuracy: 0.8542 - f1_m: 0.7184 - precision_m: 0.5718 - recall_m: 0.9825 - val_loss: 0.1752 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 22s 459ms/step - loss: 0.2711 - accuracy: 0.8879 - f1_m: 0.7213 - precision_m: 0.5715 - recall_m: 0.9879 - val_loss: 0.3085 - val_accuracy: 0.8632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 22s 452ms/step - loss: 0.2135 - accuracy: 0.9096 - f1_m: 0.7177 - precision_m: 0.5689 - recall_m: 0.9857 - val_loss: 0.1466 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.1979 - accuracy: 0.9222 - f1_m: 0.7137 - precision_m: 0.5660 - recall_m: 0.9793 - val_loss: 0.1102 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1765 - accuracy: 0.9347 - f1_m: 0.7205 - precision_m: 0.5713 - recall_m: 0.9892 - val_loss: 0.0694 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1900 - accuracy: 0.9274 - f1_m: 0.7185 - precision_m: 0.5678 - recall_m: 0.9900 - val_loss: 0.1180 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1391 - accuracy: 0.9551 - f1_m: 0.7204 - precision_m: 0.5693 - recall_m: 0.9922 - val_loss: 0.0595 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1183 - accuracy: 0.9545 - f1_m: 0.7175 - precision_m: 0.5671 - recall_m: 0.9916 - val_loss: 0.0864 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0789 - accuracy: 0.9697 - f1_m: 0.7192 - precision_m: 0.5676 - recall_m: 0.9955 - val_loss: 0.7976 - val_accuracy: 0.8316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1289 - accuracy: 0.9571 - f1_m: 0.7170 - precision_m: 0.5667 - recall_m: 0.9934 - val_loss: 0.2037 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1733 - accuracy: 0.9466 - f1_m: 0.7169 - precision_m: 0.5679 - recall_m: 0.9875 - val_loss: 0.0592 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0945 - accuracy: 0.9657 - f1_m: 0.7234 - precision_m: 0.5744 - recall_m: 0.9954 - val_loss: 0.0565 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0788 - accuracy: 0.9769 - f1_m: 0.7217 - precision_m: 0.5711 - recall_m: 0.9933 - val_loss: 0.0338 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0590 - accuracy: 0.9782 - f1_m: 0.7173 - precision_m: 0.5672 - recall_m: 0.9977 - val_loss: 0.0402 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0534 - accuracy: 0.9835 - f1_m: 0.7238 - precision_m: 0.5723 - recall_m: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0744 - accuracy: 0.9736 - f1_m: 0.7201 - precision_m: 0.5696 - recall_m: 0.9975 - val_loss: 0.0457 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0483 - accuracy: 0.9848 - f1_m: 0.7207 - precision_m: 0.5697 - recall_m: 0.9967 - val_loss: 1.3708 - val_accuracy: 0.7895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1050 - accuracy: 0.9697 - f1_m: 0.7252 - precision_m: 0.5746 - recall_m: 0.9970 - val_loss: 0.0388 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0423 - accuracy: 0.9908 - f1_m: 0.7200 - precision_m: 0.5676 - recall_m: 0.9955 - val_loss: 0.1122 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0595 - accuracy: 0.9802 - f1_m: 0.7206 - precision_m: 0.5687 - recall_m: 1.0000 - val_loss: 0.6261 - val_accuracy: 0.8632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0552 - accuracy: 0.9828 - f1_m: 0.7181 - precision_m: 0.5670 - recall_m: 0.9949 - val_loss: 0.0864 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.0461 - accuracy: 0.9848 - f1_m: 0.7209 - precision_m: 0.5691 - recall_m: 0.9992 - val_loss: 0.0541 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0710 - accuracy: 0.9749 - f1_m: 0.7252 - precision_m: 0.5733 - recall_m: 0.9990 - val_loss: 0.0102 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0438 - accuracy: 0.9861 - f1_m: 0.7176 - precision_m: 0.5665 - recall_m: 0.9943 - val_loss: 0.1269 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0431 - accuracy: 0.9868 - f1_m: 0.7243 - precision_m: 0.5753 - recall_m: 0.9979 - val_loss: 0.0446 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0514 - accuracy: 0.9802 - f1_m: 0.7233 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0355 - accuracy: 0.9848 - f1_m: 0.7211 - precision_m: 0.5693 - recall_m: 0.9966 - val_loss: 0.0476 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0386 - accuracy: 0.9861 - f1_m: 0.7183 - precision_m: 0.5681 - recall_m: 0.9975 - val_loss: 0.0800 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0891 - accuracy: 0.9749 - f1_m: 0.7200 - precision_m: 0.5682 - recall_m: 0.9942 - val_loss: 0.0401 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0956 - accuracy: 0.9743 - f1_m: 0.7208 - precision_m: 0.5690 - recall_m: 0.9945 - val_loss: 0.0163 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0394 - accuracy: 0.9875 - f1_m: 0.7171 - precision_m: 0.5660 - recall_m: 0.9964 - val_loss: 0.0222 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0415 - accuracy: 0.9881 - f1_m: 0.7222 - precision_m: 0.5698 - recall_m: 0.9976 - val_loss: 0.0136 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0422 - accuracy: 0.9861 - f1_m: 0.7195 - precision_m: 0.5698 - recall_m: 0.9955 - val_loss: 0.0302 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0342 - accuracy: 0.9921 - f1_m: 0.7218 - precision_m: 0.5700 - recall_m: 0.9976 - val_loss: 0.0266 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0609 - accuracy: 0.9809 - f1_m: 0.7167 - precision_m: 0.5662 - recall_m: 0.9986 - val_loss: 0.0146 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 22s 447ms/step - loss: 0.0380 - accuracy: 0.9881 - f1_m: 0.7189 - precision_m: 0.5671 - recall_m: 0.9952 - val_loss: 0.0346 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0333 - accuracy: 0.9894 - f1_m: 0.7240 - precision_m: 0.5745 - recall_m: 0.9970 - val_loss: 0.0779 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0666 - accuracy: 0.9828 - f1_m: 0.7171 - precision_m: 0.5650 - recall_m: 0.9980 - val_loss: 0.0423 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0414 - accuracy: 0.9848 - f1_m: 0.7235 - precision_m: 0.5731 - recall_m: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0523 - accuracy: 0.9848 - f1_m: 0.7193 - precision_m: 0.5678 - recall_m: 0.9958 - val_loss: 0.0303 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0313 - accuracy: 0.9927 - f1_m: 0.7182 - precision_m: 0.5670 - recall_m: 0.9972 - val_loss: 0.0074 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0310 - accuracy: 0.9901 - f1_m: 0.7188 - precision_m: 0.5664 - recall_m: 0.9979 - val_loss: 0.0124 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0435 - accuracy: 0.9875 - f1_m: 0.7260 - precision_m: 0.5742 - recall_m: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0175 - accuracy: 0.9954 - f1_m: 0.7224 - precision_m: 0.5718 - recall_m: 0.9991 - val_loss: 0.0191 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.0494 - accuracy: 0.9842 - f1_m: 0.7207 - precision_m: 0.5688 - recall_m: 0.9975 - val_loss: 0.0146 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0178 - accuracy: 0.9941 - f1_m: 0.7188 - precision_m: 0.5673 - recall_m: 0.9988 - val_loss: 0.0569 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 80ms/step - loss: 0.0569 - accuracy: 0.9789 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 21s 423ms/step - loss: 1.1828 - accuracy: 0.5303 - f1_m: 0.5802 - precision_m: 0.5528 - recall_m: 0.6628 - val_loss: 0.5513 - val_accuracy: 0.7158 - val_f1_m: 0.7320 - val_precision_m: 0.5786 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.8422 - accuracy: 0.6069 - f1_m: 0.6707 - precision_m: 0.5736 - recall_m: 0.8252 - val_loss: 0.4971 - val_accuracy: 0.7526 - val_f1_m: 0.7144 - val_precision_m: 0.5664 - val_recall_m: 0.9735\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.6654 - accuracy: 0.7170 - f1_m: 0.6978 - precision_m: 0.5848 - recall_m: 0.8794 - val_loss: 1.6919 - val_accuracy: 0.6053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.5653 - accuracy: 0.7698 - f1_m: 0.7125 - precision_m: 0.5843 - recall_m: 0.9275 - val_loss: 0.4177 - val_accuracy: 0.8105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.4416 - accuracy: 0.8146 - f1_m: 0.7091 - precision_m: 0.5751 - recall_m: 0.9362 - val_loss: 0.2419 - val_accuracy: 0.8737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.3272 - accuracy: 0.8766 - f1_m: 0.7111 - precision_m: 0.5689 - recall_m: 0.9656 - val_loss: 1.5756 - val_accuracy: 0.6947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.3139 - accuracy: 0.8852 - f1_m: 0.7125 - precision_m: 0.5682 - recall_m: 0.9726 - val_loss: 0.2836 - val_accuracy: 0.8579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.2450 - accuracy: 0.9057 - f1_m: 0.7184 - precision_m: 0.5703 - recall_m: 0.9820 - val_loss: 0.1340 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1979 - accuracy: 0.9235 - f1_m: 0.7177 - precision_m: 0.5691 - recall_m: 0.9875 - val_loss: 0.1997 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 20s 412ms/step - loss: 0.1985 - accuracy: 0.9222 - f1_m: 0.7197 - precision_m: 0.5687 - recall_m: 0.9909 - val_loss: 0.0719 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.1882 - accuracy: 0.9354 - f1_m: 0.7156 - precision_m: 0.5665 - recall_m: 0.9841 - val_loss: 0.1894 - val_accuracy: 0.9158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.2275 - accuracy: 0.9499 - f1_m: 0.7106 - precision_m: 0.5641 - recall_m: 0.9768 - val_loss: 0.1246 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.1785 - accuracy: 0.9538 - f1_m: 0.7176 - precision_m: 0.5681 - recall_m: 0.9879 - val_loss: 0.1760 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.1504 - accuracy: 0.9466 - f1_m: 0.7175 - precision_m: 0.5680 - recall_m: 0.9827 - val_loss: 0.0678 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1444 - accuracy: 0.9538 - f1_m: 0.7153 - precision_m: 0.5648 - recall_m: 0.9853 - val_loss: 0.0975 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.1041 - accuracy: 0.9611 - f1_m: 0.7152 - precision_m: 0.5676 - recall_m: 0.9866 - val_loss: 0.0656 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 20s 413ms/step - loss: 0.2455 - accuracy: 0.9512 - f1_m: 0.7160 - precision_m: 0.5676 - recall_m: 0.9870 - val_loss: 0.1895 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 20s 412ms/step - loss: 0.1194 - accuracy: 0.9611 - f1_m: 0.7159 - precision_m: 0.5680 - recall_m: 0.9825 - val_loss: 0.1198 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0934 - accuracy: 0.9703 - f1_m: 0.7157 - precision_m: 0.5663 - recall_m: 0.9853 - val_loss: 0.0935 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.1180 - accuracy: 0.9650 - f1_m: 0.7222 - precision_m: 0.5716 - recall_m: 0.9933 - val_loss: 0.1304 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1297 - accuracy: 0.9690 - f1_m: 0.7152 - precision_m: 0.5656 - recall_m: 0.9889 - val_loss: 0.0482 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0993 - accuracy: 0.9670 - f1_m: 0.7217 - precision_m: 0.5703 - recall_m: 0.9976 - val_loss: 0.0407 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1131 - accuracy: 0.9736 - f1_m: 0.7206 - precision_m: 0.5696 - recall_m: 0.9961 - val_loss: 0.1540 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.1817 - accuracy: 0.9763 - f1_m: 0.7226 - precision_m: 0.5711 - recall_m: 0.9977 - val_loss: 0.0812 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0910 - accuracy: 0.9743 - f1_m: 0.7224 - precision_m: 0.5730 - recall_m: 0.9916 - val_loss: 0.0704 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.1085 - accuracy: 0.9769 - f1_m: 0.7185 - precision_m: 0.5679 - recall_m: 0.9951 - val_loss: 0.0932 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.1116 - accuracy: 0.9703 - f1_m: 0.7213 - precision_m: 0.5707 - recall_m: 0.9974 - val_loss: 0.0968 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.1114 - accuracy: 0.9697 - f1_m: 0.7188 - precision_m: 0.5674 - recall_m: 0.9932 - val_loss: 0.0570 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0655 - accuracy: 0.9789 - f1_m: 0.7138 - precision_m: 0.5644 - recall_m: 0.9843 - val_loss: 0.0396 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 411ms/step - loss: 0.0913 - accuracy: 0.9782 - f1_m: 0.7164 - precision_m: 0.5657 - recall_m: 0.9881 - val_loss: 0.2287 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.0764 - accuracy: 0.9749 - f1_m: 0.7135 - precision_m: 0.5639 - recall_m: 0.9891 - val_loss: 1.0335 - val_accuracy: 0.9158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 33s 691ms/step - loss: 0.1625 - accuracy: 0.9782 - f1_m: 0.7185 - precision_m: 0.5691 - recall_m: 0.9880 - val_loss: 0.0658 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 25s 522ms/step - loss: 0.2020 - accuracy: 0.9730 - f1_m: 0.7178 - precision_m: 0.5675 - recall_m: 0.9955 - val_loss: 0.0545 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 23s 475ms/step - loss: 0.0563 - accuracy: 0.9802 - f1_m: 0.7195 - precision_m: 0.5692 - recall_m: 0.9925 - val_loss: 0.1132 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0975 - accuracy: 0.9776 - f1_m: 0.7191 - precision_m: 0.5700 - recall_m: 0.9943 - val_loss: 0.0769 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0971 - accuracy: 0.9769 - f1_m: 0.7121 - precision_m: 0.5636 - recall_m: 0.9877 - val_loss: 0.0231 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0781 - accuracy: 0.9796 - f1_m: 0.7127 - precision_m: 0.5640 - recall_m: 0.9864 - val_loss: 0.0249 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 22s 453ms/step - loss: 0.1641 - accuracy: 0.9670 - f1_m: 0.7199 - precision_m: 0.5692 - recall_m: 0.9913 - val_loss: 0.0644 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0515 - accuracy: 0.9842 - f1_m: 0.7182 - precision_m: 0.5667 - recall_m: 0.9891 - val_loss: 0.0802 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.3443 - accuracy: 0.9736 - f1_m: 0.7189 - precision_m: 0.5698 - recall_m: 0.9875 - val_loss: 0.0522 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0626 - accuracy: 0.9822 - f1_m: 0.7202 - precision_m: 0.5707 - recall_m: 0.9945 - val_loss: 0.0281 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0844 - accuracy: 0.9736 - f1_m: 0.7214 - precision_m: 0.5714 - recall_m: 0.9953 - val_loss: 0.0360 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.2101 - accuracy: 0.9697 - f1_m: 0.7153 - precision_m: 0.5666 - recall_m: 0.9825 - val_loss: 0.0430 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0654 - accuracy: 0.9842 - f1_m: 0.7135 - precision_m: 0.5661 - recall_m: 0.9828 - val_loss: 0.2345 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0780 - accuracy: 0.9776 - f1_m: 0.7197 - precision_m: 0.5688 - recall_m: 0.9929 - val_loss: 0.1438 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0919 - accuracy: 0.9835 - f1_m: 0.7187 - precision_m: 0.5678 - recall_m: 0.9891 - val_loss: 0.0250 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0517 - accuracy: 0.9842 - f1_m: 0.7195 - precision_m: 0.5707 - recall_m: 0.9878 - val_loss: 0.0620 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1410 - accuracy: 0.9769 - f1_m: 0.7182 - precision_m: 0.5684 - recall_m: 0.9879 - val_loss: 0.0269 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0804 - accuracy: 0.9796 - f1_m: 0.7112 - precision_m: 0.5643 - recall_m: 0.9855 - val_loss: 0.0279 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0666 - accuracy: 0.9828 - f1_m: 0.7159 - precision_m: 0.5657 - recall_m: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 78ms/step - loss: 0.0410 - accuracy: 0.9842 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 1.0375 - accuracy: 0.5363 - f1_m: 0.6256 - precision_m: 0.5821 - recall_m: 0.7064 - val_loss: 0.5854 - val_accuracy: 0.7316 - val_f1_m: 0.7130 - val_precision_m: 0.5751 - val_recall_m: 0.9443\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.7436 - accuracy: 0.6306 - f1_m: 0.6979 - precision_m: 0.5879 - recall_m: 0.8788 - val_loss: 0.4736 - val_accuracy: 0.7737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.6015 - accuracy: 0.6913 - f1_m: 0.7085 - precision_m: 0.5739 - recall_m: 0.9362 - val_loss: 0.4244 - val_accuracy: 0.8053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.4476 - accuracy: 0.7896 - f1_m: 0.7107 - precision_m: 0.5683 - recall_m: 0.9684 - val_loss: 0.2872 - val_accuracy: 0.8947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.3055 - accuracy: 0.8753 - f1_m: 0.7159 - precision_m: 0.5692 - recall_m: 0.9782 - val_loss: 0.1997 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.2455 - accuracy: 0.8978 - f1_m: 0.7193 - precision_m: 0.5688 - recall_m: 0.9885 - val_loss: 0.1612 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1719 - accuracy: 0.9327 - f1_m: 0.7215 - precision_m: 0.5736 - recall_m: 0.9889 - val_loss: 0.2626 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1712 - accuracy: 0.9321 - f1_m: 0.7182 - precision_m: 0.5694 - recall_m: 0.9890 - val_loss: 0.2174 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1483 - accuracy: 0.9545 - f1_m: 0.7175 - precision_m: 0.5679 - recall_m: 0.9923 - val_loss: 0.1261 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.3073 - accuracy: 0.8931 - f1_m: 0.7152 - precision_m: 0.5678 - recall_m: 0.9784 - val_loss: 0.1655 - val_accuracy: 0.9579 - val_f1_m: 0.7295 - val_precision_m: 0.5763 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.1509 - accuracy: 0.9479 - f1_m: 0.7219 - precision_m: 0.5718 - recall_m: 0.9927 - val_loss: 0.1080 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1929 - accuracy: 0.9228 - f1_m: 0.7220 - precision_m: 0.5721 - recall_m: 0.9965 - val_loss: 0.2638 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1569 - accuracy: 0.9400 - f1_m: 0.7218 - precision_m: 0.5705 - recall_m: 0.9949 - val_loss: 0.1811 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.1024 - accuracy: 0.9631 - f1_m: 0.7210 - precision_m: 0.5689 - recall_m: 0.9955 - val_loss: 0.0451 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1024 - accuracy: 0.9611 - f1_m: 0.7208 - precision_m: 0.5696 - recall_m: 0.9976 - val_loss: 0.2013 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1117 - accuracy: 0.9624 - f1_m: 0.7237 - precision_m: 0.5730 - recall_m: 0.9966 - val_loss: 0.0752 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1044 - accuracy: 0.9677 - f1_m: 0.7190 - precision_m: 0.5678 - recall_m: 0.9932 - val_loss: 0.0819 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0806 - accuracy: 0.9710 - f1_m: 0.7193 - precision_m: 0.5683 - recall_m: 0.9979 - val_loss: 0.0515 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0680 - accuracy: 0.9815 - f1_m: 0.7207 - precision_m: 0.5717 - recall_m: 0.9959 - val_loss: 0.0540 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0533 - accuracy: 0.9822 - f1_m: 0.7223 - precision_m: 0.5709 - recall_m: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0911 - accuracy: 0.9736 - f1_m: 0.7256 - precision_m: 0.5757 - recall_m: 0.9978 - val_loss: 0.0986 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0975 - accuracy: 0.9690 - f1_m: 0.7227 - precision_m: 0.5720 - recall_m: 0.9968 - val_loss: 0.0524 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0910 - accuracy: 0.9716 - f1_m: 0.7200 - precision_m: 0.5697 - recall_m: 0.9937 - val_loss: 0.1935 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0432 - accuracy: 0.9881 - f1_m: 0.7213 - precision_m: 0.5719 - recall_m: 0.9963 - val_loss: 0.0287 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1085 - accuracy: 0.9611 - f1_m: 0.7221 - precision_m: 0.5727 - recall_m: 0.9956 - val_loss: 0.0778 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.1016 - accuracy: 0.9677 - f1_m: 0.7222 - precision_m: 0.5707 - recall_m: 0.9942 - val_loss: 0.0838 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0748 - accuracy: 0.9756 - f1_m: 0.7187 - precision_m: 0.5679 - recall_m: 0.9931 - val_loss: 0.1679 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0532 - accuracy: 0.9809 - f1_m: 0.7192 - precision_m: 0.5675 - recall_m: 0.9980 - val_loss: 0.0449 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0658 - accuracy: 0.9763 - f1_m: 0.7220 - precision_m: 0.5724 - recall_m: 0.9969 - val_loss: 0.3635 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0623 - accuracy: 0.9809 - f1_m: 0.7230 - precision_m: 0.5718 - recall_m: 0.9977 - val_loss: 0.1068 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0694 - accuracy: 0.9828 - f1_m: 0.7231 - precision_m: 0.5715 - recall_m: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0576 - accuracy: 0.9782 - f1_m: 0.7222 - precision_m: 0.5722 - recall_m: 0.9985 - val_loss: 0.1356 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0330 - accuracy: 0.9888 - f1_m: 0.7211 - precision_m: 0.5694 - recall_m: 0.9990 - val_loss: 0.2743 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0571 - accuracy: 0.9815 - f1_m: 0.7241 - precision_m: 0.5730 - recall_m: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0620 - accuracy: 0.9802 - f1_m: 0.7226 - precision_m: 0.5696 - recall_m: 0.9989 - val_loss: 0.1717 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0434 - accuracy: 0.9875 - f1_m: 0.7197 - precision_m: 0.5699 - recall_m: 0.9980 - val_loss: 0.0507 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0364 - accuracy: 0.9881 - f1_m: 0.7201 - precision_m: 0.5710 - recall_m: 0.9952 - val_loss: 0.0880 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0524 - accuracy: 0.9835 - f1_m: 0.7217 - precision_m: 0.5699 - recall_m: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0610 - accuracy: 0.9809 - f1_m: 0.7218 - precision_m: 0.5688 - recall_m: 0.9958 - val_loss: 0.0895 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0587 - accuracy: 0.9815 - f1_m: 0.7242 - precision_m: 0.5719 - recall_m: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0547 - accuracy: 0.9802 - f1_m: 0.7238 - precision_m: 0.5720 - recall_m: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0341 - accuracy: 0.9901 - f1_m: 0.7228 - precision_m: 0.5706 - recall_m: 0.9985 - val_loss: 0.0681 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0367 - accuracy: 0.9868 - f1_m: 0.7232 - precision_m: 0.5726 - recall_m: 0.9958 - val_loss: 0.5393 - val_accuracy: 0.9105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0340 - accuracy: 0.9894 - f1_m: 0.7224 - precision_m: 0.5717 - recall_m: 0.9988 - val_loss: 0.0098 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0368 - accuracy: 0.9881 - f1_m: 0.7220 - precision_m: 0.5709 - recall_m: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0340 - accuracy: 0.9875 - f1_m: 0.7255 - precision_m: 0.5733 - recall_m: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0273 - accuracy: 0.9921 - f1_m: 0.7207 - precision_m: 0.5689 - recall_m: 0.9988 - val_loss: 0.0411 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0307 - accuracy: 0.9894 - f1_m: 0.7224 - precision_m: 0.5703 - recall_m: 0.9971 - val_loss: 0.0341 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0466 - accuracy: 0.9842 - f1_m: 0.7217 - precision_m: 0.5690 - recall_m: 0.9965 - val_loss: 0.3460 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0735 - accuracy: 0.9756 - f1_m: 0.7215 - precision_m: 0.5711 - recall_m: 0.9938 - val_loss: 0.0455 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.0455 - accuracy: 0.9737 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'Nadam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 22s 435ms/step - loss: 1.0660 - accuracy: 0.5369 - f1_m: 0.6226 - precision_m: 0.5821 - recall_m: 0.6912 - val_loss: 0.5755 - val_accuracy: 0.6789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.7567 - accuracy: 0.6372 - f1_m: 0.6909 - precision_m: 0.5892 - recall_m: 0.8570 - val_loss: 0.5557 - val_accuracy: 0.6053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.6703 - accuracy: 0.7045 - f1_m: 0.7065 - precision_m: 0.5849 - recall_m: 0.9094 - val_loss: 0.5011 - val_accuracy: 0.6842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.5742 - accuracy: 0.7559 - f1_m: 0.7102 - precision_m: 0.5802 - recall_m: 0.9402 - val_loss: 0.3641 - val_accuracy: 0.8421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.4560 - accuracy: 0.8160 - f1_m: 0.7224 - precision_m: 0.5819 - recall_m: 0.9639 - val_loss: 0.6308 - val_accuracy: 0.7105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.3764 - accuracy: 0.8437 - f1_m: 0.7234 - precision_m: 0.5821 - recall_m: 0.9698 - val_loss: 0.7015 - val_accuracy: 0.7158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.2977 - accuracy: 0.8806 - f1_m: 0.7292 - precision_m: 0.5871 - recall_m: 0.9765 - val_loss: 0.2301 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.3832 - accuracy: 0.8575 - f1_m: 0.7249 - precision_m: 0.5794 - recall_m: 0.9795 - val_loss: 0.1647 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.3019 - accuracy: 0.8925 - f1_m: 0.7170 - precision_m: 0.5744 - recall_m: 0.9678 - val_loss: 0.1963 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.2581 - accuracy: 0.8997 - f1_m: 0.7169 - precision_m: 0.5773 - recall_m: 0.9658 - val_loss: 0.0817 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.4287 - accuracy: 0.8555 - f1_m: 0.7126 - precision_m: 0.5737 - recall_m: 0.9561 - val_loss: 0.1613 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.2347 - accuracy: 0.9017 - f1_m: 0.7113 - precision_m: 0.5706 - recall_m: 0.9586 - val_loss: 0.5440 - val_accuracy: 0.8895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.2573 - accuracy: 0.9103 - f1_m: 0.7145 - precision_m: 0.5733 - recall_m: 0.9709 - val_loss: 0.1333 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1840 - accuracy: 0.9222 - f1_m: 0.7144 - precision_m: 0.5700 - recall_m: 0.9716 - val_loss: 0.1784 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1812 - accuracy: 0.9268 - f1_m: 0.7130 - precision_m: 0.5715 - recall_m: 0.9792 - val_loss: 0.1182 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1884 - accuracy: 0.9261 - f1_m: 0.7091 - precision_m: 0.5682 - recall_m: 0.9557 - val_loss: 0.0546 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1833 - accuracy: 0.9208 - f1_m: 0.7160 - precision_m: 0.5736 - recall_m: 0.9691 - val_loss: 0.0494 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1912 - accuracy: 0.9241 - f1_m: 0.7149 - precision_m: 0.5733 - recall_m: 0.9670 - val_loss: 0.0985 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1750 - accuracy: 0.9294 - f1_m: 0.7164 - precision_m: 0.5724 - recall_m: 0.9732 - val_loss: 0.0715 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1623 - accuracy: 0.9314 - f1_m: 0.7141 - precision_m: 0.5711 - recall_m: 0.9720 - val_loss: 0.2077 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1559 - accuracy: 0.9307 - f1_m: 0.7169 - precision_m: 0.5707 - recall_m: 0.9743 - val_loss: 0.0687 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1340 - accuracy: 0.9466 - f1_m: 0.7174 - precision_m: 0.5705 - recall_m: 0.9774 - val_loss: 0.1109 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.1196 - accuracy: 0.9571 - f1_m: 0.7190 - precision_m: 0.5724 - recall_m: 0.9795 - val_loss: 0.0613 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1253 - accuracy: 0.9518 - f1_m: 0.7231 - precision_m: 0.5756 - recall_m: 0.9850 - val_loss: 0.0550 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1190 - accuracy: 0.9505 - f1_m: 0.7223 - precision_m: 0.5765 - recall_m: 0.9820 - val_loss: 0.0604 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1206 - accuracy: 0.9598 - f1_m: 0.7241 - precision_m: 0.5751 - recall_m: 0.9850 - val_loss: 0.0673 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.3844 - accuracy: 0.9037 - f1_m: 0.7252 - precision_m: 0.5822 - recall_m: 0.9762 - val_loss: 0.6717 - val_accuracy: 0.7368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.2831 - accuracy: 0.8819 - f1_m: 0.7140 - precision_m: 0.5714 - recall_m: 0.9652 - val_loss: 0.2979 - val_accuracy: 0.8947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1665 - accuracy: 0.9393 - f1_m: 0.7198 - precision_m: 0.5728 - recall_m: 0.9841 - val_loss: 0.0605 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1313 - accuracy: 0.9453 - f1_m: 0.7233 - precision_m: 0.5771 - recall_m: 0.9833 - val_loss: 0.0424 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1307 - accuracy: 0.9505 - f1_m: 0.7096 - precision_m: 0.5661 - recall_m: 0.9706 - val_loss: 0.1815 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1232 - accuracy: 0.9499 - f1_m: 0.7161 - precision_m: 0.5694 - recall_m: 0.9823 - val_loss: 0.2384 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1147 - accuracy: 0.9584 - f1_m: 0.7246 - precision_m: 0.5773 - recall_m: 0.9877 - val_loss: 0.0604 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.1213 - accuracy: 0.9525 - f1_m: 0.7243 - precision_m: 0.5766 - recall_m: 0.9876 - val_loss: 0.0605 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1380 - accuracy: 0.9512 - f1_m: 0.7195 - precision_m: 0.5739 - recall_m: 0.9780 - val_loss: 0.0368 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.1382 - accuracy: 0.9485 - f1_m: 0.7160 - precision_m: 0.5713 - recall_m: 0.9731 - val_loss: 0.0564 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1211 - accuracy: 0.9479 - f1_m: 0.7171 - precision_m: 0.5734 - recall_m: 0.9705 - val_loss: 0.1915 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1028 - accuracy: 0.9617 - f1_m: 0.7165 - precision_m: 0.5705 - recall_m: 0.9791 - val_loss: 0.0689 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1291 - accuracy: 0.9565 - f1_m: 0.7157 - precision_m: 0.5742 - recall_m: 0.9657 - val_loss: 0.1808 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0771 - accuracy: 0.9683 - f1_m: 0.7166 - precision_m: 0.5727 - recall_m: 0.9753 - val_loss: 0.2181 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0988 - accuracy: 0.9571 - f1_m: 0.7193 - precision_m: 0.5748 - recall_m: 0.9764 - val_loss: 0.0693 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1242 - accuracy: 0.9532 - f1_m: 0.7134 - precision_m: 0.5741 - recall_m: 0.9669 - val_loss: 0.0407 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0998 - accuracy: 0.9617 - f1_m: 0.7191 - precision_m: 0.5724 - recall_m: 0.9791 - val_loss: 0.0237 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1144 - accuracy: 0.9551 - f1_m: 0.7111 - precision_m: 0.5702 - recall_m: 0.9664 - val_loss: 0.0956 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1726 - accuracy: 0.9380 - f1_m: 0.7136 - precision_m: 0.5703 - recall_m: 0.9677 - val_loss: 0.0518 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.1027 - accuracy: 0.9657 - f1_m: 0.7163 - precision_m: 0.5765 - recall_m: 0.9634 - val_loss: 0.0326 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0871 - accuracy: 0.9637 - f1_m: 0.7138 - precision_m: 0.5748 - recall_m: 0.9712 - val_loss: 0.0619 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1107 - accuracy: 0.9525 - f1_m: 0.7136 - precision_m: 0.5723 - recall_m: 0.9642 - val_loss: 0.0921 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.0876 - accuracy: 0.9611 - f1_m: 0.7138 - precision_m: 0.5706 - recall_m: 0.9657 - val_loss: 0.0809 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0801 - accuracy: 0.9723 - f1_m: 0.7247 - precision_m: 0.5781 - recall_m: 0.9826 - val_loss: 0.0352 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 79ms/step - loss: 0.0352 - accuracy: 0.9842 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 23s 446ms/step - loss: 1.1424 - accuracy: 0.5290 - f1_m: 0.5903 - precision_m: 0.5594 - recall_m: 0.6593 - val_loss: 0.6195 - val_accuracy: 0.6842 - val_f1_m: 0.7456 - val_precision_m: 0.6159 - val_recall_m: 0.9526\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.8201 - accuracy: 0.6365 - f1_m: 0.6960 - precision_m: 0.6083 - recall_m: 0.8325 - val_loss: 0.4141 - val_accuracy: 0.7684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.6502 - accuracy: 0.7183 - f1_m: 0.7132 - precision_m: 0.5912 - recall_m: 0.9176 - val_loss: 0.4461 - val_accuracy: 0.7947 - val_f1_m: 0.7230 - val_precision_m: 0.5709 - val_recall_m: 0.9917\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.4994 - accuracy: 0.7803 - f1_m: 0.7085 - precision_m: 0.5751 - recall_m: 0.9399 - val_loss: 0.3148 - val_accuracy: 0.8842 - val_f1_m: 0.7230 - val_precision_m: 0.5709 - val_recall_m: 0.9917\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 428ms/step - loss: 0.3990 - accuracy: 0.8384 - f1_m: 0.7135 - precision_m: 0.5717 - recall_m: 0.9626 - val_loss: 0.2067 - val_accuracy: 0.9158 - val_f1_m: 0.7295 - val_precision_m: 0.5763 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.3353 - accuracy: 0.8575 - f1_m: 0.7180 - precision_m: 0.5753 - recall_m: 0.9689 - val_loss: 0.1661 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.2569 - accuracy: 0.9011 - f1_m: 0.7194 - precision_m: 0.5720 - recall_m: 0.9831 - val_loss: 0.1515 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.2966 - accuracy: 0.9017 - f1_m: 0.7204 - precision_m: 0.5714 - recall_m: 0.9883 - val_loss: 0.1862 - val_accuracy: 0.9158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1929 - accuracy: 0.9228 - f1_m: 0.7253 - precision_m: 0.5778 - recall_m: 0.9909 - val_loss: 0.0943 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.2288 - accuracy: 0.9248 - f1_m: 0.7220 - precision_m: 0.5720 - recall_m: 0.9866 - val_loss: 0.1401 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.2093 - accuracy: 0.9354 - f1_m: 0.7255 - precision_m: 0.5744 - recall_m: 0.9935 - val_loss: 0.5326 - val_accuracy: 0.8526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1649 - accuracy: 0.9446 - f1_m: 0.7222 - precision_m: 0.5721 - recall_m: 0.9934 - val_loss: 0.1207 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1762 - accuracy: 0.9459 - f1_m: 0.7231 - precision_m: 0.5710 - recall_m: 0.9974 - val_loss: 0.1788 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1504 - accuracy: 0.9525 - f1_m: 0.7246 - precision_m: 0.5737 - recall_m: 0.9942 - val_loss: 0.0940 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1310 - accuracy: 0.9578 - f1_m: 0.7209 - precision_m: 0.5718 - recall_m: 0.9932 - val_loss: 0.1458 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1820 - accuracy: 0.9499 - f1_m: 0.7202 - precision_m: 0.5717 - recall_m: 0.9914 - val_loss: 0.1273 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1638 - accuracy: 0.9538 - f1_m: 0.7248 - precision_m: 0.5735 - recall_m: 0.9931 - val_loss: 0.0765 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1158 - accuracy: 0.9624 - f1_m: 0.7168 - precision_m: 0.5686 - recall_m: 0.9887 - val_loss: 0.3790 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.2162 - accuracy: 0.9525 - f1_m: 0.7236 - precision_m: 0.5741 - recall_m: 0.9931 - val_loss: 0.0791 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1315 - accuracy: 0.9571 - f1_m: 0.7216 - precision_m: 0.5709 - recall_m: 0.9932 - val_loss: 0.0501 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1654 - accuracy: 0.9485 - f1_m: 0.7235 - precision_m: 0.5729 - recall_m: 0.9945 - val_loss: 0.0644 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1564 - accuracy: 0.9598 - f1_m: 0.7209 - precision_m: 0.5724 - recall_m: 0.9871 - val_loss: 0.0470 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1019 - accuracy: 0.9697 - f1_m: 0.7213 - precision_m: 0.5709 - recall_m: 0.9944 - val_loss: 0.0872 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.1767 - accuracy: 0.9591 - f1_m: 0.7179 - precision_m: 0.5698 - recall_m: 0.9882 - val_loss: 0.1262 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.0940 - accuracy: 0.9730 - f1_m: 0.7212 - precision_m: 0.5704 - recall_m: 0.9884 - val_loss: 1.9087 - val_accuracy: 0.7526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1340 - accuracy: 0.9650 - f1_m: 0.7192 - precision_m: 0.5709 - recall_m: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1371 - accuracy: 0.9624 - f1_m: 0.7209 - precision_m: 0.5708 - recall_m: 0.9925 - val_loss: 0.4484 - val_accuracy: 0.9105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0952 - accuracy: 0.9736 - f1_m: 0.7176 - precision_m: 0.5675 - recall_m: 0.9893 - val_loss: 0.2098 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1134 - accuracy: 0.9670 - f1_m: 0.7203 - precision_m: 0.5719 - recall_m: 0.9855 - val_loss: 0.2689 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1094 - accuracy: 0.9683 - f1_m: 0.7199 - precision_m: 0.5703 - recall_m: 0.9920 - val_loss: 0.0477 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.1071 - accuracy: 0.9736 - f1_m: 0.7179 - precision_m: 0.5685 - recall_m: 0.9896 - val_loss: 0.1091 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0968 - accuracy: 0.9782 - f1_m: 0.7203 - precision_m: 0.5718 - recall_m: 0.9878 - val_loss: 0.0629 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1098 - accuracy: 0.9723 - f1_m: 0.7162 - precision_m: 0.5672 - recall_m: 0.9902 - val_loss: 0.0462 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0978 - accuracy: 0.9697 - f1_m: 0.7237 - precision_m: 0.5743 - recall_m: 0.9918 - val_loss: 0.0899 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1027 - accuracy: 0.9736 - f1_m: 0.7286 - precision_m: 0.5774 - recall_m: 0.9984 - val_loss: 0.0516 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0937 - accuracy: 0.9730 - f1_m: 0.7177 - precision_m: 0.5679 - recall_m: 0.9903 - val_loss: 0.0490 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0821 - accuracy: 0.9789 - f1_m: 0.7240 - precision_m: 0.5746 - recall_m: 0.9980 - val_loss: 0.2485 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1144 - accuracy: 0.9743 - f1_m: 0.7236 - precision_m: 0.5725 - recall_m: 0.9959 - val_loss: 0.2990 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0888 - accuracy: 0.9716 - f1_m: 0.7208 - precision_m: 0.5707 - recall_m: 0.9933 - val_loss: 0.0619 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.1018 - accuracy: 0.9782 - f1_m: 0.7244 - precision_m: 0.5746 - recall_m: 0.9937 - val_loss: 0.0256 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0856 - accuracy: 0.9769 - f1_m: 0.7214 - precision_m: 0.5727 - recall_m: 0.9915 - val_loss: 0.2675 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1900 - accuracy: 0.9703 - f1_m: 0.7172 - precision_m: 0.5672 - recall_m: 0.9920 - val_loss: 0.0378 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0595 - accuracy: 0.9809 - f1_m: 0.7213 - precision_m: 0.5707 - recall_m: 0.9930 - val_loss: 0.0195 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0930 - accuracy: 0.9776 - f1_m: 0.7234 - precision_m: 0.5726 - recall_m: 0.9941 - val_loss: 0.0511 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0544 - accuracy: 0.9848 - f1_m: 0.7157 - precision_m: 0.5659 - recall_m: 0.9902 - val_loss: 0.2970 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1050 - accuracy: 0.9763 - f1_m: 0.7250 - precision_m: 0.5769 - recall_m: 0.9939 - val_loss: 0.0085 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0652 - accuracy: 0.9822 - f1_m: 0.7207 - precision_m: 0.5705 - recall_m: 0.9927 - val_loss: 0.0386 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.1032 - accuracy: 0.9763 - f1_m: 0.7211 - precision_m: 0.5715 - recall_m: 0.9863 - val_loss: 0.0767 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.1609 - accuracy: 0.9710 - f1_m: 0.7208 - precision_m: 0.5716 - recall_m: 0.9919 - val_loss: 0.0397 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1078 - accuracy: 0.9776 - f1_m: 0.7195 - precision_m: 0.5682 - recall_m: 0.9931 - val_loss: 0.0351 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 0.0351 - accuracy: 0.9842 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 22s 444ms/step - loss: 1.1619 - accuracy: 0.4512 - f1_m: 0.5664 - precision_m: 0.5807 - recall_m: 0.5941 - val_loss: 0.6047 - val_accuracy: 0.6316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.8180 - accuracy: 0.5930 - f1_m: 0.6593 - precision_m: 0.5718 - recall_m: 0.7999 - val_loss: 0.4729 - val_accuracy: 0.7895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.7178 - accuracy: 0.6425 - f1_m: 0.6783 - precision_m: 0.5635 - recall_m: 0.8691 - val_loss: 0.4768 - val_accuracy: 0.7632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.6395 - accuracy: 0.6920 - f1_m: 0.6949 - precision_m: 0.5668 - recall_m: 0.9119 - val_loss: 0.3911 - val_accuracy: 0.8263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.5967 - accuracy: 0.7131 - f1_m: 0.7016 - precision_m: 0.5714 - recall_m: 0.9216 - val_loss: 0.3739 - val_accuracy: 0.8263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.5039 - accuracy: 0.7480 - f1_m: 0.7115 - precision_m: 0.5713 - recall_m: 0.9573 - val_loss: 0.2898 - val_accuracy: 0.8789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.5041 - accuracy: 0.7672 - f1_m: 0.7078 - precision_m: 0.5765 - recall_m: 0.9369 - val_loss: 0.2405 - val_accuracy: 0.8842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.4137 - accuracy: 0.8034 - f1_m: 0.7108 - precision_m: 0.5708 - recall_m: 0.9572 - val_loss: 0.2130 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.3568 - accuracy: 0.8470 - f1_m: 0.7139 - precision_m: 0.5728 - recall_m: 0.9674 - val_loss: 0.2241 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 20s 428ms/step - loss: 0.3235 - accuracy: 0.8621 - f1_m: 0.7072 - precision_m: 0.5650 - recall_m: 0.9602 - val_loss: 0.1212 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.4223 - accuracy: 0.8067 - f1_m: 0.7119 - precision_m: 0.5740 - recall_m: 0.9514 - val_loss: 0.1920 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.2271 - accuracy: 0.9090 - f1_m: 0.7158 - precision_m: 0.5702 - recall_m: 0.9799 - val_loss: 0.1878 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.2187 - accuracy: 0.9109 - f1_m: 0.7129 - precision_m: 0.5684 - recall_m: 0.9710 - val_loss: 0.0784 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.2256 - accuracy: 0.8931 - f1_m: 0.7230 - precision_m: 0.5794 - recall_m: 0.9827 - val_loss: 0.0659 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1614 - accuracy: 0.9261 - f1_m: 0.7232 - precision_m: 0.5742 - recall_m: 0.9863 - val_loss: 0.2141 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1288 - accuracy: 0.9393 - f1_m: 0.7180 - precision_m: 0.5695 - recall_m: 0.9869 - val_loss: 0.0631 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1382 - accuracy: 0.9393 - f1_m: 0.7228 - precision_m: 0.5745 - recall_m: 0.9912 - val_loss: 0.1108 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1420 - accuracy: 0.9479 - f1_m: 0.7215 - precision_m: 0.5737 - recall_m: 0.9891 - val_loss: 0.1238 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1457 - accuracy: 0.9426 - f1_m: 0.7253 - precision_m: 0.5794 - recall_m: 0.9907 - val_loss: 0.1677 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1322 - accuracy: 0.9453 - f1_m: 0.7170 - precision_m: 0.5703 - recall_m: 0.9824 - val_loss: 0.1039 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1295 - accuracy: 0.9466 - f1_m: 0.7246 - precision_m: 0.5768 - recall_m: 0.9887 - val_loss: 0.0223 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1355 - accuracy: 0.9472 - f1_m: 0.7229 - precision_m: 0.5745 - recall_m: 0.9904 - val_loss: 0.1299 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1477 - accuracy: 0.9472 - f1_m: 0.7234 - precision_m: 0.5776 - recall_m: 0.9856 - val_loss: 0.0797 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1070 - accuracy: 0.9532 - f1_m: 0.7231 - precision_m: 0.5750 - recall_m: 0.9924 - val_loss: 0.1318 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0958 - accuracy: 0.9664 - f1_m: 0.7186 - precision_m: 0.5697 - recall_m: 0.9938 - val_loss: 0.2151 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1461 - accuracy: 0.9393 - f1_m: 0.7263 - precision_m: 0.5774 - recall_m: 0.9907 - val_loss: 0.1243 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1107 - accuracy: 0.9578 - f1_m: 0.7209 - precision_m: 0.5718 - recall_m: 0.9906 - val_loss: 0.0326 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1463 - accuracy: 0.9472 - f1_m: 0.7239 - precision_m: 0.5769 - recall_m: 0.9874 - val_loss: 0.0514 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.1079 - accuracy: 0.9598 - f1_m: 0.7244 - precision_m: 0.5774 - recall_m: 0.9901 - val_loss: 0.0484 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1007 - accuracy: 0.9565 - f1_m: 0.7217 - precision_m: 0.5706 - recall_m: 0.9923 - val_loss: 0.0648 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1093 - accuracy: 0.9617 - f1_m: 0.7260 - precision_m: 0.5758 - recall_m: 0.9929 - val_loss: 0.0361 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0958 - accuracy: 0.9584 - f1_m: 0.7194 - precision_m: 0.5705 - recall_m: 0.9894 - val_loss: 0.0917 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1082 - accuracy: 0.9571 - f1_m: 0.7181 - precision_m: 0.5686 - recall_m: 0.9864 - val_loss: 0.0438 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0856 - accuracy: 0.9743 - f1_m: 0.7245 - precision_m: 0.5766 - recall_m: 0.9960 - val_loss: 0.0691 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0733 - accuracy: 0.9730 - f1_m: 0.7095 - precision_m: 0.5643 - recall_m: 0.9737 - val_loss: 0.0648 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.1259 - accuracy: 0.9624 - f1_m: 0.7229 - precision_m: 0.5738 - recall_m: 0.9943 - val_loss: 0.1034 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0821 - accuracy: 0.9683 - f1_m: 0.7219 - precision_m: 0.5740 - recall_m: 0.9864 - val_loss: 0.0659 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0904 - accuracy: 0.9703 - f1_m: 0.7199 - precision_m: 0.5696 - recall_m: 0.9944 - val_loss: 0.0299 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0905 - accuracy: 0.9683 - f1_m: 0.7269 - precision_m: 0.5773 - recall_m: 0.9975 - val_loss: 0.0464 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0959 - accuracy: 0.9703 - f1_m: 0.7218 - precision_m: 0.5721 - recall_m: 0.9913 - val_loss: 0.0882 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0811 - accuracy: 0.9710 - f1_m: 0.7231 - precision_m: 0.5733 - recall_m: 0.9942 - val_loss: 0.2209 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0722 - accuracy: 0.9763 - f1_m: 0.7175 - precision_m: 0.5689 - recall_m: 0.9957 - val_loss: 0.2176 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0603 - accuracy: 0.9802 - f1_m: 0.7213 - precision_m: 0.5731 - recall_m: 0.9908 - val_loss: 0.3779 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0983 - accuracy: 0.9697 - f1_m: 0.7240 - precision_m: 0.5739 - recall_m: 0.9941 - val_loss: 0.0762 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0568 - accuracy: 0.9763 - f1_m: 0.7236 - precision_m: 0.5735 - recall_m: 0.9955 - val_loss: 0.2183 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0825 - accuracy: 0.9690 - f1_m: 0.7229 - precision_m: 0.5726 - recall_m: 0.9920 - val_loss: 0.0855 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0577 - accuracy: 0.9855 - f1_m: 0.7243 - precision_m: 0.5748 - recall_m: 0.9919 - val_loss: 0.0534 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0828 - accuracy: 0.9736 - f1_m: 0.7180 - precision_m: 0.5699 - recall_m: 0.9948 - val_loss: 0.0443 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0877 - accuracy: 0.9743 - f1_m: 0.7269 - precision_m: 0.5788 - recall_m: 0.9931 - val_loss: 0.0437 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0914 - accuracy: 0.9730 - f1_m: 0.7102 - precision_m: 0.5633 - recall_m: 0.9786 - val_loss: 0.1200 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 79ms/step - loss: 0.1200 - accuracy: 0.9526 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 64, 'dropout': 0.4, 'optimizer': 'Nadam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 43s 856ms/step - loss: 0.8636 - accuracy: 0.5726 - f1_m: 0.6747 - precision_m: 0.5671 - recall_m: 0.8514\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 47s 975ms/step - loss: 0.5747 - accuracy: 0.7170 - f1_m: 0.7130 - precision_m: 0.5756 - recall_m: 0.9542\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 46s 962ms/step - loss: 0.4410 - accuracy: 0.8015 - f1_m: 0.7182 - precision_m: 0.5680 - recall_m: 0.9873\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 42s 879ms/step - loss: 0.3797 - accuracy: 0.8430 - f1_m: 0.7197 - precision_m: 0.5703 - recall_m: 0.9846\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 43s 905ms/step - loss: 0.3066 - accuracy: 0.8852 - f1_m: 0.7215 - precision_m: 0.5710 - recall_m: 0.9917\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 42s 866ms/step - loss: 0.1905 - accuracy: 0.9235 - f1_m: 0.7216 - precision_m: 0.5722 - recall_m: 0.9990\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 42s 865ms/step - loss: 0.1984 - accuracy: 0.9235 - f1_m: 0.7202 - precision_m: 0.5700 - recall_m: 0.9965\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 47s 976ms/step - loss: 0.2914 - accuracy: 0.9057 - f1_m: 0.7149 - precision_m: 0.5645 - recall_m: 0.9937\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 41s 849ms/step - loss: 0.1396 - accuracy: 0.9518 - f1_m: 0.7222 - precision_m: 0.5698 - recall_m: 0.9986\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 42s 879ms/step - loss: 0.1900 - accuracy: 0.9321 - f1_m: 0.7202 - precision_m: 0.5700 - recall_m: 0.9947\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 54s 1s/step - loss: 0.1445 - accuracy: 0.9433 - f1_m: 0.7211 - precision_m: 0.5713 - recall_m: 0.9989\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 50s 1s/step - loss: 0.1596 - accuracy: 0.9538 - f1_m: 0.7208 - precision_m: 0.5716 - recall_m: 0.9931\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 50s 1s/step - loss: 0.1231 - accuracy: 0.9591 - f1_m: 0.7194 - precision_m: 0.5689 - recall_m: 0.9934\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 43s 900ms/step - loss: 0.0827 - accuracy: 0.9743 - f1_m: 0.7217 - precision_m: 0.5694 - recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 41s 857ms/step - loss: 0.0686 - accuracy: 0.9736 - f1_m: 0.7196 - precision_m: 0.5681 - recall_m: 0.9977\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 48s 1000ms/step - loss: 0.0729 - accuracy: 0.9756 - f1_m: 0.7205 - precision_m: 0.5684 - recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 47s 973ms/step - loss: 0.0515 - accuracy: 0.9815 - f1_m: 0.7180 - precision_m: 0.5673 - recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 61s 1s/step - loss: 0.0552 - accuracy: 0.9756 - f1_m: 0.7209 - precision_m: 0.5679 - recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 45s 922ms/step - loss: 0.0567 - accuracy: 0.9802 - f1_m: 0.7226 - precision_m: 0.5693 - recall_m: 0.9991\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 43s 890ms/step - loss: 0.0476 - accuracy: 0.9855 - f1_m: 0.7213 - precision_m: 0.5698 - recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 46s 956ms/step - loss: 0.0412 - accuracy: 0.9868 - f1_m: 0.7208 - precision_m: 0.5684 - recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 52s 1s/step - loss: 0.0390 - accuracy: 0.9861 - f1_m: 0.7203 - precision_m: 0.5684 - recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 43s 890ms/step - loss: 0.0598 - accuracy: 0.9796 - f1_m: 0.7189 - precision_m: 0.5659 - recall_m: 0.9989\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 48s 991ms/step - loss: 0.0615 - accuracy: 0.9763 - f1_m: 0.7213 - precision_m: 0.5692 - recall_m: 0.9989\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 60s 1s/step - loss: 0.0375 - accuracy: 0.9881 - f1_m: 0.7206 - precision_m: 0.5685 - recall_m: 0.9990\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 45s 936ms/step - loss: 0.0230 - accuracy: 0.9914 - f1_m: 0.7205 - precision_m: 0.5681 - recall_m: 0.9989\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 44s 916ms/step - loss: 0.0252 - accuracy: 0.9914 - f1_m: 0.7211 - precision_m: 0.5693 - recall_m: 0.9991\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 37s 777ms/step - loss: 0.0199 - accuracy: 0.9934 - f1_m: 0.7217 - precision_m: 0.5705 - recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 37s 774ms/step - loss: 0.3335 - accuracy: 0.9413 - f1_m: 0.7262 - precision_m: 0.5754 - recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 36s 745ms/step - loss: 0.0804 - accuracy: 0.9723 - f1_m: 0.7193 - precision_m: 0.5677 - recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 37s 764ms/step - loss: 0.0734 - accuracy: 0.9809 - f1_m: 0.7201 - precision_m: 0.5699 - recall_m: 0.9975\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 36s 752ms/step - loss: 0.0591 - accuracy: 0.9782 - f1_m: 0.7238 - precision_m: 0.5727 - recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 41s 859ms/step - loss: 0.0370 - accuracy: 0.9894 - f1_m: 0.7223 - precision_m: 0.5698 - recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 37s 765ms/step - loss: 0.0318 - accuracy: 0.9881 - f1_m: 0.7245 - precision_m: 0.5716 - recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 36s 748ms/step - loss: 0.0445 - accuracy: 0.9835 - f1_m: 0.7207 - precision_m: 0.5677 - recall_m: 0.9988\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 37s 772ms/step - loss: 0.0221 - accuracy: 0.9954 - f1_m: 0.7199 - precision_m: 0.5684 - recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 36s 756ms/step - loss: 0.0328 - accuracy: 0.9875 - f1_m: 0.7225 - precision_m: 0.5705 - recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 36s 755ms/step - loss: 0.0320 - accuracy: 0.9888 - f1_m: 0.7226 - precision_m: 0.5705 - recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 37s 765ms/step - loss: 0.0196 - accuracy: 0.9914 - f1_m: 0.7228 - precision_m: 0.5694 - recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 36s 740ms/step - loss: 0.0659 - accuracy: 0.9822 - f1_m: 0.7227 - precision_m: 0.5705 - recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 36s 751ms/step - loss: 0.0559 - accuracy: 0.9842 - f1_m: 0.7204 - precision_m: 0.5674 - recall_m: 0.9990\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 36s 741ms/step - loss: 0.0277 - accuracy: 0.9914 - f1_m: 0.7209 - precision_m: 0.5684 - recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 36s 745ms/step - loss: 0.0205 - accuracy: 0.9927 - f1_m: 0.7226 - precision_m: 0.5705 - recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 36s 741ms/step - loss: 0.0325 - accuracy: 0.9914 - f1_m: 0.7216 - precision_m: 0.5694 - recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 36s 751ms/step - loss: 0.0418 - accuracy: 0.9888 - f1_m: 0.7169 - precision_m: 0.5651 - recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 36s 750ms/step - loss: 0.0342 - accuracy: 0.9868 - f1_m: 0.7226 - precision_m: 0.5705 - recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 36s 750ms/step - loss: 0.0246 - accuracy: 0.9927 - f1_m: 0.7212 - precision_m: 0.5684 - recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 37s 764ms/step - loss: 0.0216 - accuracy: 0.9908 - f1_m: 0.7233 - precision_m: 0.5731 - recall_m: 0.9988\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 36s 742ms/step - loss: 0.0299 - accuracy: 0.9908 - f1_m: 0.7194 - precision_m: 0.5662 - recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 36s 746ms/step - loss: 0.0183 - accuracy: 0.9934 - f1_m: 0.7239 - precision_m: 0.5698 - recall_m: 1.0000\n",
      "6/6 [==============================] - 2s 278ms/step - loss: 0.0071 - accuracy: 1.0000 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "epochs = 50\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64]))#, 64])) #8, 16\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.4, 0.5))\n",
    "# dropout_rate = 0.3\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['RMSprop','adam','Nadam']))#,'adam', 'Nadam'])) #'sgd','Adagrad','RMSprop', \n",
    "\n",
    "params = []\n",
    "losses = []\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "aucs = []\n",
    "cms = []\n",
    "units = []\n",
    "dropouts = []\n",
    "optimizers = []\n",
    "histories = []\n",
    "modelz = []\n",
    "predictions = []\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        units.append(num_units)\n",
    "        dropouts.append(dropout_rate)\n",
    "        optimizers.append(optimizer)\n",
    "        model = run('logs/hparam_tuning/' + run_name, hparams, epochs, input_shape,train_images,train_labels,test_images, test_labels,\n",
    "                HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, predictions,\n",
    "                params, losses, accuracies, f1_scores, precisions, recalls, cms, aucs,\n",
    "                units, dropouts, optimizers, histories, augmentModel=True)\n",
    "        modelz.append(model)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>dropouts</th>\n",
       "      <th>optimizers</th>\n",
       "      <th>losses</th>\n",
       "      <th>accuracies</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precisions</th>\n",
       "      <th>recalls</th>\n",
       "      <th>cms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[81, 0], [0, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[80, 1], [0, 109]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  dropouts optimizers    losses  accuracies  f1_scores  precisions  \\\n",
       "0     64       0.4      Nadam  0.007077         1.0   0.727019    0.572917   \n",
       "\n",
       "   recalls                  cms  \n",
       "0      1.0  [[81, 0], [0, 109]]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe assembly for model comparison\n",
    "#integrate confusion matrices as well\n",
    "\n",
    "modelDf = pd.DataFrame(list(zip(units, dropouts, optimizers, losses, accuracies, f1_scores, precisions, recalls, cms)),#aucs, \n",
    "               columns =['units', 'dropouts', 'optimizers', 'losses', 'accuracies', 'f1_scores', 'precisions', 'recalls', 'cms'])#'aucs',\n",
    "modelDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelz[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "modelDf['cms'].values[5]\n",
    "\n",
    "plot_confusion_matrix_2(modelDf['cms'].values[5],normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(x=test_images, steps=len(test_images), verbose=0)\n",
    "# cm = confusion_matrix(y_true=test_labels, y_pred=np.argmax(prediction, axis=-1))\n",
    "# print(np.argmax(prediction, axis=-1).shape)\n",
    "# print(test_labels.shape)\n",
    "\n",
    "predictions2 = model.predict(x=hold_out_images, steps=len(hold_out_images), verbose=0)\n",
    "cm2 = confusion_matrix(y_true=hold_out_labels, y_pred=np.argmax(predictions2, axis=-1))\n",
    "# print(np.argmax(predictions2, axis=-1).shape)\n",
    "# print(test_data_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# modelDf['test_cms'].values[0]\n",
    "# plot_confusion_matrix_2(modelDf['test_cms'].values[0],normalize=False)\n",
    "\n",
    "plot_confusion_matrix_2(cm2,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_m</th>\n",
       "      <th>precision_m</th>\n",
       "      <th>recall_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70714</td>\n",
       "      <td>0.550792</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.568331</td>\n",
       "      <td>0.982416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     loss  accuracy    f1_m  precision_m  recall_m\n",
       "0      0  0.70714  0.550792  0.7145     0.568331  0.982416"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "history_df = pd.DataFrame(histories[0].history).reset_index()\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"artifacts/model_20211201.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_chart(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "\n",
    "# for i in range(len(list(modelDf.optimizers))):\n",
    "#     cls = modelDf.iloc[i,2]\n",
    "#     plot_confusion_matrix_2(modelDf[modelDf['optimizers']==cls]['cms'][i])\n",
    "#     ax.title.set_text(type(cls).__name__)\n",
    "# plt.tight_layout()  \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_predictions_baseline = model.predict(train_images)\n",
    "# test_predictions_baseline = model.predict(test_images)\n",
    "plot_roc(\"Train Baseline\", train_labels, predictions, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", test_data_labels, predictions2, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a7e1b17602ce2ea468a951908af7bc23f5fb404bcd43f493b2f049dccd7860b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('wild_fire_detection_capstone': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
