{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sklearn\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "%load_ext tensorboard\n",
    "\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "\n",
    "import importlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in test_train_split custom function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import train\n",
    "importlib.reload(train)\n",
    "from train import test_train_split, train_test_model, run\n",
    "import charts\n",
    "importlib.reload(charts)\n",
    "from charts import line_chart, plot_confusion_matrix_2, plot_roc, plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From pickeled files\n",
    "For loading the images for the model simply run the the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load image files from pickles both train and test\n",
    "dir = os.getcwd()\n",
    "\n",
    "with open('{}/artifacts/{}'.format(dir, 'train_images_pkl.pkl'), 'rb') as pickle_file: #train_images_pkl_all.pkl\n",
    "    train_data = pickle.load(pickle_file)\n",
    "\n",
    "with open('{}/artifacts/{}'.format(dir, 'test_images_pkl.pkl'), 'rb') as pickle_file: #test_images_pkl_even_ratio.pkl\n",
    "    test_data = pickle.load(pickle_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the images we can split the training set in to training, development and test images. We have imported a function that we have created for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1516, 100, 177, 3)\n",
      "(1516, 100, 177, 3)\n",
      "(100, 177, 3)\n",
      "(1516, 100, 177, 3)\n",
      "(1516, 1)\n"
     ]
    }
   ],
   "source": [
    "#splitting in to test train split for the training data\n",
    "train_images, train_labels, dev_images, dev_labels, test_images, test_labels = test_train_split(train_data)\n",
    "print(np.array(train_images).shape)\n",
    "\n",
    "#normalize the images\n",
    "train_images, dev_images, test_images = np.array(train_images) / 255.0, \\\n",
    "                                        np.array(dev_images) / 255.0, \\\n",
    "                                        np.array(test_images) / 255.0\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "train_images = tf.convert_to_tensor(train_images, dtype=tf.float32)\n",
    "train_labels = tf.convert_to_tensor(train_labels, dtype=tf.float32)\n",
    "test_images = tf.convert_to_tensor(test_images, dtype=tf.float32)\n",
    "test_labels = tf.convert_to_tensor(test_labels, dtype=tf.float32)\n",
    "\n",
    "input_shape = train_images.shape[1:]\n",
    "print(input_shape)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3491, 100, 177, 3)\n",
      "(3491, 100, 177, 3)\n",
      "(3491, 100, 177, 3)\n",
      "(3491, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data_images, test_data_labels, dev_data_images, dev_data_labels, last_data_images, last_data_labels = test_train_split(test_data)\n",
    "\n",
    "# train_images, train_labels = zip(*test_data)\n",
    "\n",
    "test_data_images = [np.array(Image.fromarray(img).convert('RGB')) for img in test_data_images]\n",
    "dev_data_images = [np.array(Image.fromarray(img).convert('RGB')) for img in dev_data_images]\n",
    "last_data_images = [np.array(Image.fromarray(img).convert('RGB')) for img in last_data_images]\n",
    "print(np.array(test_data_images).shape)\n",
    "\n",
    "test_data_images, dev_data_images, last_data_images = np.array(test_data_images) / 255.0, \\\n",
    "                                        np.array(dev_data_images) / 255.0, \\\n",
    "                                        np.array(last_data_images) / 255.0\n",
    "\n",
    "print(test_data_images.shape)                                       \n",
    "\n",
    "test_data_images = tf.convert_to_tensor(test_data_images, dtype=tf.float32)\n",
    "test_data_labels = tf.convert_to_tensor(test_data_labels, dtype=tf.float32)\n",
    "dev_data_images = tf.convert_to_tensor(dev_data_images, dtype=tf.float32)\n",
    "dev_data_labels = tf.convert_to_tensor(dev_data_labels, dtype=tf.float32)\n",
    "last_data_images = tf.convert_to_tensor(last_data_images, dtype=tf.float32)\n",
    "last_data_labels = tf.convert_to_tensor(last_data_labels, dtype=tf.float32)\n",
    "\n",
    "print(test_data_images.shape)\n",
    "print(test_data_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "#! rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'Nadam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 24s 467ms/step - loss: 0.8800 - accuracy: 0.5851 - f1_m: 0.6586 - precision_m: 0.5688 - recall_m: 0.8046 - val_loss: 0.5919 - val_accuracy: 0.6684 - val_f1_m: 0.6991 - val_precision_m: 0.5635 - val_recall_m: 0.9275\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 23s 470ms/step - loss: 0.6562 - accuracy: 0.6774 - f1_m: 0.6985 - precision_m: 0.5803 - recall_m: 0.9044 - val_loss: 0.4521 - val_accuracy: 0.7526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 22s 462ms/step - loss: 0.5016 - accuracy: 0.7672 - f1_m: 0.7066 - precision_m: 0.5674 - recall_m: 0.9495 - val_loss: 0.4188 - val_accuracy: 0.7947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.3984 - accuracy: 0.8331 - f1_m: 0.7150 - precision_m: 0.5714 - recall_m: 0.9651 - val_loss: 0.2932 - val_accuracy: 0.8737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.3492 - accuracy: 0.8542 - f1_m: 0.7184 - precision_m: 0.5718 - recall_m: 0.9825 - val_loss: 0.1752 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 22s 459ms/step - loss: 0.2711 - accuracy: 0.8879 - f1_m: 0.7213 - precision_m: 0.5715 - recall_m: 0.9879 - val_loss: 0.3085 - val_accuracy: 0.8632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 22s 452ms/step - loss: 0.2135 - accuracy: 0.9096 - f1_m: 0.7177 - precision_m: 0.5689 - recall_m: 0.9857 - val_loss: 0.1466 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.1979 - accuracy: 0.9222 - f1_m: 0.7137 - precision_m: 0.5660 - recall_m: 0.9793 - val_loss: 0.1102 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1765 - accuracy: 0.9347 - f1_m: 0.7205 - precision_m: 0.5713 - recall_m: 0.9892 - val_loss: 0.0694 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1900 - accuracy: 0.9274 - f1_m: 0.7185 - precision_m: 0.5678 - recall_m: 0.9900 - val_loss: 0.1180 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1391 - accuracy: 0.9551 - f1_m: 0.7204 - precision_m: 0.5693 - recall_m: 0.9922 - val_loss: 0.0595 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1183 - accuracy: 0.9545 - f1_m: 0.7175 - precision_m: 0.5671 - recall_m: 0.9916 - val_loss: 0.0864 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0789 - accuracy: 0.9697 - f1_m: 0.7192 - precision_m: 0.5676 - recall_m: 0.9955 - val_loss: 0.7976 - val_accuracy: 0.8316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1289 - accuracy: 0.9571 - f1_m: 0.7170 - precision_m: 0.5667 - recall_m: 0.9934 - val_loss: 0.2037 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1733 - accuracy: 0.9466 - f1_m: 0.7169 - precision_m: 0.5679 - recall_m: 0.9875 - val_loss: 0.0592 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0945 - accuracy: 0.9657 - f1_m: 0.7234 - precision_m: 0.5744 - recall_m: 0.9954 - val_loss: 0.0565 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0788 - accuracy: 0.9769 - f1_m: 0.7217 - precision_m: 0.5711 - recall_m: 0.9933 - val_loss: 0.0338 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0590 - accuracy: 0.9782 - f1_m: 0.7173 - precision_m: 0.5672 - recall_m: 0.9977 - val_loss: 0.0402 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0534 - accuracy: 0.9835 - f1_m: 0.7238 - precision_m: 0.5723 - recall_m: 0.9969 - val_loss: 0.0588 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0744 - accuracy: 0.9736 - f1_m: 0.7201 - precision_m: 0.5696 - recall_m: 0.9975 - val_loss: 0.0457 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0483 - accuracy: 0.9848 - f1_m: 0.7207 - precision_m: 0.5697 - recall_m: 0.9967 - val_loss: 1.3708 - val_accuracy: 0.7895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1050 - accuracy: 0.9697 - f1_m: 0.7252 - precision_m: 0.5746 - recall_m: 0.9970 - val_loss: 0.0388 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0423 - accuracy: 0.9908 - f1_m: 0.7200 - precision_m: 0.5676 - recall_m: 0.9955 - val_loss: 0.1122 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0595 - accuracy: 0.9802 - f1_m: 0.7206 - precision_m: 0.5687 - recall_m: 1.0000 - val_loss: 0.6261 - val_accuracy: 0.8632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0552 - accuracy: 0.9828 - f1_m: 0.7181 - precision_m: 0.5670 - recall_m: 0.9949 - val_loss: 0.0864 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.0461 - accuracy: 0.9848 - f1_m: 0.7209 - precision_m: 0.5691 - recall_m: 0.9992 - val_loss: 0.0541 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0710 - accuracy: 0.9749 - f1_m: 0.7252 - precision_m: 0.5733 - recall_m: 0.9990 - val_loss: 0.0102 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0438 - accuracy: 0.9861 - f1_m: 0.7176 - precision_m: 0.5665 - recall_m: 0.9943 - val_loss: 0.1269 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0431 - accuracy: 0.9868 - f1_m: 0.7243 - precision_m: 0.5753 - recall_m: 0.9979 - val_loss: 0.0446 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0514 - accuracy: 0.9802 - f1_m: 0.7233 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0355 - accuracy: 0.9848 - f1_m: 0.7211 - precision_m: 0.5693 - recall_m: 0.9966 - val_loss: 0.0476 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0386 - accuracy: 0.9861 - f1_m: 0.7183 - precision_m: 0.5681 - recall_m: 0.9975 - val_loss: 0.0800 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0891 - accuracy: 0.9749 - f1_m: 0.7200 - precision_m: 0.5682 - recall_m: 0.9942 - val_loss: 0.0401 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0956 - accuracy: 0.9743 - f1_m: 0.7208 - precision_m: 0.5690 - recall_m: 0.9945 - val_loss: 0.0163 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0394 - accuracy: 0.9875 - f1_m: 0.7171 - precision_m: 0.5660 - recall_m: 0.9964 - val_loss: 0.0222 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0415 - accuracy: 0.9881 - f1_m: 0.7222 - precision_m: 0.5698 - recall_m: 0.9976 - val_loss: 0.0136 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0422 - accuracy: 0.9861 - f1_m: 0.7195 - precision_m: 0.5698 - recall_m: 0.9955 - val_loss: 0.0302 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0342 - accuracy: 0.9921 - f1_m: 0.7218 - precision_m: 0.5700 - recall_m: 0.9976 - val_loss: 0.0266 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0609 - accuracy: 0.9809 - f1_m: 0.7167 - precision_m: 0.5662 - recall_m: 0.9986 - val_loss: 0.0146 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 22s 447ms/step - loss: 0.0380 - accuracy: 0.9881 - f1_m: 0.7189 - precision_m: 0.5671 - recall_m: 0.9952 - val_loss: 0.0346 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0333 - accuracy: 0.9894 - f1_m: 0.7240 - precision_m: 0.5745 - recall_m: 0.9970 - val_loss: 0.0779 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0666 - accuracy: 0.9828 - f1_m: 0.7171 - precision_m: 0.5650 - recall_m: 0.9980 - val_loss: 0.0423 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0414 - accuracy: 0.9848 - f1_m: 0.7235 - precision_m: 0.5731 - recall_m: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0523 - accuracy: 0.9848 - f1_m: 0.7193 - precision_m: 0.5678 - recall_m: 0.9958 - val_loss: 0.0303 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0313 - accuracy: 0.9927 - f1_m: 0.7182 - precision_m: 0.5670 - recall_m: 0.9972 - val_loss: 0.0074 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0310 - accuracy: 0.9901 - f1_m: 0.7188 - precision_m: 0.5664 - recall_m: 0.9979 - val_loss: 0.0124 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0435 - accuracy: 0.9875 - f1_m: 0.7260 - precision_m: 0.5742 - recall_m: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0175 - accuracy: 0.9954 - f1_m: 0.7224 - precision_m: 0.5718 - recall_m: 0.9991 - val_loss: 0.0191 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.0494 - accuracy: 0.9842 - f1_m: 0.7207 - precision_m: 0.5688 - recall_m: 0.9975 - val_loss: 0.0146 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0178 - accuracy: 0.9941 - f1_m: 0.7188 - precision_m: 0.5673 - recall_m: 0.9988 - val_loss: 0.0569 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 80ms/step - loss: 0.0569 - accuracy: 0.9789 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 21s 423ms/step - loss: 1.1828 - accuracy: 0.5303 - f1_m: 0.5802 - precision_m: 0.5528 - recall_m: 0.6628 - val_loss: 0.5513 - val_accuracy: 0.7158 - val_f1_m: 0.7320 - val_precision_m: 0.5786 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.8422 - accuracy: 0.6069 - f1_m: 0.6707 - precision_m: 0.5736 - recall_m: 0.8252 - val_loss: 0.4971 - val_accuracy: 0.7526 - val_f1_m: 0.7144 - val_precision_m: 0.5664 - val_recall_m: 0.9735\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.6654 - accuracy: 0.7170 - f1_m: 0.6978 - precision_m: 0.5848 - recall_m: 0.8794 - val_loss: 1.6919 - val_accuracy: 0.6053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.5653 - accuracy: 0.7698 - f1_m: 0.7125 - precision_m: 0.5843 - recall_m: 0.9275 - val_loss: 0.4177 - val_accuracy: 0.8105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.4416 - accuracy: 0.8146 - f1_m: 0.7091 - precision_m: 0.5751 - recall_m: 0.9362 - val_loss: 0.2419 - val_accuracy: 0.8737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.3272 - accuracy: 0.8766 - f1_m: 0.7111 - precision_m: 0.5689 - recall_m: 0.9656 - val_loss: 1.5756 - val_accuracy: 0.6947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.3139 - accuracy: 0.8852 - f1_m: 0.7125 - precision_m: 0.5682 - recall_m: 0.9726 - val_loss: 0.2836 - val_accuracy: 0.8579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.2450 - accuracy: 0.9057 - f1_m: 0.7184 - precision_m: 0.5703 - recall_m: 0.9820 - val_loss: 0.1340 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1979 - accuracy: 0.9235 - f1_m: 0.7177 - precision_m: 0.5691 - recall_m: 0.9875 - val_loss: 0.1997 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 20s 412ms/step - loss: 0.1985 - accuracy: 0.9222 - f1_m: 0.7197 - precision_m: 0.5687 - recall_m: 0.9909 - val_loss: 0.0719 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.1882 - accuracy: 0.9354 - f1_m: 0.7156 - precision_m: 0.5665 - recall_m: 0.9841 - val_loss: 0.1894 - val_accuracy: 0.9158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.2275 - accuracy: 0.9499 - f1_m: 0.7106 - precision_m: 0.5641 - recall_m: 0.9768 - val_loss: 0.1246 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.1785 - accuracy: 0.9538 - f1_m: 0.7176 - precision_m: 0.5681 - recall_m: 0.9879 - val_loss: 0.1760 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.1504 - accuracy: 0.9466 - f1_m: 0.7175 - precision_m: 0.5680 - recall_m: 0.9827 - val_loss: 0.0678 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1444 - accuracy: 0.9538 - f1_m: 0.7153 - precision_m: 0.5648 - recall_m: 0.9853 - val_loss: 0.0975 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.1041 - accuracy: 0.9611 - f1_m: 0.7152 - precision_m: 0.5676 - recall_m: 0.9866 - val_loss: 0.0656 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 20s 413ms/step - loss: 0.2455 - accuracy: 0.9512 - f1_m: 0.7160 - precision_m: 0.5676 - recall_m: 0.9870 - val_loss: 0.1895 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 20s 412ms/step - loss: 0.1194 - accuracy: 0.9611 - f1_m: 0.7159 - precision_m: 0.5680 - recall_m: 0.9825 - val_loss: 0.1198 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0934 - accuracy: 0.9703 - f1_m: 0.7157 - precision_m: 0.5663 - recall_m: 0.9853 - val_loss: 0.0935 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.1180 - accuracy: 0.9650 - f1_m: 0.7222 - precision_m: 0.5716 - recall_m: 0.9933 - val_loss: 0.1304 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1297 - accuracy: 0.9690 - f1_m: 0.7152 - precision_m: 0.5656 - recall_m: 0.9889 - val_loss: 0.0482 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0993 - accuracy: 0.9670 - f1_m: 0.7217 - precision_m: 0.5703 - recall_m: 0.9976 - val_loss: 0.0407 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1131 - accuracy: 0.9736 - f1_m: 0.7206 - precision_m: 0.5696 - recall_m: 0.9961 - val_loss: 0.1540 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.1817 - accuracy: 0.9763 - f1_m: 0.7226 - precision_m: 0.5711 - recall_m: 0.9977 - val_loss: 0.0812 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0910 - accuracy: 0.9743 - f1_m: 0.7224 - precision_m: 0.5730 - recall_m: 0.9916 - val_loss: 0.0704 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.1085 - accuracy: 0.9769 - f1_m: 0.7185 - precision_m: 0.5679 - recall_m: 0.9951 - val_loss: 0.0932 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.1116 - accuracy: 0.9703 - f1_m: 0.7213 - precision_m: 0.5707 - recall_m: 0.9974 - val_loss: 0.0968 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.1114 - accuracy: 0.9697 - f1_m: 0.7188 - precision_m: 0.5674 - recall_m: 0.9932 - val_loss: 0.0570 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0655 - accuracy: 0.9789 - f1_m: 0.7138 - precision_m: 0.5644 - recall_m: 0.9843 - val_loss: 0.0396 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 411ms/step - loss: 0.0913 - accuracy: 0.9782 - f1_m: 0.7164 - precision_m: 0.5657 - recall_m: 0.9881 - val_loss: 0.2287 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.0764 - accuracy: 0.9749 - f1_m: 0.7135 - precision_m: 0.5639 - recall_m: 0.9891 - val_loss: 1.0335 - val_accuracy: 0.9158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 33s 691ms/step - loss: 0.1625 - accuracy: 0.9782 - f1_m: 0.7185 - precision_m: 0.5691 - recall_m: 0.9880 - val_loss: 0.0658 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 25s 522ms/step - loss: 0.2020 - accuracy: 0.9730 - f1_m: 0.7178 - precision_m: 0.5675 - recall_m: 0.9955 - val_loss: 0.0545 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 23s 475ms/step - loss: 0.0563 - accuracy: 0.9802 - f1_m: 0.7195 - precision_m: 0.5692 - recall_m: 0.9925 - val_loss: 0.1132 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0975 - accuracy: 0.9776 - f1_m: 0.7191 - precision_m: 0.5700 - recall_m: 0.9943 - val_loss: 0.0769 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0971 - accuracy: 0.9769 - f1_m: 0.7121 - precision_m: 0.5636 - recall_m: 0.9877 - val_loss: 0.0231 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0781 - accuracy: 0.9796 - f1_m: 0.7127 - precision_m: 0.5640 - recall_m: 0.9864 - val_loss: 0.0249 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 22s 453ms/step - loss: 0.1641 - accuracy: 0.9670 - f1_m: 0.7199 - precision_m: 0.5692 - recall_m: 0.9913 - val_loss: 0.0644 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0515 - accuracy: 0.9842 - f1_m: 0.7182 - precision_m: 0.5667 - recall_m: 0.9891 - val_loss: 0.0802 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.3443 - accuracy: 0.9736 - f1_m: 0.7189 - precision_m: 0.5698 - recall_m: 0.9875 - val_loss: 0.0522 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0626 - accuracy: 0.9822 - f1_m: 0.7202 - precision_m: 0.5707 - recall_m: 0.9945 - val_loss: 0.0281 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0844 - accuracy: 0.9736 - f1_m: 0.7214 - precision_m: 0.5714 - recall_m: 0.9953 - val_loss: 0.0360 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.2101 - accuracy: 0.9697 - f1_m: 0.7153 - precision_m: 0.5666 - recall_m: 0.9825 - val_loss: 0.0430 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0654 - accuracy: 0.9842 - f1_m: 0.7135 - precision_m: 0.5661 - recall_m: 0.9828 - val_loss: 0.2345 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0780 - accuracy: 0.9776 - f1_m: 0.7197 - precision_m: 0.5688 - recall_m: 0.9929 - val_loss: 0.1438 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0919 - accuracy: 0.9835 - f1_m: 0.7187 - precision_m: 0.5678 - recall_m: 0.9891 - val_loss: 0.0250 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0517 - accuracy: 0.9842 - f1_m: 0.7195 - precision_m: 0.5707 - recall_m: 0.9878 - val_loss: 0.0620 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1410 - accuracy: 0.9769 - f1_m: 0.7182 - precision_m: 0.5684 - recall_m: 0.9879 - val_loss: 0.0269 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0804 - accuracy: 0.9796 - f1_m: 0.7112 - precision_m: 0.5643 - recall_m: 0.9855 - val_loss: 0.0279 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0666 - accuracy: 0.9828 - f1_m: 0.7159 - precision_m: 0.5657 - recall_m: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 78ms/step - loss: 0.0410 - accuracy: 0.9842 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 1.0375 - accuracy: 0.5363 - f1_m: 0.6256 - precision_m: 0.5821 - recall_m: 0.7064 - val_loss: 0.5854 - val_accuracy: 0.7316 - val_f1_m: 0.7130 - val_precision_m: 0.5751 - val_recall_m: 0.9443\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.7436 - accuracy: 0.6306 - f1_m: 0.6979 - precision_m: 0.5879 - recall_m: 0.8788 - val_loss: 0.4736 - val_accuracy: 0.7737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.6015 - accuracy: 0.6913 - f1_m: 0.7085 - precision_m: 0.5739 - recall_m: 0.9362 - val_loss: 0.4244 - val_accuracy: 0.8053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.4476 - accuracy: 0.7896 - f1_m: 0.7107 - precision_m: 0.5683 - recall_m: 0.9684 - val_loss: 0.2872 - val_accuracy: 0.8947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.3055 - accuracy: 0.8753 - f1_m: 0.7159 - precision_m: 0.5692 - recall_m: 0.9782 - val_loss: 0.1997 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.2455 - accuracy: 0.8978 - f1_m: 0.7193 - precision_m: 0.5688 - recall_m: 0.9885 - val_loss: 0.1612 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1719 - accuracy: 0.9327 - f1_m: 0.7215 - precision_m: 0.5736 - recall_m: 0.9889 - val_loss: 0.2626 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1712 - accuracy: 0.9321 - f1_m: 0.7182 - precision_m: 0.5694 - recall_m: 0.9890 - val_loss: 0.2174 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1483 - accuracy: 0.9545 - f1_m: 0.7175 - precision_m: 0.5679 - recall_m: 0.9923 - val_loss: 0.1261 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.3073 - accuracy: 0.8931 - f1_m: 0.7152 - precision_m: 0.5678 - recall_m: 0.9784 - val_loss: 0.1655 - val_accuracy: 0.9579 - val_f1_m: 0.7295 - val_precision_m: 0.5763 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.1509 - accuracy: 0.9479 - f1_m: 0.7219 - precision_m: 0.5718 - recall_m: 0.9927 - val_loss: 0.1080 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1929 - accuracy: 0.9228 - f1_m: 0.7220 - precision_m: 0.5721 - recall_m: 0.9965 - val_loss: 0.2638 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1569 - accuracy: 0.9400 - f1_m: 0.7218 - precision_m: 0.5705 - recall_m: 0.9949 - val_loss: 0.1811 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.1024 - accuracy: 0.9631 - f1_m: 0.7210 - precision_m: 0.5689 - recall_m: 0.9955 - val_loss: 0.0451 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1024 - accuracy: 0.9611 - f1_m: 0.7208 - precision_m: 0.5696 - recall_m: 0.9976 - val_loss: 0.2013 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1117 - accuracy: 0.9624 - f1_m: 0.7237 - precision_m: 0.5730 - recall_m: 0.9966 - val_loss: 0.0752 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1044 - accuracy: 0.9677 - f1_m: 0.7190 - precision_m: 0.5678 - recall_m: 0.9932 - val_loss: 0.0819 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0806 - accuracy: 0.9710 - f1_m: 0.7193 - precision_m: 0.5683 - recall_m: 0.9979 - val_loss: 0.0515 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0680 - accuracy: 0.9815 - f1_m: 0.7207 - precision_m: 0.5717 - recall_m: 0.9959 - val_loss: 0.0540 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0533 - accuracy: 0.9822 - f1_m: 0.7223 - precision_m: 0.5709 - recall_m: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0911 - accuracy: 0.9736 - f1_m: 0.7256 - precision_m: 0.5757 - recall_m: 0.9978 - val_loss: 0.0986 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0975 - accuracy: 0.9690 - f1_m: 0.7227 - precision_m: 0.5720 - recall_m: 0.9968 - val_loss: 0.0524 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0910 - accuracy: 0.9716 - f1_m: 0.7200 - precision_m: 0.5697 - recall_m: 0.9937 - val_loss: 0.1935 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0432 - accuracy: 0.9881 - f1_m: 0.7213 - precision_m: 0.5719 - recall_m: 0.9963 - val_loss: 0.0287 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1085 - accuracy: 0.9611 - f1_m: 0.7221 - precision_m: 0.5727 - recall_m: 0.9956 - val_loss: 0.0778 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.1016 - accuracy: 0.9677 - f1_m: 0.7222 - precision_m: 0.5707 - recall_m: 0.9942 - val_loss: 0.0838 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0748 - accuracy: 0.9756 - f1_m: 0.7187 - precision_m: 0.5679 - recall_m: 0.9931 - val_loss: 0.1679 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0532 - accuracy: 0.9809 - f1_m: 0.7192 - precision_m: 0.5675 - recall_m: 0.9980 - val_loss: 0.0449 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0658 - accuracy: 0.9763 - f1_m: 0.7220 - precision_m: 0.5724 - recall_m: 0.9969 - val_loss: 0.3635 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0623 - accuracy: 0.9809 - f1_m: 0.7230 - precision_m: 0.5718 - recall_m: 0.9977 - val_loss: 0.1068 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0694 - accuracy: 0.9828 - f1_m: 0.7231 - precision_m: 0.5715 - recall_m: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0576 - accuracy: 0.9782 - f1_m: 0.7222 - precision_m: 0.5722 - recall_m: 0.9985 - val_loss: 0.1356 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0330 - accuracy: 0.9888 - f1_m: 0.7211 - precision_m: 0.5694 - recall_m: 0.9990 - val_loss: 0.2743 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0571 - accuracy: 0.9815 - f1_m: 0.7241 - precision_m: 0.5730 - recall_m: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0620 - accuracy: 0.9802 - f1_m: 0.7226 - precision_m: 0.5696 - recall_m: 0.9989 - val_loss: 0.1717 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0434 - accuracy: 0.9875 - f1_m: 0.7197 - precision_m: 0.5699 - recall_m: 0.9980 - val_loss: 0.0507 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0364 - accuracy: 0.9881 - f1_m: 0.7201 - precision_m: 0.5710 - recall_m: 0.9952 - val_loss: 0.0880 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0524 - accuracy: 0.9835 - f1_m: 0.7217 - precision_m: 0.5699 - recall_m: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0610 - accuracy: 0.9809 - f1_m: 0.7218 - precision_m: 0.5688 - recall_m: 0.9958 - val_loss: 0.0895 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0587 - accuracy: 0.9815 - f1_m: 0.7242 - precision_m: 0.5719 - recall_m: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0547 - accuracy: 0.9802 - f1_m: 0.7238 - precision_m: 0.5720 - recall_m: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0341 - accuracy: 0.9901 - f1_m: 0.7228 - precision_m: 0.5706 - recall_m: 0.9985 - val_loss: 0.0681 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0367 - accuracy: 0.9868 - f1_m: 0.7232 - precision_m: 0.5726 - recall_m: 0.9958 - val_loss: 0.5393 - val_accuracy: 0.9105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0340 - accuracy: 0.9894 - f1_m: 0.7224 - precision_m: 0.5717 - recall_m: 0.9988 - val_loss: 0.0098 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0368 - accuracy: 0.9881 - f1_m: 0.7220 - precision_m: 0.5709 - recall_m: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0340 - accuracy: 0.9875 - f1_m: 0.7255 - precision_m: 0.5733 - recall_m: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0273 - accuracy: 0.9921 - f1_m: 0.7207 - precision_m: 0.5689 - recall_m: 0.9988 - val_loss: 0.0411 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0307 - accuracy: 0.9894 - f1_m: 0.7224 - precision_m: 0.5703 - recall_m: 0.9971 - val_loss: 0.0341 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0466 - accuracy: 0.9842 - f1_m: 0.7217 - precision_m: 0.5690 - recall_m: 0.9965 - val_loss: 0.3460 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0735 - accuracy: 0.9756 - f1_m: 0.7215 - precision_m: 0.5711 - recall_m: 0.9938 - val_loss: 0.0455 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.0455 - accuracy: 0.9737 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'Nadam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 22s 435ms/step - loss: 1.0660 - accuracy: 0.5369 - f1_m: 0.6226 - precision_m: 0.5821 - recall_m: 0.6912 - val_loss: 0.5755 - val_accuracy: 0.6789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.7567 - accuracy: 0.6372 - f1_m: 0.6909 - precision_m: 0.5892 - recall_m: 0.8570 - val_loss: 0.5557 - val_accuracy: 0.6053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.6703 - accuracy: 0.7045 - f1_m: 0.7065 - precision_m: 0.5849 - recall_m: 0.9094 - val_loss: 0.5011 - val_accuracy: 0.6842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.5742 - accuracy: 0.7559 - f1_m: 0.7102 - precision_m: 0.5802 - recall_m: 0.9402 - val_loss: 0.3641 - val_accuracy: 0.8421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.4560 - accuracy: 0.8160 - f1_m: 0.7224 - precision_m: 0.5819 - recall_m: 0.9639 - val_loss: 0.6308 - val_accuracy: 0.7105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.3764 - accuracy: 0.8437 - f1_m: 0.7234 - precision_m: 0.5821 - recall_m: 0.9698 - val_loss: 0.7015 - val_accuracy: 0.7158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.2977 - accuracy: 0.8806 - f1_m: 0.7292 - precision_m: 0.5871 - recall_m: 0.9765 - val_loss: 0.2301 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.3832 - accuracy: 0.8575 - f1_m: 0.7249 - precision_m: 0.5794 - recall_m: 0.9795 - val_loss: 0.1647 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.3019 - accuracy: 0.8925 - f1_m: 0.7170 - precision_m: 0.5744 - recall_m: 0.9678 - val_loss: 0.1963 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.2581 - accuracy: 0.8997 - f1_m: 0.7169 - precision_m: 0.5773 - recall_m: 0.9658 - val_loss: 0.0817 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.4287 - accuracy: 0.8555 - f1_m: 0.7126 - precision_m: 0.5737 - recall_m: 0.9561 - val_loss: 0.1613 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.2347 - accuracy: 0.9017 - f1_m: 0.7113 - precision_m: 0.5706 - recall_m: 0.9586 - val_loss: 0.5440 - val_accuracy: 0.8895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.2573 - accuracy: 0.9103 - f1_m: 0.7145 - precision_m: 0.5733 - recall_m: 0.9709 - val_loss: 0.1333 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1840 - accuracy: 0.9222 - f1_m: 0.7144 - precision_m: 0.5700 - recall_m: 0.9716 - val_loss: 0.1784 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1812 - accuracy: 0.9268 - f1_m: 0.7130 - precision_m: 0.5715 - recall_m: 0.9792 - val_loss: 0.1182 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1884 - accuracy: 0.9261 - f1_m: 0.7091 - precision_m: 0.5682 - recall_m: 0.9557 - val_loss: 0.0546 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1833 - accuracy: 0.9208 - f1_m: 0.7160 - precision_m: 0.5736 - recall_m: 0.9691 - val_loss: 0.0494 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1912 - accuracy: 0.9241 - f1_m: 0.7149 - precision_m: 0.5733 - recall_m: 0.9670 - val_loss: 0.0985 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1750 - accuracy: 0.9294 - f1_m: 0.7164 - precision_m: 0.5724 - recall_m: 0.9732 - val_loss: 0.0715 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1623 - accuracy: 0.9314 - f1_m: 0.7141 - precision_m: 0.5711 - recall_m: 0.9720 - val_loss: 0.2077 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1559 - accuracy: 0.9307 - f1_m: 0.7169 - precision_m: 0.5707 - recall_m: 0.9743 - val_loss: 0.0687 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1340 - accuracy: 0.9466 - f1_m: 0.7174 - precision_m: 0.5705 - recall_m: 0.9774 - val_loss: 0.1109 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.1196 - accuracy: 0.9571 - f1_m: 0.7190 - precision_m: 0.5724 - recall_m: 0.9795 - val_loss: 0.0613 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1253 - accuracy: 0.9518 - f1_m: 0.7231 - precision_m: 0.5756 - recall_m: 0.9850 - val_loss: 0.0550 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1190 - accuracy: 0.9505 - f1_m: 0.7223 - precision_m: 0.5765 - recall_m: 0.9820 - val_loss: 0.0604 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1206 - accuracy: 0.9598 - f1_m: 0.7241 - precision_m: 0.5751 - recall_m: 0.9850 - val_loss: 0.0673 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.3844 - accuracy: 0.9037 - f1_m: 0.7252 - precision_m: 0.5822 - recall_m: 0.9762 - val_loss: 0.6717 - val_accuracy: 0.7368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.2831 - accuracy: 0.8819 - f1_m: 0.7140 - precision_m: 0.5714 - recall_m: 0.9652 - val_loss: 0.2979 - val_accuracy: 0.8947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1665 - accuracy: 0.9393 - f1_m: 0.7198 - precision_m: 0.5728 - recall_m: 0.9841 - val_loss: 0.0605 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1313 - accuracy: 0.9453 - f1_m: 0.7233 - precision_m: 0.5771 - recall_m: 0.9833 - val_loss: 0.0424 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1307 - accuracy: 0.9505 - f1_m: 0.7096 - precision_m: 0.5661 - recall_m: 0.9706 - val_loss: 0.1815 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1232 - accuracy: 0.9499 - f1_m: 0.7161 - precision_m: 0.5694 - recall_m: 0.9823 - val_loss: 0.2384 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1147 - accuracy: 0.9584 - f1_m: 0.7246 - precision_m: 0.5773 - recall_m: 0.9877 - val_loss: 0.0604 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.1213 - accuracy: 0.9525 - f1_m: 0.7243 - precision_m: 0.5766 - recall_m: 0.9876 - val_loss: 0.0605 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1380 - accuracy: 0.9512 - f1_m: 0.7195 - precision_m: 0.5739 - recall_m: 0.9780 - val_loss: 0.0368 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.1382 - accuracy: 0.9485 - f1_m: 0.7160 - precision_m: 0.5713 - recall_m: 0.9731 - val_loss: 0.0564 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.1211 - accuracy: 0.9479 - f1_m: 0.7171 - precision_m: 0.5734 - recall_m: 0.9705 - val_loss: 0.1915 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1028 - accuracy: 0.9617 - f1_m: 0.7165 - precision_m: 0.5705 - recall_m: 0.9791 - val_loss: 0.0689 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1291 - accuracy: 0.9565 - f1_m: 0.7157 - precision_m: 0.5742 - recall_m: 0.9657 - val_loss: 0.1808 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0771 - accuracy: 0.9683 - f1_m: 0.7166 - precision_m: 0.5727 - recall_m: 0.9753 - val_loss: 0.2181 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0988 - accuracy: 0.9571 - f1_m: 0.7193 - precision_m: 0.5748 - recall_m: 0.9764 - val_loss: 0.0693 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1242 - accuracy: 0.9532 - f1_m: 0.7134 - precision_m: 0.5741 - recall_m: 0.9669 - val_loss: 0.0407 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0998 - accuracy: 0.9617 - f1_m: 0.7191 - precision_m: 0.5724 - recall_m: 0.9791 - val_loss: 0.0237 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1144 - accuracy: 0.9551 - f1_m: 0.7111 - precision_m: 0.5702 - recall_m: 0.9664 - val_loss: 0.0956 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1726 - accuracy: 0.9380 - f1_m: 0.7136 - precision_m: 0.5703 - recall_m: 0.9677 - val_loss: 0.0518 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.1027 - accuracy: 0.9657 - f1_m: 0.7163 - precision_m: 0.5765 - recall_m: 0.9634 - val_loss: 0.0326 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0871 - accuracy: 0.9637 - f1_m: 0.7138 - precision_m: 0.5748 - recall_m: 0.9712 - val_loss: 0.0619 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1107 - accuracy: 0.9525 - f1_m: 0.7136 - precision_m: 0.5723 - recall_m: 0.9642 - val_loss: 0.0921 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.0876 - accuracy: 0.9611 - f1_m: 0.7138 - precision_m: 0.5706 - recall_m: 0.9657 - val_loss: 0.0809 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0801 - accuracy: 0.9723 - f1_m: 0.7247 - precision_m: 0.5781 - recall_m: 0.9826 - val_loss: 0.0352 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 79ms/step - loss: 0.0352 - accuracy: 0.9842 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 23s 446ms/step - loss: 1.1424 - accuracy: 0.5290 - f1_m: 0.5903 - precision_m: 0.5594 - recall_m: 0.6593 - val_loss: 0.6195 - val_accuracy: 0.6842 - val_f1_m: 0.7456 - val_precision_m: 0.6159 - val_recall_m: 0.9526\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.8201 - accuracy: 0.6365 - f1_m: 0.6960 - precision_m: 0.6083 - recall_m: 0.8325 - val_loss: 0.4141 - val_accuracy: 0.7684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.6502 - accuracy: 0.7183 - f1_m: 0.7132 - precision_m: 0.5912 - recall_m: 0.9176 - val_loss: 0.4461 - val_accuracy: 0.7947 - val_f1_m: 0.7230 - val_precision_m: 0.5709 - val_recall_m: 0.9917\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.4994 - accuracy: 0.7803 - f1_m: 0.7085 - precision_m: 0.5751 - recall_m: 0.9399 - val_loss: 0.3148 - val_accuracy: 0.8842 - val_f1_m: 0.7230 - val_precision_m: 0.5709 - val_recall_m: 0.9917\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 428ms/step - loss: 0.3990 - accuracy: 0.8384 - f1_m: 0.7135 - precision_m: 0.5717 - recall_m: 0.9626 - val_loss: 0.2067 - val_accuracy: 0.9158 - val_f1_m: 0.7295 - val_precision_m: 0.5763 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.3353 - accuracy: 0.8575 - f1_m: 0.7180 - precision_m: 0.5753 - recall_m: 0.9689 - val_loss: 0.1661 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.2569 - accuracy: 0.9011 - f1_m: 0.7194 - precision_m: 0.5720 - recall_m: 0.9831 - val_loss: 0.1515 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.2966 - accuracy: 0.9017 - f1_m: 0.7204 - precision_m: 0.5714 - recall_m: 0.9883 - val_loss: 0.1862 - val_accuracy: 0.9158 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1929 - accuracy: 0.9228 - f1_m: 0.7253 - precision_m: 0.5778 - recall_m: 0.9909 - val_loss: 0.0943 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.2288 - accuracy: 0.9248 - f1_m: 0.7220 - precision_m: 0.5720 - recall_m: 0.9866 - val_loss: 0.1401 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.2093 - accuracy: 0.9354 - f1_m: 0.7255 - precision_m: 0.5744 - recall_m: 0.9935 - val_loss: 0.5326 - val_accuracy: 0.8526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1649 - accuracy: 0.9446 - f1_m: 0.7222 - precision_m: 0.5721 - recall_m: 0.9934 - val_loss: 0.1207 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1762 - accuracy: 0.9459 - f1_m: 0.7231 - precision_m: 0.5710 - recall_m: 0.9974 - val_loss: 0.1788 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.1504 - accuracy: 0.9525 - f1_m: 0.7246 - precision_m: 0.5737 - recall_m: 0.9942 - val_loss: 0.0940 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1310 - accuracy: 0.9578 - f1_m: 0.7209 - precision_m: 0.5718 - recall_m: 0.9932 - val_loss: 0.1458 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1820 - accuracy: 0.9499 - f1_m: 0.7202 - precision_m: 0.5717 - recall_m: 0.9914 - val_loss: 0.1273 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1638 - accuracy: 0.9538 - f1_m: 0.7248 - precision_m: 0.5735 - recall_m: 0.9931 - val_loss: 0.0765 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1158 - accuracy: 0.9624 - f1_m: 0.7168 - precision_m: 0.5686 - recall_m: 0.9887 - val_loss: 0.3790 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.2162 - accuracy: 0.9525 - f1_m: 0.7236 - precision_m: 0.5741 - recall_m: 0.9931 - val_loss: 0.0791 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1315 - accuracy: 0.9571 - f1_m: 0.7216 - precision_m: 0.5709 - recall_m: 0.9932 - val_loss: 0.0501 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1654 - accuracy: 0.9485 - f1_m: 0.7235 - precision_m: 0.5729 - recall_m: 0.9945 - val_loss: 0.0644 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1564 - accuracy: 0.9598 - f1_m: 0.7209 - precision_m: 0.5724 - recall_m: 0.9871 - val_loss: 0.0470 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1019 - accuracy: 0.9697 - f1_m: 0.7213 - precision_m: 0.5709 - recall_m: 0.9944 - val_loss: 0.0872 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.1767 - accuracy: 0.9591 - f1_m: 0.7179 - precision_m: 0.5698 - recall_m: 0.9882 - val_loss: 0.1262 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.0940 - accuracy: 0.9730 - f1_m: 0.7212 - precision_m: 0.5704 - recall_m: 0.9884 - val_loss: 1.9087 - val_accuracy: 0.7526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1340 - accuracy: 0.9650 - f1_m: 0.7192 - precision_m: 0.5709 - recall_m: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1371 - accuracy: 0.9624 - f1_m: 0.7209 - precision_m: 0.5708 - recall_m: 0.9925 - val_loss: 0.4484 - val_accuracy: 0.9105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0952 - accuracy: 0.9736 - f1_m: 0.7176 - precision_m: 0.5675 - recall_m: 0.9893 - val_loss: 0.2098 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1134 - accuracy: 0.9670 - f1_m: 0.7203 - precision_m: 0.5719 - recall_m: 0.9855 - val_loss: 0.2689 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1094 - accuracy: 0.9683 - f1_m: 0.7199 - precision_m: 0.5703 - recall_m: 0.9920 - val_loss: 0.0477 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.1071 - accuracy: 0.9736 - f1_m: 0.7179 - precision_m: 0.5685 - recall_m: 0.9896 - val_loss: 0.1091 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0968 - accuracy: 0.9782 - f1_m: 0.7203 - precision_m: 0.5718 - recall_m: 0.9878 - val_loss: 0.0629 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1098 - accuracy: 0.9723 - f1_m: 0.7162 - precision_m: 0.5672 - recall_m: 0.9902 - val_loss: 0.0462 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0978 - accuracy: 0.9697 - f1_m: 0.7237 - precision_m: 0.5743 - recall_m: 0.9918 - val_loss: 0.0899 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1027 - accuracy: 0.9736 - f1_m: 0.7286 - precision_m: 0.5774 - recall_m: 0.9984 - val_loss: 0.0516 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0937 - accuracy: 0.9730 - f1_m: 0.7177 - precision_m: 0.5679 - recall_m: 0.9903 - val_loss: 0.0490 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0821 - accuracy: 0.9789 - f1_m: 0.7240 - precision_m: 0.5746 - recall_m: 0.9980 - val_loss: 0.2485 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1144 - accuracy: 0.9743 - f1_m: 0.7236 - precision_m: 0.5725 - recall_m: 0.9959 - val_loss: 0.2990 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0888 - accuracy: 0.9716 - f1_m: 0.7208 - precision_m: 0.5707 - recall_m: 0.9933 - val_loss: 0.0619 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.1018 - accuracy: 0.9782 - f1_m: 0.7244 - precision_m: 0.5746 - recall_m: 0.9937 - val_loss: 0.0256 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0856 - accuracy: 0.9769 - f1_m: 0.7214 - precision_m: 0.5727 - recall_m: 0.9915 - val_loss: 0.2675 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1900 - accuracy: 0.9703 - f1_m: 0.7172 - precision_m: 0.5672 - recall_m: 0.9920 - val_loss: 0.0378 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0595 - accuracy: 0.9809 - f1_m: 0.7213 - precision_m: 0.5707 - recall_m: 0.9930 - val_loss: 0.0195 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0930 - accuracy: 0.9776 - f1_m: 0.7234 - precision_m: 0.5726 - recall_m: 0.9941 - val_loss: 0.0511 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0544 - accuracy: 0.9848 - f1_m: 0.7157 - precision_m: 0.5659 - recall_m: 0.9902 - val_loss: 0.2970 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1050 - accuracy: 0.9763 - f1_m: 0.7250 - precision_m: 0.5769 - recall_m: 0.9939 - val_loss: 0.0085 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0652 - accuracy: 0.9822 - f1_m: 0.7207 - precision_m: 0.5705 - recall_m: 0.9927 - val_loss: 0.0386 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.1032 - accuracy: 0.9763 - f1_m: 0.7211 - precision_m: 0.5715 - recall_m: 0.9863 - val_loss: 0.0767 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.1609 - accuracy: 0.9710 - f1_m: 0.7208 - precision_m: 0.5716 - recall_m: 0.9919 - val_loss: 0.0397 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1078 - accuracy: 0.9776 - f1_m: 0.7195 - precision_m: 0.5682 - recall_m: 0.9931 - val_loss: 0.0351 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 0.0351 - accuracy: 0.9842 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.5, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 22s 444ms/step - loss: 1.1619 - accuracy: 0.4512 - f1_m: 0.5664 - precision_m: 0.5807 - recall_m: 0.5941 - val_loss: 0.6047 - val_accuracy: 0.6316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.8180 - accuracy: 0.5930 - f1_m: 0.6593 - precision_m: 0.5718 - recall_m: 0.7999 - val_loss: 0.4729 - val_accuracy: 0.7895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.7178 - accuracy: 0.6425 - f1_m: 0.6783 - precision_m: 0.5635 - recall_m: 0.8691 - val_loss: 0.4768 - val_accuracy: 0.7632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.6395 - accuracy: 0.6920 - f1_m: 0.6949 - precision_m: 0.5668 - recall_m: 0.9119 - val_loss: 0.3911 - val_accuracy: 0.8263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.5967 - accuracy: 0.7131 - f1_m: 0.7016 - precision_m: 0.5714 - recall_m: 0.9216 - val_loss: 0.3739 - val_accuracy: 0.8263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.5039 - accuracy: 0.7480 - f1_m: 0.7115 - precision_m: 0.5713 - recall_m: 0.9573 - val_loss: 0.2898 - val_accuracy: 0.8789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.5041 - accuracy: 0.7672 - f1_m: 0.7078 - precision_m: 0.5765 - recall_m: 0.9369 - val_loss: 0.2405 - val_accuracy: 0.8842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.4137 - accuracy: 0.8034 - f1_m: 0.7108 - precision_m: 0.5708 - recall_m: 0.9572 - val_loss: 0.2130 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.3568 - accuracy: 0.8470 - f1_m: 0.7139 - precision_m: 0.5728 - recall_m: 0.9674 - val_loss: 0.2241 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 20s 428ms/step - loss: 0.3235 - accuracy: 0.8621 - f1_m: 0.7072 - precision_m: 0.5650 - recall_m: 0.9602 - val_loss: 0.1212 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.4223 - accuracy: 0.8067 - f1_m: 0.7119 - precision_m: 0.5740 - recall_m: 0.9514 - val_loss: 0.1920 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.2271 - accuracy: 0.9090 - f1_m: 0.7158 - precision_m: 0.5702 - recall_m: 0.9799 - val_loss: 0.1878 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.2187 - accuracy: 0.9109 - f1_m: 0.7129 - precision_m: 0.5684 - recall_m: 0.9710 - val_loss: 0.0784 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.2256 - accuracy: 0.8931 - f1_m: 0.7230 - precision_m: 0.5794 - recall_m: 0.9827 - val_loss: 0.0659 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1614 - accuracy: 0.9261 - f1_m: 0.7232 - precision_m: 0.5742 - recall_m: 0.9863 - val_loss: 0.2141 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1288 - accuracy: 0.9393 - f1_m: 0.7180 - precision_m: 0.5695 - recall_m: 0.9869 - val_loss: 0.0631 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1382 - accuracy: 0.9393 - f1_m: 0.7228 - precision_m: 0.5745 - recall_m: 0.9912 - val_loss: 0.1108 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1420 - accuracy: 0.9479 - f1_m: 0.7215 - precision_m: 0.5737 - recall_m: 0.9891 - val_loss: 0.1238 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1457 - accuracy: 0.9426 - f1_m: 0.7253 - precision_m: 0.5794 - recall_m: 0.9907 - val_loss: 0.1677 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1322 - accuracy: 0.9453 - f1_m: 0.7170 - precision_m: 0.5703 - recall_m: 0.9824 - val_loss: 0.1039 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.1295 - accuracy: 0.9466 - f1_m: 0.7246 - precision_m: 0.5768 - recall_m: 0.9887 - val_loss: 0.0223 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.1355 - accuracy: 0.9472 - f1_m: 0.7229 - precision_m: 0.5745 - recall_m: 0.9904 - val_loss: 0.1299 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.1477 - accuracy: 0.9472 - f1_m: 0.7234 - precision_m: 0.5776 - recall_m: 0.9856 - val_loss: 0.0797 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1070 - accuracy: 0.9532 - f1_m: 0.7231 - precision_m: 0.5750 - recall_m: 0.9924 - val_loss: 0.1318 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0958 - accuracy: 0.9664 - f1_m: 0.7186 - precision_m: 0.5697 - recall_m: 0.9938 - val_loss: 0.2151 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.1461 - accuracy: 0.9393 - f1_m: 0.7263 - precision_m: 0.5774 - recall_m: 0.9907 - val_loss: 0.1243 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1107 - accuracy: 0.9578 - f1_m: 0.7209 - precision_m: 0.5718 - recall_m: 0.9906 - val_loss: 0.0326 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1463 - accuracy: 0.9472 - f1_m: 0.7239 - precision_m: 0.5769 - recall_m: 0.9874 - val_loss: 0.0514 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.1079 - accuracy: 0.9598 - f1_m: 0.7244 - precision_m: 0.5774 - recall_m: 0.9901 - val_loss: 0.0484 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1007 - accuracy: 0.9565 - f1_m: 0.7217 - precision_m: 0.5706 - recall_m: 0.9923 - val_loss: 0.0648 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1093 - accuracy: 0.9617 - f1_m: 0.7260 - precision_m: 0.5758 - recall_m: 0.9929 - val_loss: 0.0361 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0958 - accuracy: 0.9584 - f1_m: 0.7194 - precision_m: 0.5705 - recall_m: 0.9894 - val_loss: 0.0917 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1082 - accuracy: 0.9571 - f1_m: 0.7181 - precision_m: 0.5686 - recall_m: 0.9864 - val_loss: 0.0438 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0856 - accuracy: 0.9743 - f1_m: 0.7245 - precision_m: 0.5766 - recall_m: 0.9960 - val_loss: 0.0691 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0733 - accuracy: 0.9730 - f1_m: 0.7095 - precision_m: 0.5643 - recall_m: 0.9737 - val_loss: 0.0648 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.1259 - accuracy: 0.9624 - f1_m: 0.7229 - precision_m: 0.5738 - recall_m: 0.9943 - val_loss: 0.1034 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0821 - accuracy: 0.9683 - f1_m: 0.7219 - precision_m: 0.5740 - recall_m: 0.9864 - val_loss: 0.0659 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0904 - accuracy: 0.9703 - f1_m: 0.7199 - precision_m: 0.5696 - recall_m: 0.9944 - val_loss: 0.0299 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0905 - accuracy: 0.9683 - f1_m: 0.7269 - precision_m: 0.5773 - recall_m: 0.9975 - val_loss: 0.0464 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 427ms/step - loss: 0.0959 - accuracy: 0.9703 - f1_m: 0.7218 - precision_m: 0.5721 - recall_m: 0.9913 - val_loss: 0.0882 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0811 - accuracy: 0.9710 - f1_m: 0.7231 - precision_m: 0.5733 - recall_m: 0.9942 - val_loss: 0.2209 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0722 - accuracy: 0.9763 - f1_m: 0.7175 - precision_m: 0.5689 - recall_m: 0.9957 - val_loss: 0.2176 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0603 - accuracy: 0.9802 - f1_m: 0.7213 - precision_m: 0.5731 - recall_m: 0.9908 - val_loss: 0.3779 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0983 - accuracy: 0.9697 - f1_m: 0.7240 - precision_m: 0.5739 - recall_m: 0.9941 - val_loss: 0.0762 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0568 - accuracy: 0.9763 - f1_m: 0.7236 - precision_m: 0.5735 - recall_m: 0.9955 - val_loss: 0.2183 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0825 - accuracy: 0.9690 - f1_m: 0.7229 - precision_m: 0.5726 - recall_m: 0.9920 - val_loss: 0.0855 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0577 - accuracy: 0.9855 - f1_m: 0.7243 - precision_m: 0.5748 - recall_m: 0.9919 - val_loss: 0.0534 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0828 - accuracy: 0.9736 - f1_m: 0.7180 - precision_m: 0.5699 - recall_m: 0.9948 - val_loss: 0.0443 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0877 - accuracy: 0.9743 - f1_m: 0.7269 - precision_m: 0.5788 - recall_m: 0.9931 - val_loss: 0.0437 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0914 - accuracy: 0.9730 - f1_m: 0.7102 - precision_m: 0.5633 - recall_m: 0.9786 - val_loss: 0.1200 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 79ms/step - loss: 0.1200 - accuracy: 0.9526 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 64, 'dropout': 0.4, 'optimizer': 'Nadam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 25s 483ms/step - loss: 0.8180 - accuracy: 0.6201 - f1_m: 0.6951 - precision_m: 0.5751 - recall_m: 0.8922 - val_loss: 0.4947 - val_accuracy: 0.7526 - val_f1_m: 0.7144 - val_precision_m: 0.5664 - val_recall_m: 0.9735\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 22s 461ms/step - loss: 0.5510 - accuracy: 0.7302 - f1_m: 0.7199 - precision_m: 0.5751 - recall_m: 0.9800 - val_loss: 0.3713 - val_accuracy: 0.8263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 22s 462ms/step - loss: 0.4760 - accuracy: 0.7863 - f1_m: 0.7182 - precision_m: 0.5689 - recall_m: 0.9836 - val_loss: 0.3068 - val_accuracy: 0.8737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.3325 - accuracy: 0.8668 - f1_m: 0.7210 - precision_m: 0.5703 - recall_m: 0.9944 - val_loss: 0.6757 - val_accuracy: 0.7632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.2989 - accuracy: 0.8865 - f1_m: 0.7229 - precision_m: 0.5729 - recall_m: 0.9937 - val_loss: 0.4777 - val_accuracy: 0.7842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.1971 - accuracy: 0.9314 - f1_m: 0.7218 - precision_m: 0.5692 - recall_m: 0.9981 - val_loss: 0.0871 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 22s 462ms/step - loss: 0.1201 - accuracy: 0.9518 - f1_m: 0.7218 - precision_m: 0.5687 - recall_m: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.2119 - accuracy: 0.9413 - f1_m: 0.7218 - precision_m: 0.5684 - recall_m: 0.9979 - val_loss: 0.0933 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.1825 - accuracy: 0.9413 - f1_m: 0.7180 - precision_m: 0.5675 - recall_m: 0.9966 - val_loss: 0.1931 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.0939 - accuracy: 0.9683 - f1_m: 0.7222 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.0737 - accuracy: 0.9736 - f1_m: 0.7207 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 22s 453ms/step - loss: 0.0597 - accuracy: 0.9756 - f1_m: 0.7228 - precision_m: 0.5703 - recall_m: 0.9990 - val_loss: 0.0304 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.2455 - accuracy: 0.9466 - f1_m: 0.7227 - precision_m: 0.5707 - recall_m: 0.9965 - val_loss: 0.0984 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 22s 457ms/step - loss: 0.0579 - accuracy: 0.9789 - f1_m: 0.7238 - precision_m: 0.5727 - recall_m: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 22s 455ms/step - loss: 0.0715 - accuracy: 0.9723 - f1_m: 0.7222 - precision_m: 0.5713 - recall_m: 0.9988 - val_loss: 0.0517 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 22s 459ms/step - loss: 0.0603 - accuracy: 0.9776 - f1_m: 0.7230 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.0361 - accuracy: 0.9888 - f1_m: 0.7215 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.0424 - accuracy: 0.9881 - f1_m: 0.7219 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.0411 - accuracy: 0.9888 - f1_m: 0.7211 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.0503 - accuracy: 0.9855 - f1_m: 0.7210 - precision_m: 0.5692 - recall_m: 0.9990 - val_loss: 0.0144 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 22s 453ms/step - loss: 0.0371 - accuracy: 0.9875 - f1_m: 0.7209 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 22s 462ms/step - loss: 0.0302 - accuracy: 0.9888 - f1_m: 0.7205 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 22s 455ms/step - loss: 0.0406 - accuracy: 0.9888 - f1_m: 0.7212 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.7789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.0500 - accuracy: 0.9809 - f1_m: 0.7218 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 22s 452ms/step - loss: 0.0397 - accuracy: 0.9881 - f1_m: 0.7236 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.0579 - accuracy: 0.9809 - f1_m: 0.7215 - precision_m: 0.5691 - recall_m: 0.9987 - val_loss: 0.0672 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.0482 - accuracy: 0.9842 - f1_m: 0.7228 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 22s 458ms/step - loss: 0.0527 - accuracy: 0.9835 - f1_m: 0.7205 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.0231 - accuracy: 0.9934 - f1_m: 0.7205 - precision_m: 0.5692 - recall_m: 0.9990 - val_loss: 0.0116 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 22s 459ms/step - loss: 0.0340 - accuracy: 0.9861 - f1_m: 0.7233 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 22s 455ms/step - loss: 0.0329 - accuracy: 0.9901 - f1_m: 0.7216 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 22s 461ms/step - loss: 0.0854 - accuracy: 0.9789 - f1_m: 0.7218 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 22s 461ms/step - loss: 0.0401 - accuracy: 0.9842 - f1_m: 0.7205 - precision_m: 0.5692 - recall_m: 0.9990 - val_loss: 0.0549 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 22s 462ms/step - loss: 0.0238 - accuracy: 0.9921 - f1_m: 0.7205 - precision_m: 0.5691 - recall_m: 0.9988 - val_loss: 0.0119 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 22s 453ms/step - loss: 0.0211 - accuracy: 0.9921 - f1_m: 0.7220 - precision_m: 0.5681 - recall_m: 0.9988 - val_loss: 0.1465 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.0298 - accuracy: 0.9894 - f1_m: 0.7237 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 22s 455ms/step - loss: 0.0161 - accuracy: 0.9934 - f1_m: 0.7240 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 22s 461ms/step - loss: 0.0217 - accuracy: 0.9908 - f1_m: 0.7215 - precision_m: 0.5692 - recall_m: 0.9989 - val_loss: 0.0087 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.0195 - accuracy: 0.9934 - f1_m: 0.7229 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 22s 460ms/step - loss: 0.0398 - accuracy: 0.9861 - f1_m: 0.7216 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 22s 454ms/step - loss: 0.0213 - accuracy: 0.9934 - f1_m: 0.7202 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.0236 - accuracy: 0.9914 - f1_m: 0.7201 - precision_m: 0.5687 - recall_m: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 22s 455ms/step - loss: 0.0163 - accuracy: 0.9908 - f1_m: 0.7223 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.0418 - accuracy: 0.9848 - f1_m: 0.7214 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 22s 460ms/step - loss: 0.0245 - accuracy: 0.9888 - f1_m: 0.7202 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 22s 459ms/step - loss: 0.0263 - accuracy: 0.9914 - f1_m: 0.7219 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 22s 453ms/step - loss: 0.0193 - accuracy: 0.9941 - f1_m: 0.7217 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 22s 459ms/step - loss: 0.0179 - accuracy: 0.9934 - f1_m: 0.7206 - precision_m: 0.5686 - recall_m: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 22s 452ms/step - loss: 0.0169 - accuracy: 0.9954 - f1_m: 0.7246 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 22s 457ms/step - loss: 0.0148 - accuracy: 0.9947 - f1_m: 0.7193 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 80ms/step - loss: 0.0046 - accuracy: 1.0000 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 64, 'dropout': 0.4, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 24s 461ms/step - loss: 0.8569 - accuracy: 0.5805 - f1_m: 0.6605 - precision_m: 0.5512 - recall_m: 0.8590 - val_loss: 0.6215 - val_accuracy: 0.5789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.5731 - accuracy: 0.7051 - f1_m: 0.7158 - precision_m: 0.5733 - recall_m: 0.9677 - val_loss: 0.4363 - val_accuracy: 0.7737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.4471 - accuracy: 0.7955 - f1_m: 0.7157 - precision_m: 0.5669 - recall_m: 0.9873 - val_loss: 0.3466 - val_accuracy: 0.8368 - val_f1_m: 0.7294 - val_precision_m: 0.5758 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.3868 - accuracy: 0.8311 - f1_m: 0.7209 - precision_m: 0.5718 - recall_m: 0.9933 - val_loss: 0.2865 - val_accuracy: 0.8526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.3060 - accuracy: 0.8701 - f1_m: 0.7163 - precision_m: 0.5667 - recall_m: 0.9971 - val_loss: 0.4604 - val_accuracy: 0.8105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.2290 - accuracy: 0.9077 - f1_m: 0.7216 - precision_m: 0.5691 - recall_m: 0.9971 - val_loss: 0.2419 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.2278 - accuracy: 0.9169 - f1_m: 0.7218 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.2010 - accuracy: 0.9255 - f1_m: 0.7231 - precision_m: 0.5709 - recall_m: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.1505 - accuracy: 0.9459 - f1_m: 0.7216 - precision_m: 0.5688 - recall_m: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.1426 - accuracy: 0.9479 - f1_m: 0.7226 - precision_m: 0.5692 - recall_m: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.1417 - accuracy: 0.9499 - f1_m: 0.7201 - precision_m: 0.5681 - recall_m: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.1262 - accuracy: 0.9617 - f1_m: 0.7188 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.1283 - accuracy: 0.9611 - f1_m: 0.7173 - precision_m: 0.5651 - recall_m: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 443ms/step - loss: 0.0770 - accuracy: 0.9716 - f1_m: 0.7203 - precision_m: 0.5673 - recall_m: 0.9990 - val_loss: 0.0884 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.1179 - accuracy: 0.9617 - f1_m: 0.7229 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0950 - accuracy: 0.9690 - f1_m: 0.7218 - precision_m: 0.5687 - recall_m: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0937 - accuracy: 0.9683 - f1_m: 0.7198 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.0985 - accuracy: 0.9736 - f1_m: 0.7220 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.0660 - accuracy: 0.9822 - f1_m: 0.7197 - precision_m: 0.5680 - recall_m: 0.9986 - val_loss: 0.0133 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.1436 - accuracy: 0.9789 - f1_m: 0.7197 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.0694 - accuracy: 0.9789 - f1_m: 0.7201 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0569 - accuracy: 0.9789 - f1_m: 0.7226 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.1384 - accuracy: 0.9756 - f1_m: 0.7222 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0901 - accuracy: 0.9822 - f1_m: 0.7232 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 22s 449ms/step - loss: 0.0355 - accuracy: 0.9861 - f1_m: 0.7231 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0905 - accuracy: 0.9789 - f1_m: 0.7236 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0746 - accuracy: 0.9789 - f1_m: 0.7192 - precision_m: 0.5663 - recall_m: 0.9962 - val_loss: 0.0465 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0674 - accuracy: 0.9789 - f1_m: 0.7230 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0573 - accuracy: 0.9763 - f1_m: 0.7236 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0602 - accuracy: 0.9848 - f1_m: 0.7205 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0841 - accuracy: 0.9796 - f1_m: 0.7209 - precision_m: 0.5692 - recall_m: 0.9991 - val_loss: 0.0533 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0434 - accuracy: 0.9868 - f1_m: 0.7222 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0562 - accuracy: 0.9848 - f1_m: 0.7229 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 448ms/step - loss: 0.0367 - accuracy: 0.9868 - f1_m: 0.7223 - precision_m: 0.5698 - recall_m: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0809 - accuracy: 0.9822 - f1_m: 0.7231 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0570 - accuracy: 0.9888 - f1_m: 0.7222 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.1798 - accuracy: 0.9861 - f1_m: 0.7208 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.0379 - accuracy: 0.9868 - f1_m: 0.7199 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0391 - accuracy: 0.9875 - f1_m: 0.7210 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0685 - accuracy: 0.9822 - f1_m: 0.7215 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0489 - accuracy: 0.9848 - f1_m: 0.7213 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0525 - accuracy: 0.9888 - f1_m: 0.7212 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0620 - accuracy: 0.9855 - f1_m: 0.7218 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0845 - accuracy: 0.9881 - f1_m: 0.7201 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0449 - accuracy: 0.9868 - f1_m: 0.7213 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0645 - accuracy: 0.9842 - f1_m: 0.7193 - precision_m: 0.5667 - recall_m: 0.9978 - val_loss: 0.0685 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 443ms/step - loss: 0.0837 - accuracy: 0.9809 - f1_m: 0.7204 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0354 - accuracy: 0.9861 - f1_m: 0.7213 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.0927 - accuracy: 0.9828 - f1_m: 0.7236 - precision_m: 0.5705 - recall_m: 0.9986 - val_loss: 0.0434 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0532 - accuracy: 0.9888 - f1_m: 0.7229 - precision_m: 0.5709 - recall_m: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 81ms/step - loss: 0.0418 - accuracy: 0.9895 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 64, 'dropout': 0.4, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 23s 452ms/step - loss: 0.7422 - accuracy: 0.6088 - f1_m: 0.6880 - precision_m: 0.5612 - recall_m: 0.9115 - val_loss: 0.4836 - val_accuracy: 0.7211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.5398 - accuracy: 0.7355 - f1_m: 0.7189 - precision_m: 0.5732 - recall_m: 0.9775 - val_loss: 0.3472 - val_accuracy: 0.8421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.3940 - accuracy: 0.8239 - f1_m: 0.7186 - precision_m: 0.5682 - recall_m: 0.9891 - val_loss: 0.3619 - val_accuracy: 0.8526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.2555 - accuracy: 0.8931 - f1_m: 0.7230 - precision_m: 0.5713 - recall_m: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.1865 - accuracy: 0.9268 - f1_m: 0.7231 - precision_m: 0.5708 - recall_m: 0.9980 - val_loss: 0.4143 - val_accuracy: 0.8421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1525 - accuracy: 0.9512 - f1_m: 0.7198 - precision_m: 0.5687 - recall_m: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1421 - accuracy: 0.9472 - f1_m: 0.7232 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.1198 - accuracy: 0.9545 - f1_m: 0.7201 - precision_m: 0.5680 - recall_m: 0.9985 - val_loss: 0.1026 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1103 - accuracy: 0.9591 - f1_m: 0.7227 - precision_m: 0.5709 - recall_m: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1981 - accuracy: 0.9321 - f1_m: 0.7196 - precision_m: 0.5679 - recall_m: 0.9949 - val_loss: 0.1037 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0733 - accuracy: 0.9716 - f1_m: 0.7230 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.0767 - accuracy: 0.9756 - f1_m: 0.7200 - precision_m: 0.5680 - recall_m: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1336 - accuracy: 0.9525 - f1_m: 0.7223 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0901 - accuracy: 0.9650 - f1_m: 0.7216 - precision_m: 0.5695 - recall_m: 0.9987 - val_loss: 0.0429 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.0583 - accuracy: 0.9796 - f1_m: 0.7216 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0428 - accuracy: 0.9868 - f1_m: 0.7225 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0739 - accuracy: 0.9730 - f1_m: 0.7193 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0594 - accuracy: 0.9763 - f1_m: 0.7206 - precision_m: 0.5693 - recall_m: 0.9991 - val_loss: 0.1120 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0555 - accuracy: 0.9809 - f1_m: 0.7214 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0375 - accuracy: 0.9881 - f1_m: 0.7224 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0847 - accuracy: 0.9730 - f1_m: 0.7197 - precision_m: 0.5666 - recall_m: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0444 - accuracy: 0.9855 - f1_m: 0.7193 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0312 - accuracy: 0.9881 - f1_m: 0.7227 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0308 - accuracy: 0.9875 - f1_m: 0.7218 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0542 - accuracy: 0.9809 - f1_m: 0.7216 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0412 - accuracy: 0.9894 - f1_m: 0.7233 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0343 - accuracy: 0.9875 - f1_m: 0.7165 - precision_m: 0.5662 - recall_m: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0261 - accuracy: 0.9881 - f1_m: 0.7219 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0190 - accuracy: 0.9921 - f1_m: 0.7195 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.0428 - accuracy: 0.9848 - f1_m: 0.7236 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0288 - accuracy: 0.9908 - f1_m: 0.7231 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0340 - accuracy: 0.9888 - f1_m: 0.7213 - precision_m: 0.5692 - recall_m: 0.9991 - val_loss: 0.1120 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0526 - accuracy: 0.9822 - f1_m: 0.7206 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0881 - accuracy: 0.9710 - f1_m: 0.7182 - precision_m: 0.5664 - recall_m: 0.9964 - val_loss: 0.0340 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.1711 - accuracy: 0.9525 - f1_m: 0.7220 - precision_m: 0.5696 - recall_m: 0.9991 - val_loss: 0.0607 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0907 - accuracy: 0.9690 - f1_m: 0.7224 - precision_m: 0.5714 - recall_m: 0.9974 - val_loss: 0.0262 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0548 - accuracy: 0.9789 - f1_m: 0.7202 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0491 - accuracy: 0.9796 - f1_m: 0.7201 - precision_m: 0.5690 - recall_m: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0486 - accuracy: 0.9822 - f1_m: 0.7217 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 20s 427ms/step - loss: 0.0402 - accuracy: 0.9881 - f1_m: 0.7208 - precision_m: 0.5689 - recall_m: 0.9978 - val_loss: 0.1038 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0431 - accuracy: 0.9835 - f1_m: 0.7215 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0276 - accuracy: 0.9901 - f1_m: 0.7201 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0294 - accuracy: 0.9908 - f1_m: 0.7207 - precision_m: 0.5677 - recall_m: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0151 - accuracy: 0.9954 - f1_m: 0.7230 - precision_m: 0.5727 - recall_m: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0352 - accuracy: 0.9848 - f1_m: 0.7206 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0211 - accuracy: 0.9927 - f1_m: 0.7221 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0381 - accuracy: 0.9875 - f1_m: 0.7212 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0324 - accuracy: 0.9927 - f1_m: 0.7229 - precision_m: 0.5698 - recall_m: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 415ms/step - loss: 0.0233 - accuracy: 0.9921 - f1_m: 0.7213 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0134 - accuracy: 0.9954 - f1_m: 0.7233 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.1085 - accuracy: 0.9579 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 64, 'dropout': 0.5, 'optimizer': 'Nadam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 24s 469ms/step - loss: 0.8162 - accuracy: 0.5818 - f1_m: 0.6723 - precision_m: 0.5635 - recall_m: 0.8572 - val_loss: 0.5519 - val_accuracy: 0.7421 - val_f1_m: 0.7294 - val_precision_m: 0.5758 - val_recall_m: 1.0000\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.5872 - accuracy: 0.6933 - f1_m: 0.7080 - precision_m: 0.5687 - recall_m: 0.9527 - val_loss: 0.4608 - val_accuracy: 0.7737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.4831 - accuracy: 0.7724 - f1_m: 0.7136 - precision_m: 0.5675 - recall_m: 0.9764 - val_loss: 0.3529 - val_accuracy: 0.8263 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.3839 - accuracy: 0.8318 - f1_m: 0.7194 - precision_m: 0.5707 - recall_m: 0.9838 - val_loss: 0.6611 - val_accuracy: 0.7000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.3212 - accuracy: 0.8786 - f1_m: 0.7182 - precision_m: 0.5676 - recall_m: 0.9905 - val_loss: 0.1580 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 448ms/step - loss: 0.2304 - accuracy: 0.9175 - f1_m: 0.7195 - precision_m: 0.5692 - recall_m: 0.9921 - val_loss: 0.1437 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.3939 - accuracy: 0.8701 - f1_m: 0.7174 - precision_m: 0.5669 - recall_m: 0.9912 - val_loss: 0.4647 - val_accuracy: 0.7421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 443ms/step - loss: 0.4400 - accuracy: 0.7883 - f1_m: 0.7176 - precision_m: 0.5709 - recall_m: 0.9812 - val_loss: 0.2846 - val_accuracy: 0.8947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 22s 456ms/step - loss: 0.2580 - accuracy: 0.8964 - f1_m: 0.7228 - precision_m: 0.5731 - recall_m: 0.9953 - val_loss: 0.1395 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.1701 - accuracy: 0.9360 - f1_m: 0.7194 - precision_m: 0.5701 - recall_m: 0.9958 - val_loss: 0.0773 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.1476 - accuracy: 0.9446 - f1_m: 0.7225 - precision_m: 0.5702 - recall_m: 0.9969 - val_loss: 0.0708 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.1052 - accuracy: 0.9611 - f1_m: 0.7200 - precision_m: 0.5695 - recall_m: 0.9969 - val_loss: 0.0584 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 22s 451ms/step - loss: 0.0975 - accuracy: 0.9670 - f1_m: 0.7228 - precision_m: 0.5720 - recall_m: 0.9988 - val_loss: 0.0697 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.1201 - accuracy: 0.9584 - f1_m: 0.7214 - precision_m: 0.5687 - recall_m: 0.9988 - val_loss: 0.0893 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0849 - accuracy: 0.9690 - f1_m: 0.7231 - precision_m: 0.5707 - recall_m: 0.9989 - val_loss: 0.0533 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0549 - accuracy: 0.9815 - f1_m: 0.7197 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.1110 - accuracy: 0.9697 - f1_m: 0.7225 - precision_m: 0.5735 - recall_m: 0.9988 - val_loss: 0.2140 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0764 - accuracy: 0.9723 - f1_m: 0.7232 - precision_m: 0.5712 - recall_m: 0.9978 - val_loss: 0.0365 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0633 - accuracy: 0.9736 - f1_m: 0.7252 - precision_m: 0.5752 - recall_m: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0405 - accuracy: 0.9861 - f1_m: 0.7227 - precision_m: 0.5691 - recall_m: 0.9986 - val_loss: 0.0222 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 443ms/step - loss: 0.2061 - accuracy: 0.9433 - f1_m: 0.7222 - precision_m: 0.5719 - recall_m: 0.9967 - val_loss: 0.0411 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 443ms/step - loss: 0.0848 - accuracy: 0.9730 - f1_m: 0.7210 - precision_m: 0.5691 - recall_m: 0.9986 - val_loss: 0.0552 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0766 - accuracy: 0.9743 - f1_m: 0.7221 - precision_m: 0.5713 - recall_m: 0.9975 - val_loss: 0.0224 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0617 - accuracy: 0.9782 - f1_m: 0.7209 - precision_m: 0.5688 - recall_m: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 448ms/step - loss: 0.0428 - accuracy: 0.9822 - f1_m: 0.7212 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 440ms/step - loss: 0.0714 - accuracy: 0.9743 - f1_m: 0.7231 - precision_m: 0.5716 - recall_m: 0.9988 - val_loss: 0.0381 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0544 - accuracy: 0.9789 - f1_m: 0.7189 - precision_m: 0.5670 - recall_m: 0.9990 - val_loss: 0.0144 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 448ms/step - loss: 0.0336 - accuracy: 0.9894 - f1_m: 0.7229 - precision_m: 0.5702 - recall_m: 0.9988 - val_loss: 0.0161 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 441ms/step - loss: 0.0482 - accuracy: 0.9835 - f1_m: 0.7228 - precision_m: 0.5696 - recall_m: 0.9990 - val_loss: 0.0124 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 22s 450ms/step - loss: 0.0444 - accuracy: 0.9815 - f1_m: 0.7221 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0278 - accuracy: 0.9921 - f1_m: 0.7243 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0395 - accuracy: 0.9888 - f1_m: 0.7219 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0312 - accuracy: 0.9888 - f1_m: 0.7240 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 447ms/step - loss: 0.0328 - accuracy: 0.9888 - f1_m: 0.7224 - precision_m: 0.5699 - recall_m: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 22s 447ms/step - loss: 0.0388 - accuracy: 0.9868 - f1_m: 0.7230 - precision_m: 0.5710 - recall_m: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0257 - accuracy: 0.9921 - f1_m: 0.7226 - precision_m: 0.5696 - recall_m: 0.9990 - val_loss: 0.0062 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 22s 452ms/step - loss: 0.2487 - accuracy: 0.9387 - f1_m: 0.7241 - precision_m: 0.5721 - recall_m: 0.9977 - val_loss: 0.0678 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0688 - accuracy: 0.9749 - f1_m: 0.7239 - precision_m: 0.5738 - recall_m: 0.9975 - val_loss: 0.0135 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0376 - accuracy: 0.9881 - f1_m: 0.7195 - precision_m: 0.5674 - recall_m: 0.9988 - val_loss: 0.0293 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 444ms/step - loss: 0.0316 - accuracy: 0.9894 - f1_m: 0.7191 - precision_m: 0.5687 - recall_m: 0.9991 - val_loss: 0.0410 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0273 - accuracy: 0.9875 - f1_m: 0.7238 - precision_m: 0.5719 - recall_m: 0.9987 - val_loss: 0.0261 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0285 - accuracy: 0.9914 - f1_m: 0.7206 - precision_m: 0.5689 - recall_m: 0.9977 - val_loss: 0.0457 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0330 - accuracy: 0.9888 - f1_m: 0.7220 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 446ms/step - loss: 0.0221 - accuracy: 0.9901 - f1_m: 0.7225 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0207 - accuracy: 0.9941 - f1_m: 0.7219 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0347 - accuracy: 0.9868 - f1_m: 0.7180 - precision_m: 0.5673 - recall_m: 0.9990 - val_loss: 0.0186 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 445ms/step - loss: 0.0314 - accuracy: 0.9894 - f1_m: 0.7252 - precision_m: 0.5745 - recall_m: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0260 - accuracy: 0.9914 - f1_m: 0.7215 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 22s 452ms/step - loss: 0.0121 - accuracy: 0.9947 - f1_m: 0.7212 - precision_m: 0.5688 - recall_m: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 21s 442ms/step - loss: 0.0456 - accuracy: 0.9842 - f1_m: 0.7201 - precision_m: 0.5670 - recall_m: 0.9989 - val_loss: 0.0136 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 82ms/step - loss: 0.0136 - accuracy: 0.9895 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 64, 'dropout': 0.5, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 23s 455ms/step - loss: 1.1455 - accuracy: 0.5633 - f1_m: 0.6716 - precision_m: 0.5629 - recall_m: 0.8473 - val_loss: 0.6114 - val_accuracy: 0.7316 - val_f1_m: 0.6838 - val_precision_m: 0.5696 - val_recall_m: 0.8592\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.6783 - accuracy: 0.6497 - f1_m: 0.7051 - precision_m: 0.5739 - recall_m: 0.9292 - val_loss: 0.4914 - val_accuracy: 0.7895 - val_f1_m: 0.7220 - val_precision_m: 0.5700 - val_recall_m: 0.9889\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.5294 - accuracy: 0.7460 - f1_m: 0.7192 - precision_m: 0.5735 - recall_m: 0.9746 - val_loss: 0.7755 - val_accuracy: 0.6947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.4712 - accuracy: 0.7896 - f1_m: 0.7151 - precision_m: 0.5676 - recall_m: 0.9777 - val_loss: 0.3187 - val_accuracy: 0.8789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 21s 443ms/step - loss: 0.3547 - accuracy: 0.8503 - f1_m: 0.7217 - precision_m: 0.5696 - recall_m: 0.9958 - val_loss: 0.2558 - val_accuracy: 0.8947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.2799 - accuracy: 0.8918 - f1_m: 0.7229 - precision_m: 0.5703 - recall_m: 0.9956 - val_loss: 0.2390 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.2554 - accuracy: 0.9030 - f1_m: 0.7209 - precision_m: 0.5687 - recall_m: 0.9968 - val_loss: 0.2545 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.2188 - accuracy: 0.9156 - f1_m: 0.7211 - precision_m: 0.5709 - recall_m: 0.9969 - val_loss: 0.1631 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.2019 - accuracy: 0.9373 - f1_m: 0.7216 - precision_m: 0.5695 - recall_m: 0.9977 - val_loss: 0.1346 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1917 - accuracy: 0.9367 - f1_m: 0.7222 - precision_m: 0.5702 - recall_m: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.1759 - accuracy: 0.9485 - f1_m: 0.7224 - precision_m: 0.5698 - recall_m: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.1507 - accuracy: 0.9485 - f1_m: 0.7221 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1287 - accuracy: 0.9584 - f1_m: 0.7232 - precision_m: 0.5727 - recall_m: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1528 - accuracy: 0.9558 - f1_m: 0.7225 - precision_m: 0.5702 - recall_m: 0.9988 - val_loss: 0.1738 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.1810 - accuracy: 0.9644 - f1_m: 0.7203 - precision_m: 0.5678 - recall_m: 0.9976 - val_loss: 0.0681 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.0832 - accuracy: 0.9697 - f1_m: 0.7238 - precision_m: 0.5738 - recall_m: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1075 - accuracy: 0.9617 - f1_m: 0.7230 - precision_m: 0.5713 - recall_m: 0.9986 - val_loss: 0.6013 - val_accuracy: 0.8895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.1353 - accuracy: 0.9637 - f1_m: 0.7214 - precision_m: 0.5681 - recall_m: 0.9975 - val_loss: 0.0593 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1034 - accuracy: 0.9650 - f1_m: 0.7220 - precision_m: 0.5697 - recall_m: 0.9991 - val_loss: 0.0947 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0751 - accuracy: 0.9723 - f1_m: 0.7224 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.7684 - val_accuracy: 0.8684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.1003 - accuracy: 0.9776 - f1_m: 0.7191 - precision_m: 0.5680 - recall_m: 0.9987 - val_loss: 0.0849 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0676 - accuracy: 0.9796 - f1_m: 0.7240 - precision_m: 0.5727 - recall_m: 1.0000 - val_loss: 0.0618 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1240 - accuracy: 0.9664 - f1_m: 0.7207 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0776 - accuracy: 0.9736 - f1_m: 0.7212 - precision_m: 0.5703 - recall_m: 0.9991 - val_loss: 0.1352 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.1121 - accuracy: 0.9802 - f1_m: 0.7238 - precision_m: 0.5721 - recall_m: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0881 - accuracy: 0.9809 - f1_m: 0.7214 - precision_m: 0.5707 - recall_m: 0.9980 - val_loss: 0.0750 - val_accuracy: 0.9579 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 21s 433ms/step - loss: 0.0591 - accuracy: 0.9802 - f1_m: 0.7195 - precision_m: 0.5677 - recall_m: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.1296 - accuracy: 0.9736 - f1_m: 0.7209 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9053 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.0493 - accuracy: 0.9815 - f1_m: 0.7236 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.0843 - accuracy: 0.9756 - f1_m: 0.7237 - precision_m: 0.5744 - recall_m: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0474 - accuracy: 0.9822 - f1_m: 0.7196 - precision_m: 0.5682 - recall_m: 0.9991 - val_loss: 0.1456 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.0910 - accuracy: 0.9828 - f1_m: 0.7201 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0962 - accuracy: 0.9802 - f1_m: 0.7195 - precision_m: 0.5665 - recall_m: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0510 - accuracy: 0.9848 - f1_m: 0.7225 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0643 - accuracy: 0.9822 - f1_m: 0.7229 - precision_m: 0.5719 - recall_m: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0343 - accuracy: 0.9888 - f1_m: 0.7214 - precision_m: 0.5687 - recall_m: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 21s 435ms/step - loss: 0.0806 - accuracy: 0.9763 - f1_m: 0.7216 - precision_m: 0.5702 - recall_m: 0.9987 - val_loss: 0.1817 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0525 - accuracy: 0.9868 - f1_m: 0.7178 - precision_m: 0.5662 - recall_m: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0696 - accuracy: 0.9789 - f1_m: 0.7192 - precision_m: 0.5681 - recall_m: 0.9989 - val_loss: 1.2042 - val_accuracy: 0.8684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 21s 430ms/step - loss: 0.0527 - accuracy: 0.9809 - f1_m: 0.7178 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 21s 436ms/step - loss: 0.0519 - accuracy: 0.9875 - f1_m: 0.7217 - precision_m: 0.5692 - recall_m: 0.9988 - val_loss: 0.0167 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0662 - accuracy: 0.9881 - f1_m: 0.7200 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.0560 - accuracy: 0.9835 - f1_m: 0.7201 - precision_m: 0.5692 - recall_m: 0.9989 - val_loss: 0.0201 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 21s 438ms/step - loss: 0.1270 - accuracy: 0.9796 - f1_m: 0.7200 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 21s 431ms/step - loss: 0.0670 - accuracy: 0.9881 - f1_m: 0.7229 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.1871 - accuracy: 0.9809 - f1_m: 0.7190 - precision_m: 0.5669 - recall_m: 0.9987 - val_loss: 0.2148 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 21s 434ms/step - loss: 0.0760 - accuracy: 0.9901 - f1_m: 0.7236 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0793 - accuracy: 0.9861 - f1_m: 0.7204 - precision_m: 0.5693 - recall_m: 0.9983 - val_loss: 0.0498 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 21s 439ms/step - loss: 0.0708 - accuracy: 0.9789 - f1_m: 0.7184 - precision_m: 0.5669 - recall_m: 0.9987 - val_loss: 0.0371 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 21s 432ms/step - loss: 0.0543 - accuracy: 0.9842 - f1_m: 0.7190 - precision_m: 0.5666 - recall_m: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 83ms/step - loss: 0.0833 - accuracy: 0.9895 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 64, 'dropout': 0.5, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 22s 437ms/step - loss: 0.9702 - accuracy: 0.5660 - f1_m: 0.6527 - precision_m: 0.5710 - recall_m: 0.7933 - val_loss: 0.6155 - val_accuracy: 0.6632 - val_f1_m: 0.7191 - val_precision_m: 0.5698 - val_recall_m: 0.9778\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.5874 - accuracy: 0.7249 - f1_m: 0.7151 - precision_m: 0.5786 - recall_m: 0.9527 - val_loss: 0.3874 - val_accuracy: 0.8421 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 20s 426ms/step - loss: 0.3857 - accuracy: 0.8305 - f1_m: 0.7176 - precision_m: 0.5715 - recall_m: 0.9759 - val_loss: 0.2060 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.2672 - accuracy: 0.8958 - f1_m: 0.7216 - precision_m: 0.5765 - recall_m: 0.9852 - val_loss: 0.1695 - val_accuracy: 0.9368 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1805 - accuracy: 0.9321 - f1_m: 0.7211 - precision_m: 0.5695 - recall_m: 0.9953 - val_loss: 0.1198 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.1870 - accuracy: 0.9281 - f1_m: 0.7232 - precision_m: 0.5726 - recall_m: 0.9942 - val_loss: 0.1991 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 20s 424ms/step - loss: 0.1177 - accuracy: 0.9584 - f1_m: 0.7217 - precision_m: 0.5692 - recall_m: 0.9976 - val_loss: 0.1396 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1212 - accuracy: 0.9591 - f1_m: 0.7199 - precision_m: 0.5674 - recall_m: 0.9989 - val_loss: 0.2125 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 20s 423ms/step - loss: 0.1034 - accuracy: 0.9664 - f1_m: 0.7176 - precision_m: 0.5660 - recall_m: 0.9964 - val_loss: 0.0667 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 20s 420ms/step - loss: 0.0965 - accuracy: 0.9670 - f1_m: 0.7191 - precision_m: 0.5682 - recall_m: 0.9991 - val_loss: 0.0806 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0947 - accuracy: 0.9677 - f1_m: 0.7197 - precision_m: 0.5676 - recall_m: 0.9983 - val_loss: 0.0444 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.1213 - accuracy: 0.9571 - f1_m: 0.7220 - precision_m: 0.5695 - recall_m: 0.9977 - val_loss: 0.5221 - val_accuracy: 0.9105 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.1519 - accuracy: 0.9446 - f1_m: 0.7234 - precision_m: 0.5728 - recall_m: 0.9969 - val_loss: 0.0654 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0816 - accuracy: 0.9703 - f1_m: 0.7234 - precision_m: 0.5712 - recall_m: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0895 - accuracy: 0.9723 - f1_m: 0.7207 - precision_m: 0.5687 - recall_m: 0.9976 - val_loss: 0.0818 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0708 - accuracy: 0.9736 - f1_m: 0.7248 - precision_m: 0.5735 - recall_m: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0635 - accuracy: 0.9802 - f1_m: 0.7210 - precision_m: 0.5692 - recall_m: 0.9989 - val_loss: 0.1722 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0967 - accuracy: 0.9670 - f1_m: 0.7234 - precision_m: 0.5714 - recall_m: 0.9989 - val_loss: 0.2074 - val_accuracy: 0.9316 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0605 - accuracy: 0.9782 - f1_m: 0.7247 - precision_m: 0.5722 - recall_m: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0504 - accuracy: 0.9842 - f1_m: 0.7192 - precision_m: 0.5673 - recall_m: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.9211 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 20s 422ms/step - loss: 0.0962 - accuracy: 0.9644 - f1_m: 0.7229 - precision_m: 0.5705 - recall_m: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 22s 463ms/step - loss: 0.0672 - accuracy: 0.9789 - f1_m: 0.7235 - precision_m: 0.5713 - recall_m: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 21s 429ms/step - loss: 0.0718 - accuracy: 0.9763 - f1_m: 0.7207 - precision_m: 0.5678 - recall_m: 0.9979 - val_loss: 0.0286 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 21s 437ms/step - loss: 0.0553 - accuracy: 0.9815 - f1_m: 0.7221 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 20s 413ms/step - loss: 0.0571 - accuracy: 0.9789 - f1_m: 0.7191 - precision_m: 0.5673 - recall_m: 0.9991 - val_loss: 0.0344 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0742 - accuracy: 0.9730 - f1_m: 0.7217 - precision_m: 0.5685 - recall_m: 0.9977 - val_loss: 0.1627 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 20s 412ms/step - loss: 0.0646 - accuracy: 0.9782 - f1_m: 0.7199 - precision_m: 0.5683 - recall_m: 0.9975 - val_loss: 0.0830 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 20s 410ms/step - loss: 0.0634 - accuracy: 0.9815 - f1_m: 0.7219 - precision_m: 0.5702 - recall_m: 0.9988 - val_loss: 0.1065 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0434 - accuracy: 0.9848 - f1_m: 0.7242 - precision_m: 0.5713 - recall_m: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 20s 413ms/step - loss: 0.0389 - accuracy: 0.9868 - f1_m: 0.7219 - precision_m: 0.5692 - recall_m: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9632 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 20s 409ms/step - loss: 0.0694 - accuracy: 0.9789 - f1_m: 0.7166 - precision_m: 0.5662 - recall_m: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 20s 414ms/step - loss: 0.0339 - accuracy: 0.9868 - f1_m: 0.7229 - precision_m: 0.5709 - recall_m: 0.9989 - val_loss: 0.3208 - val_accuracy: 0.9526 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 20s 412ms/step - loss: 0.0413 - accuracy: 0.9881 - f1_m: 0.7201 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 20s 412ms/step - loss: 0.0344 - accuracy: 0.9881 - f1_m: 0.7215 - precision_m: 0.5691 - recall_m: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9474 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0427 - accuracy: 0.9894 - f1_m: 0.7212 - precision_m: 0.5692 - recall_m: 0.9990 - val_loss: 0.0237 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 20s 421ms/step - loss: 0.0268 - accuracy: 0.9908 - f1_m: 0.7212 - precision_m: 0.5700 - recall_m: 0.9988 - val_loss: 0.1063 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0936 - accuracy: 0.9716 - f1_m: 0.7223 - precision_m: 0.5716 - recall_m: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9684 - val_f1_m: 0.7225 - val_precision_m: 0.5704 - val_recall_m: 0.9902\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 20s 417ms/step - loss: 0.0537 - accuracy: 0.9822 - f1_m: 0.7222 - precision_m: 0.5707 - recall_m: 0.9979 - val_loss: 0.0752 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 21s 428ms/step - loss: 0.0233 - accuracy: 0.9921 - f1_m: 0.7202 - precision_m: 0.5687 - recall_m: 0.9970 - val_loss: 0.0073 - val_accuracy: 1.0000 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0628 - accuracy: 0.9855 - f1_m: 0.7202 - precision_m: 0.5684 - recall_m: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 20s 416ms/step - loss: 0.0604 - accuracy: 0.9769 - f1_m: 0.7216 - precision_m: 0.5710 - recall_m: 0.9975 - val_loss: 0.0204 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 20s 418ms/step - loss: 0.0497 - accuracy: 0.9842 - f1_m: 0.7228 - precision_m: 0.5711 - recall_m: 0.9987 - val_loss: 0.0425 - val_accuracy: 0.9737 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 20s 419ms/step - loss: 0.0407 - accuracy: 0.9855 - f1_m: 0.7230 - precision_m: 0.5727 - recall_m: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 20s 425ms/step - loss: 0.0328 - accuracy: 0.9894 - f1_m: 0.7179 - precision_m: 0.5662 - recall_m: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9842 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 20s 409ms/step - loss: 0.0412 - accuracy: 0.9848 - f1_m: 0.7197 - precision_m: 0.5677 - recall_m: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 20s 410ms/step - loss: 0.0386 - accuracy: 0.9881 - f1_m: 0.7206 - precision_m: 0.5694 - recall_m: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9789 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 20s 409ms/step - loss: 0.0293 - accuracy: 0.9894 - f1_m: 0.7206 - precision_m: 0.5681 - recall_m: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 20s 408ms/step - loss: 0.0361 - accuracy: 0.9901 - f1_m: 0.7227 - precision_m: 0.5697 - recall_m: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9684 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 20s 410ms/step - loss: 0.0762 - accuracy: 0.9723 - f1_m: 0.7181 - precision_m: 0.5664 - recall_m: 0.9965 - val_loss: 0.0279 - val_accuracy: 0.9895 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 19s 407ms/step - loss: 0.0664 - accuracy: 0.9796 - f1_m: 0.7216 - precision_m: 0.5707 - recall_m: 0.9966 - val_loss: 0.0098 - val_accuracy: 0.9947 - val_f1_m: 0.7270 - val_precision_m: 0.5729 - val_recall_m: 1.0000\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.0098 - accuracy: 0.9947 - f1_m: 0.7270 - precision_m: 0.5729 - recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "epochs = 50\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64]))#, 64])) #8, 16\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.4, 0.5))\n",
    "# dropout_rate = 0.3\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['RMSprop','adam','Nadam']))#,'adam', 'Nadam'])) #'sgd','Adagrad','RMSprop', \n",
    "\n",
    "params = []\n",
    "losses = []\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "aucs = []\n",
    "cms = []\n",
    "units = []\n",
    "dropouts = []\n",
    "optimizers = []\n",
    "histories = []\n",
    "modelz = []\n",
    "predictions = []\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        units.append(num_units)\n",
    "        dropouts.append(dropout_rate)\n",
    "        optimizers.append(optimizer)\n",
    "        model = run('logs/hparam_tuning/' + run_name, hparams, epochs, input_shape,train_images,train_labels,test_images, test_labels,\n",
    "                HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, predictions,\n",
    "                params, losses, accuracies, f1_scores, precisions, recalls, cms, aucs,\n",
    "                units, dropouts, optimizers, histories, augmentModel=True)\n",
    "        modelz.append(model)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>dropouts</th>\n",
       "      <th>optimizers</th>\n",
       "      <th>losses</th>\n",
       "      <th>accuracies</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precisions</th>\n",
       "      <th>recalls</th>\n",
       "      <th>cms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.056921</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[81, 0], [4, 105]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.041024</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[81, 0], [3, 106]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.045496</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[81, 0], [5, 104]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.035171</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[79, 2], [1, 108]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.035080</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[81, 0], [3, 106]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.119966</td>\n",
       "      <td>0.952632</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[75, 6], [3, 106]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[81, 0], [0, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[81, 0], [2, 107]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.108506</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[80, 1], [7, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[79, 2], [0, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.083273</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[79, 2], [0, 109]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[80, 1], [0, 109]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  dropouts optimizers    losses  accuracies  f1_scores  precisions  \\\n",
       "0      32       0.4      Nadam  0.056921    0.978947   0.727019    0.572917   \n",
       "1      32       0.4    RMSprop  0.041024    0.984211   0.727019    0.572917   \n",
       "2      32       0.4       adam  0.045496    0.973684   0.727019    0.572917   \n",
       "3      32       0.5      Nadam  0.035171    0.984211   0.727019    0.572917   \n",
       "4      32       0.5    RMSprop  0.035080    0.984211   0.727019    0.572917   \n",
       "5      32       0.5       adam  0.119966    0.952632   0.727019    0.572917   \n",
       "6      64       0.4      Nadam  0.004578    1.000000   0.727019    0.572917   \n",
       "7      64       0.4    RMSprop  0.041787    0.989474   0.727019    0.572917   \n",
       "8      64       0.4       adam  0.108506    0.957895   0.727019    0.572917   \n",
       "9      64       0.5      Nadam  0.013631    0.989474   0.727019    0.572917   \n",
       "10     64       0.5    RMSprop  0.083273    0.989474   0.727019    0.572917   \n",
       "11     64       0.5       adam  0.009835    0.994737   0.727019    0.572917   \n",
       "\n",
       "    recalls                  cms  \n",
       "0       1.0  [[81, 0], [4, 105]]  \n",
       "1       1.0  [[81, 0], [3, 106]]  \n",
       "2       1.0  [[81, 0], [5, 104]]  \n",
       "3       1.0  [[79, 2], [1, 108]]  \n",
       "4       1.0  [[81, 0], [3, 106]]  \n",
       "5       1.0  [[75, 6], [3, 106]]  \n",
       "6       1.0  [[81, 0], [0, 109]]  \n",
       "7       1.0  [[81, 0], [2, 107]]  \n",
       "8       1.0  [[80, 1], [7, 102]]  \n",
       "9       1.0  [[79, 2], [0, 109]]  \n",
       "10      1.0  [[79, 2], [0, 109]]  \n",
       "11      1.0  [[80, 1], [0, 109]]  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe assembly for model comparison\n",
    "#integrate confusion matrices as well\n",
    "\n",
    "modelDf = pd.DataFrame(list(zip(units, dropouts, optimizers, losses, accuracies, f1_scores, precisions, recalls, cms)),#aucs, \n",
    "               columns =['units', 'dropouts', 'optimizers', 'losses', 'accuracies', 'f1_scores', 'precisions', 'recalls', 'cms'])#'aucs',\n",
    "modelDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelz[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxUAAALICAYAAAAJyt1PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeVhUZRvH8d8MCCqLKIa54pqamuYCuaRlGmVZZhZmaZqKu1mWSyoumWRmi5hLmq+5k0vl2qK+ZS5hlmn5amaYqbiRG4vgwMz7hzVJiTjMGQaa7+e65rqYMzPPcx8snfvc93Mek81mswkAAAAA8sjs7gAAAAAAFG4kFQAAAACcQlIBAAAAwCkkFQAAAACcQlIBAAAAwCkkFQCAAosbFAJA4UBSAcBlYmNjdfvtt7s7jEJh27Ztatu2rerVq6eXX37ZkDFbt26tCRMmGDKWO+zatUuDBw/O9X01a9bUe++9lw8RAQBy4u3uAAAA0tSpU1W0aFHNmTNHZcuWNWTM6dOnKzAw0JCx3GHFihU6fPhwru+Li4tTuXLl8iEiAEBOSCoAoAA4f/68WrVqpTvuuMOwMW+99VbDxirIGjRo4O4QAMDj0f4EIN+MGDFCgwcP1nvvvaeWLVuqQYMGGjx4sFJSUjR9+nQ1a9ZM4eHhmjhxoqxWq/1ze/fuVe/evdW4cWPVrVtXERERWrZsWbaxDxw4oG7duqlBgwa655579PHHH6tt27aKjY21v+f333/XsGHDFBYWpttvv119+/bV0aNHrxtzVlaWZs2apTZt2qh+/fp6+OGHtXHjRvvrFotF7777riIiIlSvXj21b99ea9assb9+7Ngx1axZU5s3b1bPnj1Vv3593XnnnZo5c2a2148fP64lS5aoZs2aOnbsmLp27ao+ffpki2X+/PmqWbOm/XlCQoJ69eqlxo0bq2HDhurZs6cOHDhgf/3v7U/Hjh3Ts88+q2bNmun2229Xv3799Ouvv9pfj42NVceOHbV27Vr7+Tz66KP67rvvcvz9/Bn/xo0b1b17d9WvX1/33HOPPvvsMx06dEhdunRR/fr11aFDB+3duzfb723atGmKiIhQ3bp11aRJEw0cOFAnTpyQdOW/lQ8//FA///yzatasqfj4eK1atUrh4eGaO3euwsPDFRERoUuXLtnbnzIzM/Xwww+rdevWSk9Pt8/Tvn17dejQQRaL5bp/1gCAvCOpAJCvtm7dqs8//1wvv/yyXnzxRX3++ed69NFHtWfPHr366qt65JFHtHDhQq1fv16SlJiYqG7duql48eJ6++239c4776hKlSoaO3as/Qt0UlKSunXrpoyMDL3xxhvq3bu3XnnlFfsXVElKT09Xt27d9O2332r06NF67bXXlJSUpKeeekoXLlzIMd6YmBhNnz5dHTt21KxZs1S/fn0NHjxYu3btkiQNHz5cM2bM0OOPP66ZM2fq9ttv1wsvvKDly5dnG2fkyJGqX7++Zs2apbvvvltvvfWWvvzyS4WEhCguLk433XSTIiIiFBcXp5CQkBv6XQ4YMEBZWVl688039eabb+rcuXPq06ePsrKy/vHekydP6rHHHtORI0c0duxYxcTE6NixY+rSpYtOnTplf9+vv/6qadOmaeDAgYqNjVVGRoaeffZZZWZmXjeWUaNGqXnz5po5c6ZuvvlmDR8+XAMGDNADDzygqVOnKiUlRS+++GK23+uiRYvUu3dvzZs3T0OGDNGOHTs0adIkSVL//v3VqlUrVaxYUXFxcapTp44kKTk5WatWrdLrr7+u5557TsWKFbOP6e3trUmTJunkyZOaPXu2JGnWrFk6fPiwJk+erCJFitzQ7xUA4DjanwDkq7S0NE2bNs3+xXn16tU6dOiQVq5cKX9/f7Vs2VIbNmzQnj179OCDD+rnn39WgwYN9Prrr9u/FNavX1/h4eHatWuXatWqpYULF8pqtWrOnDn2NQQlS5bMtsj3o48+0uHDh7VmzRpVq1ZNktS0aVPdfffdWrhwoQYOHPiPWM+fP68lS5ZowIAB6t+/v/0zhw8f1q5duxQQEKB169Zp/Pjx6ty5sySpRYsWSklJ0RtvvKGOHTvax7r//vvt8YSHh+vTTz/Vli1b1KpVKzVo0EA+Pj4qXbr0DbfynD17VgkJCRowYIDuvPNOSVLZsmW1du1apaWlKSAgINv758+fr/T0dM2bN0+lSpWSJIWFhalNmzb6z3/+oxEjRkiSUlNTNX/+fN12222SrlRq+vfvrwMHDqhu3bo5xnPfffepd+/e9s/06tVL7du315NPPilJOnfunEaPHq2LFy8qMDBQZ8+e1bBhw9SpUyd7LH/++UhSpUqVVKpUKSUmJmb7nWRlZWnw4MH2c/67OnXq6JlnntHcuXNVv359zZ49W4MGDcpW4QEAGI+kAkC+Klu2bLYr8cHBwcrKypK/v7/9WFBQkJKTkyVJrVq1UqtWrZSRkaEDBw7o119/1Q8//CBJunz5siQpPj5eYWFh2RYlt2nTRt7ef/0VFx8fr9DQUIWGhtqvuhctWlSNGjXS119/fc2kYs+ePcrKylLr1q2zHV+4cKEkafHixZKufKG+Wrt27bRu3Tr98ssvKl68uKTsff9ms1khISFKS0u7od/ZtQQFBaly5coaM2aMtm/frlatWqlFixZ6/vnnr/n+b775RuHh4faEQpJKlSqlpk2baufOnfZj3t7e2ZKHm2++WZJ06dKl68bzZxIiSaVLl5Yk1atXz36sZMmSkmRPKt566y1J0qlTp5SQkKCEhAR999139j/T66levfp1Xx80aJA+//xz9evXT7fddpt69eqV65gAAOeQVADIV35+fv84dnULy99lZWXp1VdfVVxcnCwWiypVqqTGjRtL+msPg3Pnzv3ji6aXl5f9i6x0peqQkJBgb6O5WuXKla85959tUVd/Ef/7697e3goKCsp2/M8v1SkpKfakomjRotneYzabndqDwWw2a/78+YqNjdWmTZu0cuVKFS1aVD179tSgQYNkMpmyvf/ixYuqXbv2P8YJDg7WoUOH7M99fHxkNv/VGfvnz1evcbmWa/25/v2cr/bdd99p3Lhx+umnnxQQEKDatWvL19f3unP8Kac/jz/5+voqIiJCs2fPVvPmzeXl5XVD4wIA8o6kAkCBNnPmTH3wwQeaPHmyWrVqpeLFi+vSpUtasWKF/T0hISE6e/Zsts9ZrVadP3/e/jwgIEC1atXSxIkT/zGHj4/PNef+s4Xo3LlzKlOmjP34/v37ZbPZVKJECWVmZur8+fPZEoukpCRJ+key4ai/f5H/e2WjbNmymjRpkqxWq77//nstX75c77zzjqpXr6527dple2+JEiXscV0tKSnJ6TgdlZycrL59+6phw4aKjY1VaGioJOm1117LttA8r44cOaL3339fNWvW1Ny5c9W+fXtVqVLF6XEBADljoTaAAu37779X3bp1df/999uv+n/11VeS/qpUNGnSRDt37lRKSor9c1u2bMl2t5+GDRvq2LFjKl++vOrVq6d69eqpbt26mj9/vr744otrzn3bbbfJ29tb//3vf7Mdj46O1nvvvadGjRpJkj755JNsr69fv17BwcE5VkBuhL+/v06fPp3t2Lfffmv/+cCBA2rRooX27dsns9mshg0bauLEifL29lZiYuI/xmvUqJHi4+OzJV9nz57Vjh071LBhwzzHmRcJCQm6cOGCnn76aXtCYbVatX379mzVm6srJjfKZrNp9OjRKl++vJYtW6by5ctr9OjR7MwNAC5GpQJAgVavXj3NmTNHixYt0i233KIffvhB77zzjkwmk/22oV27dtWiRYsUFRWl3r176+zZs3rzzTclyd4G1KlTJy1cuFDPPPOMoqKiFBQUpLi4OH322Wd66KGHrjl3cHCwOnfurJkzZ9rXGmzYsEH79+9XdHS0atWqpYiICL366qtKTU1VzZo1tWnTJq1bt07R0dF5+lL8p5YtW2rcuHGKjY1VkyZN9Omnn+rHH3+0v169enX5+flp+PDhGjhwoEqUKKGPPvpIJpNJd9111z/G6969uz788EM988wz6t+/v2w2m2bOnCkfHx89/fTTeY4zL6pWrSo/Pz/NmDFDVqtV6enpWrJkiQ4cOCCTySSbzSaTyaTAwECdPHlS27Ztu+4i8avFxcVp586dWrhwoYoXL67o6Gh1795dS5YssS8aBwAYj0oFgAItKipKHTp00PTp09WnTx+tXbtWY8aMUfPmzbV7925JVxYBz5s3T1arVYMHD9aMGTM0cuRISX/1+vv7+2vx4sWqWrWqxo0bp/79+ysxMVEzZsxQq1atcpz/pZdeUlRUlBYvXqy+ffvqf//7n+bMmWNfhPz666/rySef1Pz589WvXz999913mjJlitNfYB977DE9/fTTWrRokfr166eUlBS99NJL9te9vb01Z84chYaGaty4cerTp48SEhI0e/bsay5kLlu2rBYvXqyQkBANHz5co0aNUrly5bRs2TL7Yuz8EhAQoNjYWF28eFH9+vXThAkTFBQUpLfffltWq1V79uyRJEVGRio4OFh9+vTRtm3bch331KlTmjJlih5++GGFhYVJunK3rgcffFBTp069ZgUHAGAMk42aMIBCbvfu3UpPT1fTpk3txw4fPqz77rtPM2bM0D333OPG6AAA+Pej/QlAoffbb79p1KhRev7551WvXj0lJSVp1qxZqly5slq0aOHu8AAA+NejUgHgX2H+/PmKi4vT8ePH5efnp+bNm+vFF1/MdtcmAADgGiQVAAAAAJzCQm0AAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATiGpAAAAAOAUkgoAAAAATvF2dwDX8nOt6u4OAQAKjBrx290dAgAUHCVC3B1BrvqaAt029yzbRbfMS6UCAAAAgFNIKgAAAAA4pUC2PwEAAACFlSdetffEcwYAAABgICoVAAAAgIHMJpO7Q8h3VCoAAAAAOIWkAgAAAIBTaH8CAAAADOSJV+098ZwBAAAAGIhKBQAAAGAgs+et06ZSAQAAAMA5JBUAAAAAnEL7EwAAAGAgT7xq74nnDAAAAMBAVCoAAAAAA7GjNgAAAAA4iEoFAAAAYCBPvGrviecMAAAAwEAkFQAAAACcQvsTAAAAYCB21AYAAAAAB1GpAAAAAAzkiVftPfGcAQAAABiIpAIAAACAU2h/AgAAAAxkYkdtAAAAAHAMlQoAAADAQJ541d4TzxkAAACAgUgqAAAAADiF9icAAADAQOyoDQAAAAAOolIBAAAAGMgTr9p74jkDAAAAHmvPnj3q2rWrJOnIkSN64okn1KVLF40dO1ZWq1WSNH36dHXq1EmdO3fW3r17cx2TSgUAAABgIHMB3vxuzpw5Wr16tYoVKyZJiomJ0ZAhQxQeHq7o6Ght2rRJ5cqV086dO7V8+XKdOHFCgwYN0sqVK687LpUKAAAAwENUqlRJsbGx9uf79u1TWFiYJKlly5bavn27vv32W7Vo0UImk0nlypVTVlaWzp49e91xqVQAAAAA/xJxcXGKi4uzP4+MjFRkZKT9eUREhI4dO2Z/brPZZPqjsuLn56fk5GSlpKQoKCjI/p4/j5cqVSrHeUkqAAAAAAO5sxXo70lEbszmv6JNTU1VYGCg/P39lZqamu14QEDA9cdxPFQAAAAA/wa33nqr4uPjJUlbtmxR48aN1bBhQ23dulVWq1WJiYmyWq3XrVJIVCoAAAAAQxWmze+GDx+uMWPG6I033lDVqlUVEREhLy8vNW7cWJGRkbJarYqOjs51HJPNZrPlQ7wO+blWdXeHAAAFRo347e4OAQAKjhIh7o4gVzHFrn9V35VGXrr+gmpXof0JAAAAgFNofwIAAAAM5IlX7T3xnAEAAAAYiEoFAAAAYCCzCtFKbYNQqQAAAADgFCoVAAAAgIEK0y1ljUKlAgAAAIBTSCoAAAAAOIX2JwAAAMBAnnjV3hPPGQAAAICBqFQAAAAABmKhNgAAAAA4iKQCAAAAgFNofwIAAAAMxI7aAAAAAOAgKhUAAACAgVioDQAAAAAOIqkAAAAA4BTanwAAAAADeeJVe088ZwAAAAAGolIBAAAAGIiF2gAAAADgICoVAAAAgIHY/A4AAAAAHERSAQAAAMAptD8BAAAABmKhNgAAAAA4iEoFAAAAYCAPLFRQqQAAAADgHJIKAAAAAE6h/QkAAAAwEAu1AQAAAMBBVCoAAAAAA7GjNgAAAAA4iKQCAAAAgFNofwIAAAAMxEJtAAAAAHAQlQoAAADAQJ541d4TzxkAAACAgahUAAAAAAbywCUVVCoAAAAAOIekAgAAAIBTaH8CAAAADGQ2eV4DFJUKAAAAAE6hUgEAAAAYyPPqFFQqAAAAADiJpAIAAACAU2h/AgAAAAxE+xMAAAAAOIhKBQAAAGAgKhUAAAAA4CCSCgAAAABOof0JAAAAMJCJHbUBAAAAwDFUKgAAAAADeV6dgkoFAAAAACdRqQAAAAAM5IlX7T3xnAEAAAAYiKQCAAAAgFNofwIAAAAM5IF3lKVSAQAAAMA5VCoAAAAAA5k88KayVCoAAAAAOIWkAgAAAIBTaH8CAAAADOR5zU9UKgAAAAA4iUoFAAAAYCAqFQAAAADgIJIKAAAAAE6h/QkAAAAwkNkD+5+oVAAAAABwCpUKAAAAwEDsqA0AAAAADqJSAQAAABjI8+oUVCoAAAAAOImkAgAAAIBTaH8CAAAADGTywP4nKhUAAAAAnEKlAgAAADCQBxYqqFQAAAAAcA5JBQAAAACn0P4EAAAAGMjsgQ1QVCoAAAAAOIVKBQAAAGAgz6tTUKkAAAAA4CSSCgAAAABOof0JAAAAMBA7agMAAACAg6hUAAAAAAbywEIFlQoAAAAAzqFSAQAAABjI5IG1CioVAAAAAJxCUgEAAADAKbQ/AQAAAAYye173E5UKAAAAAM6hUgEAAAAYyAMLFVQqAAAAADiHpAIAAACAU2h/AgAAAAxE+xMAAAAAOIhKBQxXevhI+dapK+/SpWUqWkyWY0eVdfasTg4ZZMj4lTd9oXPz5+nCwgWSpCJVqipk/Ms63u1JQ8b3a9NW6Xv3SFarSvUfpDMTxuZ5rKKNGqvorXV0fuH7eR6jzKtTVKRyFSV/uFI2m1UXP4jL9TMmX1+FjH9Zp0YMy/O8APLHscQTeujJ7qpT8xb7sfDGDTWwV49rvn/E+FfU7t42atk0PE/ztX74MZUtU0ZmL7NsVquCSpTQq2NHyd+v+A2P8e77i3RH44aqWb2aVm/4TI91aK9Va9erRGCg7mnZIk9xSdLEqW+r11NPyJKZqYHDRqlWjeoKDAxQjy6RKndzmVw//+W2HTrz+1l1euiBPMcAGMETd9QmqYDhkibHSJICHukonyrV9PsbUwyfo2T3Z5S29StZDh82fOygbt11euwYWQ4nOJVQSFLwwME6HtXTqTGKt7hTh1vc4dBnbBkZurT7OwV0eETJH33o1PwAXK96lcpaOCs23+abFztVvr6+kqQpsTO1au16dYvsdMOfj3r6KUlXEqLlq9fqsQ7t1fHBdk7F9P0P++Tt5aWby4To4w2fqmmTRhoxZKBDY7Rq3lS9nn1BEa1bKcDf36l4ADiGpAL5plhYuEoPfVE2i0UXPohT8LNDdOT+e2W7fFnBz7+oy4d/UfKHqxT8/Asq1riJZDbr/H/mKeXTDf8Y68yrk1QmZoqOdXk823GfW27RTaOiJZNJ1vPndOqlEbKmpOim6PEqWreuMpOSVKRCBSX2i5K5eHGVHjFKJpNJ5sBAnXllgsyBJeRbq7ZunjxFJ4cNVZlXX9fp6FG66aXROt69qySp3Kx39fvbb8ns76/gIc/LZrXK8tsRnR47RsrMtMdSvHkLXf7lkGSxqFhYuEr2ipLNYlGRChWUvH6dzs2eKe/y5VVmYoxM3t6ySTozcYIu/3TAPsZN0ePlFRiosu/MUsrGz+RTpZouxC1RuZnvKuv8eaV9+YVSv/rymuecsmG9ys+ZR1IBFFJZWVmKjpmik6dO69yFi2rZ7A4N6dvL/vrhI79p5IQYeXt7ycvLS6+NG60yITdp6juz9M3uPbJZbereJVL3t7k7xzmsVquSU1JUJbSSLJmZeunlGB09lqgsa5Z6dIlUu7b3aPGKD/XRug0ym8xq2KCehg8eYK+WfLb5Cx06/Kumz/2PbFabSgeX0q+/HVWtGtX1yIP360zS7+rz/DCtWvBernEtjFuhHk92VuLJU5o5b4HS09NVqUJ5bdi4WeNGvKD1n23S7h9+VFraJb0yeri279yltZ9ulMlkUrt777EnRa2a3aEP133iUJIEwHkkFchXJl9fHf3jL/rgZ4f84/Xid7ZUkfIVdKxLpEw+PqoYt0Jp27fKmpyc7X1pX34hvztbqWTvPkr57FP78ZAJk3R61Ahd/uWQAh99TCV7RSl97155BQXp6OOPyqtkKYV+ulGS5FO9hpImT9LlgwcV8GB7BT7SSaejRynjwH6dHjtGNotFknT54E8yFS0q73LlZLNYZA4qpYz9/1PoJ5/rWJdIZZ09q1KDhyjwkUd1cflfrUnFwsKV8dNP9ufe5crrt4cfkMnHR1W2bNe52TNVethInV+4QKmbN8qnVm2VeSVGRzs9Yv/MmQlj5d/2Xp0Y0FcBj3S0H/cqfZN+e7SDZLGowrIV/zjn3996Q9aLF2UuWUpmf39ZU1Kc+WMD4GKHDv+qrn3/ahF9fUK0LJmZalC3jh4bPUIZGRlq+eCj2ZKK7Tt3qU6tWzTiuUHatXuPLiQn68ChX3Qs8YSWzZ2pjIwMPf5MXzUPb6zAgIBs8z0zaKjMXmaZZNJtdWqrQ7sILVv1sUqWKKEp48coJTVNHbv11B1NGmnVmvUa88IQNahXR0tWfKjMqy6e9O3RTQd/SdDAXj0U++48SdLjHdpr/Gtv6pEH79fHGz5Vxwfb6cvtX+ca187d3ysmeqR8fHwU9fSTSvj1N3Xp9Ig2bNxsf0/VyqEaPfRZHUo4rPUbN2vJnHdkMpnUfcBzanFHmKqGVlLNGtW0YNkKkgq4lcnzup9IKpC/LufUrvTH/3y+t9SUb526Kr9g8ZUD3kXkXa58tqv3fzozeZIqrfhQlt+O2I/5VKumm8aOvzKkt7csvx6WT7VqSv9+tyQp69xZXU5IkCRlnjqlUv0GypaRLnNxP1lTc/7ifXHFcgU+/Ihsly/r4ocr5FWqlLxvukk3v3WlXcHs66vUbVuzfcarZEmlf//9X+d+8CcpK0u2S5dkS0+/Em/Varq0a+eV1w/sl/fNZXOM4WqZx45KfyQ91zrnP2X9niRziSCSCqCAu1b7U0pKqn7Yf0Bff7tb/n7FddlyOdvrnR56QHMWLFGvwUMV4O+v5/pH6eChX7TvwEF7gpKZmanEE6f+kVRc3f70p19+PaJmTRpLkvz9iqtalco6euy4YqJHat6ipXp9+kw1qFdXtlzOpVqVysrKytLxEye1/vPNmv/Om4r7cHWucVmzrPLx8bnu2FVCK0mSDv5yWIknTqn7gCsXpy5cTNZvR4+pamgl3RQcrPMXLuQSJQCjkVQgf1mt9h9tGRnyuilEmcePybf2rbqc8IsuJyTo0s6vdTp6tGQyqVT/gbIcO3rNoWypqTo9doxunvqWLh++kihYDifo1PAXlHnihIre3lDeISGyZWQo4KEO0oL5MgcGyqdyZUnSTaOidfLF52VJ+EWlBj2rIuXL22M0mc3Z/uFMXr9WFf6zQDablNizu6xpqco8eVIn+veRNSVFfnffI2taarb4sn7/XebAq/4ht/3zn+LLCb+oWKMmSv3vJvnUqq2spDM39Gu0Wf8a61rn/CdzQKCyzp29oTEBFCyr1m1QgL+/Jox8UUeOHtMHH62R7aq/RzZt2apGDW7TwN49tPbTjZq7YLHa3NVS4Y1u18svDZPVatWM995XhfLlbmi+apVDtev7PWp7d0ulpKbp4KFfVKFcOc38zwKNH/GCfH191XPQ89q99wf7Z8xms6zWf/7d1umhBzQldqaqV6mswIAAVa0cmmtcvr6+ysrKkpeXV44xmv+4/Fs1tJKqV62suW+/LpPJpPlL4nRL9WqSpIvJySpVsuQNnTPgKp54e1WSCrjNublzVP7dubIcPy7rH1eVUv+7ScXCw1Vh0VKZivspdeNnsqWm5jjGpZ3xSl63Vr633ipJOj0+WmUmvy6T+cr/zqdGj5Tl119V/M5WqrD0A2WdOSNrerpslkwlr/lY5WbMUlZSkjJPnZRX0JV/hNJ3f6cyk6dcSWz+YEtLU8ZPByQvL3tF48ykiSo3e65kNsuakqJTw1/IFlvaznj5t7lXyR9/lGP8Sa/FqMyEV1TymZ5SkSI6NXqkw7/Ha52zJJkDAmRNvihbWprDYwJwv6aNG+n50eP07fd7VaxYUYVWrKDTZ5Lsr9etXUsvRr+s2HfnyWw2aeRzg3RrzVu089vd6tJ7gNIuXVKbu+684bs6Pf7IQxrzymt6ond/ZWRkaGCvHgouVVI1q1VVp+5RKhkUpDIhpVW/zq1atWa9JCm4ZJAsFoumxM5U0asqH/e1uVuvvDFNM1+/cuOO1nc2zzWuhvXrat9PB3XbrbVzjbXWLdXVtEkjPdG7vy5ftui2OrVV5qbSkqQ9+/araZNGN3TOAIxjstmucfnUzX6uVd3dIeBfpEiVqvKtXVsp69fJHBSk0DUb9GvrVrL9rZXAcCaTyr+/SMd7dre3KuWnEk88KWtKipLXfJzvc8NYNeK3uzsEwOV27/1R6z7fpNFDn3VqnJ6Dh+rtSRPk7+9nUGQocEqE5P4eN4u/uaLb5g4/ee0OD1fzxOoMPEzmyRMKeKC9KixbofJz5ilp6muuTygkyWbT2XdiFfSEMftnOMLk66uiDRsqee3qfJ8bAPLi9tvqKisrSydPnc7zGF9s3a6I1q1IKAA3oFIBAAUclQoAuAqViutyV1kR3fQAACAASURBVKWCNRUAAACAgUweeE9Z2p8AAAAAOIVKBQAAAGAgz6tT5ENSkZKSouPHj6tixYoqXvzGbmsHAAAAwFgWi0UjRozQ8ePHZTab9fLLL8vb21sjRoyQyWRSjRo1NHbsWJnNjjczuTSp+OSTTzRr1ixlZWXpvvvuk8lkUv/+/V05JQAAAIBr+PLLL5WZmally5Zp27Zteuutt2SxWDRkyBCFh4crOjpamzZtUtu2bR0e26VrKubPn68PPvhAQUFB6t+/vzZu3OjK6QAAAAC3M7nxcT1VqlRRVlaWrFarUlJS5O3trX379iksLEyS1LJlS23fnrc7Drq0UmE2m+Xj4yOTySSTyaRixYq5cjoAAADAo8XFxSkuLs7+PDIyUpGRkZKk4sWL6/jx47r//vt17tw5zZo1S9988439blV+fn5KTk7O07wuTSoaN26soUOH6tSpU4qOjla9evVcOR0AAADgdu68pezVScTfzZ8/Xy1atNDQoUN14sQJPf3007JYLPbXU1NTFRgYmKd5XZpUPP/889qyZYtq166tatWq6e6773bldAAAAAByEBgYqCJFikiSSpQooczMTN16662Kj49XeHi4tmzZojvuuCNPY7t0R+3Tp0/r4sWLMpvNmjt3rrp27aratWvn+jl21AaAv7CjNgBcpRDsqP1tuVC3zd0o8UiOr6Wmpuqll17SmTNnZLFY1K1bN9WtW1djxoyRxWJR1apVNXHiRHl5eTk8r0uTih49eqhPnz5asmSJIiIitGzZMi1cuDDXz5FUAMBfSCoA4CqFIKnYXd59ScXtx3NOKlzJpXd/yszMVJMmTXTx4kU98MADslqtrpwOcErAIx1VfsFilV+wWBWWrVC1Pfvk1/ZehX622X68WJMwd4cJAPlu9vyFinymrzp266nlH691dzgACiCXrqmwWCyKiYlR48aN9fXXXysrK8uV0wFOSf5wlZI/XCVJumnMOF1ctVxFb62j31+frJTPPnVzdADgHvHf7tbuvT9q6dwZupSernmLlrk7JKDAM5k9b09tl1YqXn31VVWpUkVRUVE6e/aspkyZ4srpAEP41q0rnxo1dPGDOPnWqavAjp1UYdFSlR4+UspDjyEAFGZbv47XLdWrasCwUeo7dITuatHM3SEBKIBcUqnYunWr/efQ0FDt3LlTgYGBOnLkiCpWrOiKKQHDlIrqp7PvxEqS0rZvU8rGz5V57KhCxr+sEp276MLi3NcFAcC/xbnzF5R48pRmvTFZxxJPqN/QEfpk+WK33jITKOg88X8PlyQV69aty/G1Fi1auGJKwBDmgAAVqVpNl+K/liRdXLlc1j82gUnZtFH+997nzvAAIN8FlSihqpVD5VOkiKqGVpKvj4/Onjuv4FIl3R0agALEJUlFTEzMNY+fPn3aFdMBhinWOEyXdmyzP6/08Tode+JxZZ46qeJNmylj349ujA4A8l+j+vW0IG6FenSJ1Omk33UpPV1BJfK2ORaAfy+XLtSeNm2alixZIovFovT0dFWuXPm6VQzA3YpUqSLL0aP256fHvKSyse/ImpGhy4d+1oXlcdf5NAD8+9x9Z3N9s3uPOnWPks1mVfSLz+XpHvaAJ6H9yWBbtmzRli1bNGnSJPXo0UPjx4935XSA087Pm5vtedq2rUrbtjWHdwOAZxg2uL+7QwBQwLk0qQgKCpKPj49SU1MVGhqqS5cuuXI6AAAAwO088UYGLr2l7M0336wVK1aoWLFimjp1qlJSUlw5HQAAAAA3cElSMWPGDEnShAkTVK1aNQ0bNkwhISF68803XTEdAAAAADdySVLx9ddXbsdpNpv15ptvyt/fX127dlX16tVdMR0AAABQYJhM7nu4i0uSCpvNds2fAQAAAPz7uGSh9tWLUzxxoQoAAAA8lyd+/3VJUrFv3z517txZNptNhw4dsv9sMpm0bNkyV0wJAAAAwE1cklSsXr3aFcMCAAAAKIBcklSUL1/eFcMCAAAABZ4Hdj+5dp8KAAAAAP9+Lt1RGwAAAPA0Zg8sVVCpAAAAAOAUKhUAAACAgTywUEGlAgAAAIBzSCoAAAAAOIX2JwAAAMBAnrijNpUKAAAAAE6hUgEAAAAYyOSBl+098JQBAAAAGImkAgAAAIBTaH8CAAAADMRCbQAAAABwEJUKAAAAwEAeWKigUgEAAADAOSQVAAAAAJxC+xMAAABgIBZqAwAAAICDqFQAAAAABvLAQgWVCgAAAADOoVIBAAAAGMjsgaUKKhUAAAAAnEJSAQAAAMAptD8BAAAABvLA7icqFQAAAACcQ6UCAAAAMBCb3wEAAACAg0gqAAAAADiF9icAAADAQB7Y/USlAgAAAIBzqFQAAAAABqJSAQAAAAAOIqkAAAAA4BTanwAAAAADmcye1/9EpQIAAACAU6hUAAAAAAZioTYAAAAAOIhKBQAAAGAgsweWKqhUAAAAAHAKSQUAAAAAp9D+BAAAABjIA7ufqFQAAAAAcA6VCgAAAMBAJg8sVVCpAAAAAOAUkgoAAAAATqH9CQAAADCQB3Y/UakAAAAA4BwqFQAAAICBWKgNAAAAAA4iqQAAAADgFNqfAAAAAAN5YPcTlQoAAAAAzqFSAQAAABiIhdoAAAAA4CAqFQAAAICBTB542d4DTxkAAACAkUgqAAAAADiF9icAAADAQCzUBgAAAAAHUakAAAAAjGSmUgEAAAAADiGpAAAAAOAU2p8AAAAAI7FQGwAAAAAcQ6UCAAAAMBC3lAUAAAAAB5FUAAAAAHAK7U8AAACAkdinAgAAAAAcQ6UCAAAAMBILtQEAAADAMVQqAAAAAAOZWFMBAAAAAI4hqQAAAADgFNqfAAAAACOxUBsAAAAAHEOlAgAAADAQC7UBAAAAwEEkFQAAAACcQvsTAAAAYCQWagMAAACAY6hUAAAAAEZioTYAAAAAOIZKBQAAAGAgE2sqAAAAAMAxJBUAAAAAnEL7EwAAAGAkFmoDAAAAgGOoVAAAAABGYqE2AAAAADiGpAIAAACAU2h/AgAAAAxk8sDL9h54ygAAAACMRKUCAAAAMBILtQEAAADAMSQVAAAAAJxC+xMAAABgIFMB3lF79uzZ2rx5sywWi5544gmFhYVpxIgRMplMqlGjhsaOHSuz2fG6A5UKAAAAwAPEx8dr9+7dWrp0qRYuXKiTJ08qJiZGQ4YM0ZIlS2Sz2bRp06Y8je1wpcJisahIkSJ5mgwAAAD413PjQu24uDjFxcXZn0dGRioyMlKStHXrVt1yyy0aMGCAUlJSNGzYMH3wwQcKCwuTJLVs2VLbtm1T27ZtHZ4316Ri165d2rlzp3r16qUnn3xSBw8eVExMjNq1a+fwZAAAAABc5+ok4u/OnTunxMREzZo1S8eOHVO/fv1ks9lk+iMJ8vPzU3Jycp7mzbX9acqUKWrQoIE2btyooKAgrVu3TvPmzcvTZAAAAMC/ntnkvsd1BAUFqUWLFvLx8VHVqlXl6+ubLYlITU1VYGBg3k45tzdkZWWpWbNm2r59u9q0aaMKFSrIarXmaTIAAAAA7tGoUSN99dVXstlsOnXqlC5duqSmTZsqPj5ekrRlyxY1btw4T2Pn2v5ktVq1d+9effHFF+rTp48OHjwoi8WSp8kAAAAAuMfdd9+tb775Rp06dZLNZlN0dLQqVKigMWPG6I033lDVqlUVERGRp7FzTSr69u2roUOHqlOnTqpYsaJat26tUaNG5WkyAAAA4N/OVIB31B42bNg/ji1atMjpcXNNKu69917de++99ueff/65vLy8nJ4YAAAAwL9Drmsqzpw5o6ioKEVERCgpKUlRUVE6ffp0fsQGAAAAFD4FdKG2S085tzeMHz9ebdq0ka+vr0qUKKFatWpp9OjR+REbAAAAgEIg16Ti+PHjevzxx2U2m1WkSBG9+OKLOnHiRH7EBgAAAKAQyHVNhclkynYL2ZSUFG4pCwAAAOSkAC/UdpUbWqj9wgsvKDk5WcuWLdPy5ct1//3350dsAAAAAAqBG7ql7EcffSSr1art27crMjJSjz32WH7EBgAAABQ6BfmWsq6Sa1IhSR06dFCHDh1cHQsAAACAQijXpKJ9+/bXPL5mzRrDgwEAAABQ+OSaVIwZM8b+s8Vi0bp161SxYkWXBgUAAAAUWm7cL8Jdck0qwsLCsj1v1qyZOnfurH79+rksKAAAAACFxw2tqbjauXPn2FEbAAAAyAELta/h72sqEhMTFRkZ6bKAAAAAABQuDq2pMJlMKlWqlKpVq+bSoAAAAIBCizUVf9m3b58kyc/PL9vx9PR07du3T3Xq1HFtZAAAAAAKhRyTikGDBuX4IZPJpE2bNrkkIAAAAACFS45JxebNm/MzDgAAAODfgYXa/3T27FmtXr1aqampstlsslqtOnLkiKZOnZof8QEAAAAo4HJNKoYMGaKiRYvq0KFDatasmbZv365GjRrlR2wAAABAoWPywIXa5tzekJiYqHfffVctW7bUU089paVLlyohISE/YgMAAABQCOSaVJQuXVqSVLlyZR08eFBlypRRZmamywMDAAAAUDjk2v4UHBysuXPnqkGDBoqNjZW/v7/S09PzIzYAAACg8PHAhdq5ViomTJggHx8fNW7cWHXr1tW0adP0wgsv5EdsAAAAAAoBk81ms13rhffff1+PPvqo/P398zsm/Vyrer7PCQAFVY347e4OAQAKjhIh7o4gV5Z+7dw2d5GZ690yb46Vih07duiuu+5SdHS0Dh48mJ8xAQAAAChEckwqZs2apXXr1ikkJER9+/bVU089pfXr1ysrKys/4wMAAABQwF13TUWZMmU0cOBAbdq0Sb169dK6devUtm1bTZ8+Pb/iAwAAAAoVk8nktofbzjmnNRXXcuTIES1YsEDLly/X3r17XRdV2gXXjQ0AhUxfv4ruDgEACoxZtovuDiFXmf0fcNvc3jPWuWfe3N6Qnp6uTz75RCtWrNDRo0f12GOPaePGjfkRGwAAAFD4eOCO2jkmFXv37tWKFSu0YcMG1a5dW0899ZTatm0rLy+v/IwPAAAAQAGXY1LRo0cPdejQQcuWLVO1atXyMyYAAACg8PLAze9yTCq++uorFS9ePD9jAQAAAFAI5Xj3JxIKAAAAADci14XaAAAAABzgge1P192nAgAAAAByk2OlYuLEidf94OjRow0PBgAAACj0PLBSkWNSERQUlJ9xAAAAACikckwqBg4cmOOH0tLSXBIMAAAAgMIn14XaGzdu1LRp05SWliabzSar1arz589r9+7d+REfAAAAULiYPW/Zcq5JxWuvvaYhQ4Zo6dKl6t27tzZu3Cg/P7/8iA0AAABAIZBrGlWsWDG1a9dODRo0kK+vr8aNG6cvvvgiH0IDAAAACiGTyX0PN8k1qfD19dXly5dVqVIl7d+/X2azWSYPXNEOAAAA4NpybX9q3bq1oqKiNHnyZEVGRurbb79VyZIl8yM2AAAAAIVArklF37599dBDD6lMmTKaMWOGvvnmGz344IP5ERsAAABQ+HhgV0+uScW+ffskSefOnZMkNW7cWCdPnlRwcLBrIwMAAABQKOSaVAwaNMj+s8ViUVJSkurUqaMVK1a4NDAAAACgUKJS8U+bN2/O9jw+Pl5r1qxxWUAAAAAACheHd+YIDw+3t0QBAAAA+Buz2X0PN7nhNRWSZLPZ9OOPPyo9Pd2lQQEAAAAoPBxaU2EymRQcHKxx48a5MiYAAAAAhUiuScWSJUt08803Zzt26NAhlwUEAAAAFGoeuFA7x8ar8+fP6/z584qKitKFCxd0/vx5XbhwQUlJSRo4cGB+xggAAACgAMuxUjF06FBt27ZN0pXF2X/y8vLSfffd5/rIAAAAgMLIAysVOSYV7733niRp5MiRiomJybeAAAAAABQuud536tlnn7UvzE5ISFD//v2VlJTk6rgAAAAAFBK5JhUjRoxQ1apVJUnly5dXWFiYRo4c6fLAAAAAgELJZHLfw01yTSrOnTunbt26SZJ8fX3VvXt3nTlzxuWBAQAAACgccr2lbFZWlk6dOqUyZcpIkpKSkmSz2VweGAAAAFAouXFna3fJNano3r27OnTooDvvvFOStGPHDg0bNszlgQEAAAAoHHJNKjp16qS6devq66+/lpeXlypVqqQFCxaoffv2+REfAAAAgAIu16RCksqWLavLly9r8eLFSktLU9euXV0dFwAAAFA4sU9FdgkJCXr//fe1evVqlS9fXunp6dq8ebMCAgLyKz4AAAAABVyOq0iioqL01FNPqUiRIlqwYIHWrl0rPz8/EgoAAADgeril7F/+97//qU6dOqpRo4ZCQ0MlSSYPLOUAAAAAuL4c25+++OILffbZZ1q6dKleeeUV3XXXXcrIyMjP2AAAAIDCxwMvxOdYqfD29la7du20cOFCrVq1SiEhIcrIyNC9996rpUuX5meMAAAAAAqwG9qZo3r16ho9erS2bNminj176oMPPnB1XAAAAAAKiRu6peyfihUrpsjISEVGRroqHgAAAKBQM3ngjtqed8YAAAAADOVQpQIAAABALlioDQAAAACOIakAAAAA4BTanwAAAAAj0f4EAAAAAI6hUgEAAAAYiUoFAAAAADiGpAIAAACAU2h/AgAAAIzEjtoAAAAA4BgqFQAAAICRWKgNAAAAAI6hUgEAAAAYiUoFAAAAADiGpAIAAACAU2h/AgAAAIxE+xMAAAAAOIZKBQAAAGAkNr8DAAAAAMeQVAAAAABwCu1PAAAAgJFYqA0AAAAAjqFSAQAAABiJSgUAAAAAOIakAgAAAIBTaH8CAAAAjMQ+FQAAAADgGCoVAAAAgJFYqA0AAAAAjqFSAQAAABiJSgUAAAAAOIakAgAAAIBTaH8CAAAAjET7EwAAAAA4hkoFAAAAYCQ2vwMAAAAAx5BUAAAAAHAK7U8AAACAkVioDQAAAACOoVIBAAAAGIlKBQAAAAA4hqQCAAAAgFNofwIAAACMZPK86/aed8YAAACAB/v999/VqlUr/fLLLzpy5IieeOIJdenSRWPHjpXVas3TmCQVAAAAgJHMJvc9cmGxWBQdHa2iRYtKkmJiYjRkyBAtWbJENptNmzZtytsp5+lTAAAAAAqdyZMnq3PnzgoJCZEk7du3T2FhYZKkli1bavv27Xkal6QCAAAAMJLJ7LZHXFycOnbsaH/ExcXZw1q1apVKlSqlO++8037MZrPJ9MctcP38/JScnJynU2ahNgAAAPAvERkZqcjIyGu+tnLlSplMJu3YsUP79+/X8OHDdfbsWfvrqampCgwMzNO8JBUAAACAB1i8eLH9565du2rcuHGaMmWK4uPjFR4eri1btuiOO+7I09i0PwEAAABGMpnc93DQ8OHDFRsbq8jISFksFkVEROTplKlUAAAAAB5m4cKF9p8XLVrk9HgkFQAAAICRzJ7XDOR5ZwwAAADAUCQVAAAAAJxC+xMAAABgpDwsmC7sqFQAAAAAcAqVCgAAAMBIJs+7bu95ZwwAAADAUCQVAAAAAJxC+xMAAABgJBZqAwAAAIBjqFQAAAAARmJHbQAAAABwDJUKAAAAwEisqQAAAAAAx5BUAAAAAHAK7U8AAACAkdhRGwAAAAAcQ6UCAAAAMJKZhdoAAAAA4BCSCgAAAABOof0JAAAAMBILtQEAAADAMVQqAAAAACOxozYAAAAAOIakAgAAAIBTaH8CAAAAjMRCbQAAAABwDJUKAAAAwEjsqA0AAAAAjqFSAQAAABiJW8oCAAAAgGNIKgAAAAA4hfYnAAAAwEjcUhYAAAAAHEOlAgAAADASt5QFAAAAAMeQVAAAAABwCu1PAAAAgJFYqA0AAAAAjqFSAQAAABiJHbUBAAAAwDEkFQAAAACcQvsTAAAAYCQWagMAAACAY6hUAAAAAEZiR20AAAAAcAyVCgAAAMBIrKkAAAAAAMeQVAAAAABwCkkFDHMsMVENW9ytrr362h/TZ8/N8f0josdry7YdeZ6vdbuHtWBJnP35L4d/VddeffM83t99vvm/OnX6jM4kJWncpMlOjbXru916f8kyp8YYNnqsHu/2jJYuX6m4lR/e0GfS09M1fMw42Ww2p+YG4HqPvv6Knv/vOo3bv0uTjuzT8/9dp94fvG/Y+K8c/kFDv9yg5zav1fNfrFeflYvk6+/v0BgRw59T5SaN5O3rq+Y9u0mSmj7dRbe1v9+p2B5/a7KCypdTcOVQjdq9VU/Pn6XH3nxVJStWuKHP173/XjXr8ZRTMQCGMpnc93AT1lTAUNWrVtHCubPybb75i5aoRbM7VLVyqOFjL1gSp3Gjqqhalcoa99LwPI9js9kUO3uO5kx/26l4tu6I1/ZNnzj0maJFi+r2+rfpozXr9MhDDzo1PwDXWvnCKElXvqSXqXWLPho5zvA53r63gzIzMiRJj7w6Xs16PKX/xt7439mfTn5TkhQcWknNez2tbe8t0I73lzgVU5XwJsrKzNT544kKezJSBzZ9af9d3KgfN3ymgetX6ruVq5V+8aJT8QDIG5IKuFxWVpaiJ8bo5KlTOnf+glo2b6YhA/6qKBw+ckQjoyfI29tbXt5eeu3lcSoTEqKp097RN9/tls1qVfeuXXR/2zb/GHvE0CEaET1eS/8zJ9vxn34+pImvTZVsNgWVKKFJ48bI399P42Ne04//26/SwcE6npiomW9PVVraJb069S1ZrVZdTE7W6GEv6GLyRe3/6aCGjxmnKa+M1/Ax4zVh9P/bu/O4qOr9j+PvGQYEGUBJ00oj1BSX0q4W1yXSUnPJJTM1uuaSaS4/RdQE99xzy6ul5lIueXO7hEtqpqXmkqbtrrmgKQhqrCEgML8/vE2RWk5zxqF4PR8PHg/mzMx3GR8d+szn8zknWhOnzdDS+XMlSb36D9SAPi8rI+Mnvf7mXHmYzSpfvpzGDo+Wp+cv/2nt/myfKgUHy8vTU/sOHNSCd5bK09NT5+Lj1aJpY/Xu0V3n4uM1/NXxyr2aK5PJpBGvDFJIlcr2McZMfE1paWnqHTFYTR5vqFOn49Tp2XbqPWCQSgQEKKxBPYXVr3fdnv38rGretLF69B1AUAH8RVV+rIGefm2scnNytGv+YrUeN1yjQ+ooNztbbSeNUeLR49q75D9qO3G07g+rL5PZrK0z3tAXa2JvOqbJZJJPiQAlHvteZotFL7w9R6UrBsvs4aGtM97QwVUxeqx3D/2zS7hs+fk6sWuvYl4ZqS7vzNXnK/6rfzzTWndVq6IWI4fKbDYr9UKiylSupHNff6fPlv5H/mXuVN8PVmtSncf+cF2N+r+srdNnq2T5cmoxYoi8ivvo4olTqtOxnZa/HKGHO7VXhXqhKmb11bIX+yqkcSM9Ev6sbDabDqz4rz0o+m7jFtXtEu5QkAS4jLnoFQMVvR3DpU6cOl2g/CkxKUkJiYmq9UANLZozW++9s0Dvrflvgffs+Wy/qlcN0Tvz3tTLL3ZTalq6duzao3Pn47Vi8UItXTBX8xa+o7T09Ovme6xBPVWuVFELFi8tcHzkuIkaHTVEyxbOU1iDelq4ZKm2bd+plNRUrXl3sSaOHqGEC4nX1nzylIZGDtDit95Ut87hilm3Xg0fbaCqVSrrtXFj5OnpKUkKqXy/srOydT4+QUkXLyk5JVVVq1TWyHET9Mb01/TuordUpnRpvb9+Q4G17D/whapUvt/+OD7hgmZPm6yVSxZp4ZJlkqQpM2apc6eOWv72fA1/ZZCGvTq+wBhjhg1VQIC/5s6cVuD4xUuXtWjubL3U9YUb7lmSAvz9lZySovT0jFv+dwRQuHh6F9P0sGba9+6NyyirN2uiO4Lv09QGTTWjUUs1Hz5YPgEB171uwJZYDfx4gwZsXafM5BR9tvQ9hfXqrp8uXdbU+k00s3FrtRk/Ur53BKput39p1YChmlKvsS6dipPZw8M+zqYJ05Rw+Jg2jvulNHTXgsX6Z5fnJEmhnTtp7zvLb2ldlR+rr/jvDiv5h3P6cPIM7f/Pau2ct6jAay4cOaap9ZvIZDKpTsd2mtqgqaY1aKqabVuqTOVKkqTz33ynyg0b/JmPF4AByFTAUDcqf8rIyNC3h4/oswMHZfX1VU7O1QLPt2/bWgsWL1WPfv3lZ7VqYL8+On7ihA4dOWrvkcjNzVV8fIL8q/hdN2fUoAg983wX3Vvul9rbk6dP69VJUyRJV3NzFRx0r06djlOtBx+QJAUGllSF4PskSXfeWVpzFiySd7Fi+ikzU1Zf35vur33b1ordsFFeXp5q1/op/ZicrKRLlxXxyjBJUlZ2tur/M7TAe5JTUlTzgRr2x5XvryiLxSKLxSLvYsXs63249kOSpKpVKutCYtJN1/Br5e65W17/C3putOeflQoMVEpaqvz8HKufBlA4JB77/obHTf+rn77ngWoKql1LkZ98IEny8PRUYFB5nf8mtcDrf13+9LOyVavo6NZPJEnZGRlKOHxUpStW0NJuvdVkcH89/dqrOrV3/x/Wal84elweFosC7y2vOh3baWbjNnq0Z9c/XJfJw0O5OTm3tP+7a1RTYFB5Ddy2XpJUvGQJla5UUYnHTyg1IVG+dwT+7jgAXIegAi4Xs+4D+flZNXZEtM6c/UGrYmILNA5v275TtR+qpX69XtKGTR9q4eKlatyooUIfrq1xI4cpPz9fcxYsUrly99xwfKuvr8aOiFZk1HBVuO8+SVJwUJBeGzdGd99VVge/+loXL15SsWJeWvvBJun555Salqa4M2clSROmTNe0CWNVsUKwZs2dr/Px8ZIkk9kkW35+gblaNGuqrr36ymQy6e05s1S8eHGVLXOn5rw+TX5+Vm3bvlPFi/sUeE9gYEml/yrLYtL1f5grBgfrwBdf6YmGYTpy7LhK3eIfRvOv0qs32vPP0tIzFFiy5C2NCaDwyc//5Zx5NStbAXeV1eW4MypX60FdOHJMF44e17FPdmp5qSGNeQAAFjRJREFUrwEymUxqMXKoLp2Ku6WxLxw5pkqP1tNXsRtUzGrV3Q9U0+XTcWo+fIiWvxyh3Oxs/d/m91Wx3i9fmOTn5xc4//xs96JlajdlrBIOH9OV1NRbWtfVK1dkMpuvO98W3P+15y4c+14Jh45qdvN2kqQnIvrq/LeHJF0LMNKTLt7SngGXc2PDtLsQVMDl6obWUWTUCB384iv5+Pgo6N7ySrr4y4m/RrWqGjJ8lGZb5stsMit68EBVC6mi/QcOKrz7S8rMvKLGjRr+bgYhtE5ttWzWVEeOHpd0rVxo6MgxysvPkyRNGD1C9917r3bu3qtOXV5UqVJ3yNvbW54Wi1q3aKY+AwfrjjsCVfbOMkpOSZEkPVTzQb0ycozGjRxmn8e3eHGFVL5fuXl5sv7vqinDh0SqZ/+BsuXny9fqqynjxhRcW+3a+uiT7WrbquVN1/9KZH+NHDtRby99V7m5uZoweoRjH/JN9ixJaenp8vezyrd4cYfHBFD4bJkyU/02rtHluLPKTL52vvpm/SZVbvioBu3crGJWX331/gZlZ9xayeOn89/RvxbM1uBPP5Snj7c+ePU1pV+8pPPfHlL059uVfvGSUs4n6PS+A/YrLKUnXZSHl6eenvyqrl7Jso91cPX76vDvyZrTutMtr+vk7n269x+1dObAF3+41vPffKej27ZryK4tshTzUtz+L5Ry/toXQcGhdXR0245b2jMA45lshfFak5mpf/wawEEnT8fp6LHjatmsqZJTUvRU+076ZOM6eXl5uXTe/Px8denZR4vmzraXKt1Oy1etkdXXV21aOnfJR7jPy77l3b0EwGWC//mIHu70jFZF/Pmr7EnS/22K0YIOXZR1g/47/L3MsxX+K3zlffiO2+b2eLKbW+alURtFxl1ly2jD5i3q8EJ39eg7QIP793N5QCFdK1Hq26uH/rNqjcvn+q2srCx98dXXatX8yds+NwDcitOf7ZfZYlGJe+7+02PUaPGkvvzvWgIKwI3IVABAIUemAgB+Qabi97krU0FPBQAAAGCkItioTfkTAAAAAKeQqQAAAACMxB21jZWRkaFjx44pMzPTldMAAAAAcCOXZSo2b96sefPmKS8vT82aNZPJZFKfPn1cNR0AAABQONBTYZzFixdr1apVKlGihPr06aOtW7e6aioAAAAAbuSyoMJsNsvLy0smk0kmk0k+Pj6umgoAAACAG7ms/KlOnTqKjIxUYmKiRo0apQceeMBVUwEAAACFh6noNWq7LKiIjIzUzp07Va1aNVWsWFGNGjVy1VQAAAAA3MhlYVRsbKx+/PFHlSpVSqmpqYqNjXXVVAAAAEDhYTK578dNXJapOHnypCTJZrPpyJEjKlGihNq2beuq6QAAAAC4icuCikGDBtl/t9ls6tWrl6umAgyVl5enEeMm6nTcGXmYzZr06ijdW76cu5cFALfFfY/UUbvXXtWMRi1VumIFdVk8VzabTfHfHdaKvoNks9lUt0u4wnr3kNnDrK/XbtTG8VPcvWwAbuay8qecnBz7T3x8vM6dO+eqqQBDfbLzU0nSisUL1b9PL02aPtPNKwKA26PpkAHqvHC2LN7ekqT2MyZq3Yhxmh527X5TNdu0VKkKwQrr3UMzGrbQ5EcaycPLS2aLy76jBP6aTGb3/biJy84CP9/wzmazydvbWy+++KKrpgIM1bhRQzV8tIEkKT4+QaXuCHTzigDg9rh48rTeavcvdV02X5IUVLuWju/YJUk6tOkjVW36hPzuLK0zB75U1yXz5H9XWW2aME35ubnuXDaAQsBlQcWAAQPUpk0bVw0PuJTFYtHQkWP00Sc7NGvqJHcvBwBuiy9j1umOoHt/OfCrps+s9Az5BPjLWuoO3R9WT1PqNZGXj7eG7P5Ikx5uqCupqW5YMVBImbmjtmFWr17tqqGB2+K1cWP0YexqjRw7UZlXrrh7OQBw29ny8+2/e/tZdSUlVRmXf9Tx7buUnZGh9IuXlHD4qMpUruTGVQIoDFyWqcjJyVHbtm0VHBwss/la7DJ9+nRXTQcYJnbDRiUmJqnXi13l4+0tk9kkD3PRu4kNAPzw5Teq/FgDHd+xS9WbN9GxTz5VwuGjatj3JVmKFZPZw0N3VQtR0olT7l4qADczPKiIiIjQzJkzNXjwYKOHBm6Lpk80UvTosXq+e0/l5uZq2OBIFStWzN3LAoDbbs2g4frXglmyeHkp4cgxfbEmVrb8fO1etExDdm+RyWTSB+OmKDM52d1LBQqXInhHbZPNZrMZOeALL7ygpUuXOjdIJnWZAPCzl33Lu3sJAFBozLOluXsJfyjvU/e1AXg8+qxb5jU8U/HDDz9oxowZN3wuMjLS6OkAAACAwsWNd7Z2F8ODCm9vbwUHBxs9LAAAAIBCyvCgolSpUnr66aeNHhYAAAD4ayiCPRWG77hGjRpGDwkAAACgEDM8qBg6dKjRQwIAAAAoxFx2nwoAAACgKDIVwUbtolfwBQAAAMBQZCoAAAAAI9GoDQAAAACOIagAAAAA4BTKnwAAAAAjUf4EAAAAAI4hUwEAAAAYycwlZQEAAADAIWQqAAAAACPRUwEAAAAAjiGoAAAAAOAUyp8AAAAAI5lo1AYAAAAAh5CpAAAAAIxEozYAAAAAOIagAgAAAIBTKH8CAAAAjESjNgAAAAA4hkwFAAAAYCQatQEAAADAMQQVAAAAAJxC+RMAAABgJDON2gAAAADgEDIVAAAAgJFo1AYAAAAAx5CpAAAAAIzEze8AAAAAwDEEFQAAAACcQvkTAAAAYKQi2KhNUAEAAAAUAVevXtWwYcN0/vx55eTkqHfv3qpUqZKioqJkMpl0//33a/To0TKbHQ+KCCoAAAAAIxXSRu1169apRIkSmjp1qpKTk/X0008rJCREERERCg0N1ahRo7Rt2zY1adLE4bGLXm4GAAAAKIKaNWumAQMG2B97eHjo0KFDeuSRRyRJYWFh2rNnz58am6ACAAAA+JtYuXKl2rVrZ/9ZuXKl/TlfX19ZrVZlZGSof//+ioiIkM1mk+l/mRVfX1+lp6f/qXkpfwIAAACM5MZG7Y4dO6pjx443fT4hIUF9+/ZVeHi4WrVqpalTp9qf++mnn+Tv7/+n5iVTAQAAABQBly5dUvfu3TVkyBC1b99eklStWjXt27dPkrRz507VqVPnT41NpgIAAAAw0p+4etLtMG/ePKWlpWnOnDmaM2eOJGn48OEaP368ZsyYoQoVKujJJ5/8U2ObbDabzcjFGiIz1d0rAIBC42Xf8u5eAgAUGvNsae5ewh/KP7rXbXObQ+q6Z163zAoAAADgb4PyJwAAAMBApkJ6nwpXIlMBAAAAwClkKgAAAAAjufGSsu5S9HYMAAAAwFBkKgAAAAAj0VMBAAAAAI4hqAAAAADgFMqfAAAAACPRqA0AAAAAjiFTAQAAABiJRm0AAAAAcAxBBQAAAACnUP4EAAAAGMlc9L63L3o7BgAAAGAoMhUAAACAkWjUBgAAAADHEFQAAAAAcArlTwAAAICRuKM2AAAAADiGTAUAAABgJBq1AQAAAMAxZCoAAAAAQ5GpAAAAAACHEFQAAAAAcArlTwAAAICRaNQGAAAAAMeQqQAAAACMRKYCAAAAABxDUAEAAADAKZQ/AQAAAIai/AkAAAAAHEKmAgAAADASjdoAAAAA4BiCCgAAAABOofwJAAAAMFLRq34iUwEAAADAOWQqAAAAAEMVvVQFmQoAAAAATiFTAQAAABiJS8oCAAAAgGMIKgAAAAA4hfInAAAAwEiUPwEAAACAY8hUAAAAAIYiUwEAAAAADiGoAAAAAOAUyp8AAAAAI9GoDQAAAACOIVMBAAAAGIpMBQAAAAA4hKACAAAAgFMofwIAAACMRKM2AAAAADiGTAUAAABgJDIVAAAAAOAYMhUAAACAochUAAAAAIBDCCoAAAAAOIXyJwAAAMBAJhq1AQAAAMAxZCoAAAAAI5GpAAAAAADHEFQAAAAAcArlTwAAAIChKH8CAAAAAIeQqQAAAACMRKM2AAAAADiGoAIAAACAUyh/AgAAAIxE+RMAAAAAOIZMBQAAAGAoMhUAAAAA4BAyFQAAAICR6KkAAAAAAMcQVAAAAABwCuVPAAAAgJGKXvUTmQoAAAAAziFTAQAAABiq6KUqyFQAAAAAcApBBQAAAACnUP4EAAAAGIn7VAAAAACAY8hUAAAAAEYiUwEAAAAAjiGoAAAAAOAUyp8AAAAAQ1H+BAAAAAAOIVMBAAAAGIlGbQAAAABwDJkKAAAAwEhkKgAAAADAMQQVAAAAAJxC+RMAAABgKMqfAAAAAMAhZCoAAAAAI9GoDQAAAACOMdlsNpu7FwEAAADgr4tMBQAAAACnEFQAAAAAcApBBQAAAACnEFQAAAAAcApBBQAAAACnEFQAAAAAcApBBQAAAACncEdtFCnnzp1T69atVb16dfux0NBQ9evX77rXRkVFqUWLFgoLC7udSwSA227y5Mk6dOiQLl68qKysLJUvX14lS5bUrFmz3L00AH8RBBUocipVqqRly5a5exkAUGhERUVJkmJiYnTq1CkNHjzYzSsC8FdDUIEiLy8vT6NGjdKFCxeUnJyssLAwRURE2J8/ffq0oqOjZbFY5OHhoSlTpqhMmTKaPn26Pv/8c9lsNnXt2lXNmzd34y4AwFj79u3TtGnT5OnpqQ4dOmjWrFnatGmTihUrpmnTpqlChQpq164d50IAkggqUASdOHFCnTt3tj+OiIhQrVq19Oyzzyo7O/u6oGLPnj2qXr26oqKidODAAaWmpuro0aM6d+6cVqxYoezsbHXo0EH169eXv7+/O7YEAC6RnZ2t1atXS9INS6F27NjBuRCAJIIKFEG/LX/KyMjQ2rVr9dlnn8lqtSonJ6fA69u3b68FCxaoR48e8vPz08CBA3X8+HEdOnTIHpzk5uYqPj6eP6QA/laCg4NveNxms0kS50IAdlz9CUVeTEyM/Pz8NH36dHXv3l1ZWVn2P5iStG3bNtWuXVtLlixRs2bNtHDhQlWoUEGhoaFatmyZlixZoubNm6tcuXJu3AUAGM9s/uV/E7y8vJSUlCSbzaajR49KEudCAHZkKlDk1a1bV5GRkTp48KB8fHwUFBSkpKQk+/M1atTQkCFDNHv2bJnNZkVHR6tatWrav3+/wsPDlZmZqcaNG8tqtbpxFwDgWj169FDPnj11zz332DMRjz/+OOdCAJIkk+3XX8kCAAAAgIMofwIAAADgFIIKAAAAAE4hqAAAAADgFIIKAAAAAE4hqAAAAADgFIIKAAAAAE4hqAAAAADgFIIKAAAAAE4hqAAAAADgFIIKAAAAAE4hqAAAAADgFIIKAAAAAE4hqAAAAADgFIIKAAAAAE4hqAAAAADgFIIKAAAAAE4hqAAAAADgFIIKAEXKuXPnVLVqVbVp08b+07p1a61Zs8bpsXv16qWYmBhJUps2bZSWlnbT16anp+uFF15weI7Nmzerc+fO1x3v3Lmz5s+ff93xt99+W7179/7dMaOiorRo0SKH1wIAwM8s7l4AANxu3t7eWrt2rf1xYmKinnrqKdWoUUMhISGGzPHr8W8kNTVV3377rSFzSVJ4eLhmzpypnj17Fji+atUqjRgxwrB5AAC4EYIKAEVemTJlFBQUpLi4OB0+fFhr1qzRlStXZLVatWzZMq1evVrvvfee8vPzVaJECY0cOVIVK1ZUYmKioqKilJSUpLvvvluXL1+2j1mlShXt3btXgYGBeuutt/T+++/LYrEoKChIkydPVnR0tLKystSmTRvFxMQoLi5OEyZMUEpKivLy8tS5c2e1b99ekvTvf/9b69evV4kSJRQUFHTDPTRp0kQTJ07UgQMHVKdOHUnS/v37ZbPZVL9+feXn52vixIn6+uuv9dNPP8lms2n8+PGqXbt2gXF+ve7fPv744481d+5cXb16Vd7e3ho6dKgeeughnTx5UsOHD1dOTo5sNpvat2+v559/3hX/VACAQoqgAkCR9+WXX+rs2bOqWbOm9u7dqxMnTujjjz+W1WrV/v37FRsbq+XLl8vHx0e7du1Sv379tGnTJo0dO1Y1a9ZURESEzpw5o7Zt21439rZt2xQTE6NVq1YpICBAkyZN0rvvvqtJkyapVatWWrt2rXJzc9W/f39NmTJF1atXV3p6ujp27KhKlSrp0qVL2rJli2JjY+Xt7a2+ffvecA8Wi0UdOnTQmjVr7EHFypUrFR4eLpPJpK+++kpJSUlauXKlzGaz5s+frwULFlwXVNxMXFycXn/9dS1dulQlS5bU999/r27dumnLli1atGiRHn/8cfXs2VMXL17UxIkT9dxzz8lspsIWAIoKggoARc7PGQJJysvLU8mSJTV16lTdddddkq59O2+1WiVJ27dv15kzZ9SpUyf7+9PS0pSSkqI9e/Zo6NChkqSgoCCFhoZeN9fevXvVrFkzBQQESJKio6MlXevt+FlcXJzOnj2rYcOGFVjj4cOHdfLkSTVp0sS+nmeeeUbLli274b46dOigli1bKiMjQ7m5udq1a5fGjBkjSXrooYcUEBCgFStW6IcfftC+ffvk6+t7y5/Z7t27lZSUpK5du9qPmUwmnT17Vk2aNNHQoUP1zTffqG7duhoxYgQBBQAUMQQVAIqc3/ZU/Fbx4sXtv+fn56tNmzYaMmSI/XFSUpICAgJkMplks9nsr7VYrj+lenh4yGQy2R+npaVd18Cdl5cnPz+/Amu6dOmS/Pz8NGXKlAJzeHh43HTdZcqUUb169bRx40ZlZmbqySeflJ+fn6RrwdGECRPUrVs3PfHEE6pQoYLWrVt307EkKScnp8DnULduXc2cOdN+LCEhQXfeeadCQkL04Ycfas+ePdq7d6/efPNNxcTEqGzZsr87PgDg74OvkgDgdzRo0EAffPCBkpKSJEnvvfeeunTpIkl69NFHtXLlSklSfHy89u3bd93769Wrp48++kgZGRmSpNmzZ2vx4sWyWCzKy8uTzWZTcHBwgUAnISFBTz31lL777juFhYVp8+bNSktLU35+/h82gD///PNav369YmNjC/Q17N69W40aNVJ4eLhq1KihrVu3Ki8v77r3BwYG2hvIN2zYYD9et25d7d69WydPnpQk7dixQ61bt1ZWVpYGDRqkjRs3qmXLlho9erSsVqvOnj17ax8wAOBvgUwFAPyOBg0a6KWXXlL37t1lMplktVr1xhtvyGQyafTo0YqOjlbz5s1VtmzZG1456rHHHtOJEyf03HPPSZIqVaqkcePGycfHRw8++KBatmyp5cuXa86cOZowYYIWLlyo3NxcDRgwwN7vcOzYMT3zzDPy9/dXSEiIkpOTb7re0NBQjR8/XgEBAapSpYr9eKdOnTRo0CC1atVKubm5ql+/vrZs2aL8/PwC7x8xYoTGjh0rf39/1atXT6VLl7ave+zYsYqMjJTNZpPFYtHcuXPl6+urPn36aPjw4Vq5cqU8PDzUuHFjPfzww05/9gCAvw6T7dd5dQAAAABwEOVPAAAAAJxCUAEAAADAKQQVAAAAAJxCUAEAAADAKQQVAAAAAJxCUAEAAADAKQQVAAAAAJzy/yqQvHe4S/IQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "modelDf['cms'].values[5]\n",
    "\n",
    "plot_confusion_matrix_2(modelDf['cms'].values[5],normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(x=test_images, steps=len(test_images), verbose=0)\n",
    "# cm = confusion_matrix(y_true=test_labels, y_pred=np.argmax(prediction, axis=-1))\n",
    "# print(np.argmax(prediction, axis=-1).shape)\n",
    "# print(test_labels.shape)\n",
    "\n",
    "predictions2 = model.predict(x=test_data_images, steps=len(test_data_images), verbose=0)\n",
    "cm2 = confusion_matrix(y_true=test_data_labels, y_pred=np.argmax(predictions2, axis=-1))\n",
    "# print(np.argmax(predictions2, axis=-1).shape)\n",
    "# print(test_data_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# modelDf['test_cms'].values[0]\n",
    "# plot_confusion_matrix_2(modelDf['test_cms'].values[0],normalize=False)\n",
    "\n",
    "plot_confusion_matrix_2(cm2,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_m</th>\n",
       "      <th>precision_m</th>\n",
       "      <th>recall_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70714</td>\n",
       "      <td>0.550792</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.568331</td>\n",
       "      <td>0.982416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     loss  accuracy    f1_m  precision_m  recall_m\n",
       "0      0  0.70714  0.550792  0.7145     0.568331  0.982416"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "history_df = pd.DataFrame(histories[0].history).reset_index()\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_chart(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "\n",
    "# for i in range(len(list(modelDf.optimizers))):\n",
    "#     cls = modelDf.iloc[i,2]\n",
    "#     plot_confusion_matrix_2(modelDf[modelDf['optimizers']==cls]['cms'][i])\n",
    "#     ax.title.set_text(type(cls).__name__)\n",
    "# plt.tight_layout()  \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_predictions_baseline = model.predict(train_images)\n",
    "# test_predictions_baseline = model.predict(test_images)\n",
    "plot_roc(\"Train Baseline\", train_labels, predictions, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", test_data_labels, predictions2, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a7e1b17602ce2ea468a951908af7bc23f5fb404bcd43f493b2f049dccd7860b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('wild_fire_detection_capstone': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
