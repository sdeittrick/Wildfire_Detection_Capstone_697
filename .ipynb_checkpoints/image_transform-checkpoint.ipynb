{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow\n",
    "# check out https://www.tensorflow.org/tutorials/images/cnn\n",
    "# can run and compare results in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorboard\n",
    "tensorboardPath = \"C:/users/npess/appdata/roaming/python/python37/site-packages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python C:/users/npess/appdata/roaming/python/python37/site-packages/tensorflow/tensorboard/tensorboard.py --logdir=C:/Capstone/Wildfire_Detection_Capstone_697/logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# # !pip install -q tf-nightly-2.0-preview\n",
    "# !pip install tf-nightly-gpu-2.0-preview\n",
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "# # Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# import required libaries to process images\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import altair as alt\n",
    " \n",
    "#using Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "! rm -rf ./logs/\n",
    "# print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tf-nightly-2.0-preview\n",
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs_base_dir = \"./logs\"\n",
    "# os.makedirs(logs_base_dir, exist_ok=True)\n",
    "# %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and examining the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    width, height = img.size\n",
    "    ratio = width/height\n",
    "    new_height = 100\n",
    "    new_width = int(new_height*ratio)\n",
    "    img = img.resize((new_width, new_height))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow this on zero padding vs resizing and how it effects accuracy \n",
    "# mabye something we talk to Jiaqi about\n",
    "def pad_images(images, width_max, length_max): \n",
    "    padded_images = [] \n",
    "    c = 0 \n",
    "    for image in images: \n",
    "        wpad1 = (width_max - image.shape[0])/2\n",
    "        lpad1 = (length_max - image.shape[1])/2\n",
    "\n",
    "        if lpad1%1 > 0: \n",
    "            lpad1 = int(lpad1)\n",
    "            lpad2 = int(lpad1)+1\n",
    "        else: \n",
    "            lpad1 = int(lpad1)\n",
    "            lpad2 = int(lpad1)\n",
    "\n",
    "        if wpad1%1 > 0: \n",
    "            wpad1 = int(wpad1)\n",
    "            wpad2 = int(wpad1)+1\n",
    "        else: \n",
    "            wpad1 = int(wpad1)\n",
    "            wpad2 = int(wpad1)\n",
    "        try:\n",
    "            padded_images.append(np.pad(image, pad_width=[(wpad1 , wpad2),(lpad1, lpad2),(0, 0)], mode='constant'))\n",
    "        except: \n",
    "            print(\"at {}\".format(c))\n",
    "        c = c + 1\n",
    "    return padded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop images to center based on full dataset mean_size\n",
    "def crop_images(images, width_mean, length_mean):\n",
    "    train_padded_c = []\n",
    "    for image in images: \n",
    "        \n",
    "        left = int((image.shape[0] - int(width_mean))/2)\n",
    "        top = int((image.shape[1] - int(length_mean))/2)\n",
    "        right = int((image.shape[0] + int(width_mean))/2)\n",
    "        bottom = int((image.shape[1] + int(length_mean))/2)\n",
    "\n",
    "        train_padded_c.append(image[left:right, top:bottom])\n",
    "    return train_padded_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out the shape for standardization\n",
    "def shaping (all_images):\n",
    "    width_means = []\n",
    "    length_means = []\n",
    "    for array in all_images:\n",
    "\n",
    "    #     print(array.shape)\n",
    "\n",
    "        #width to length ratio\n",
    "    #     print(array.shape[0]/array.shape[1])\n",
    "\n",
    "        #width & length means\n",
    "        width_means.append(array.shape[0])\n",
    "        length_means.append(array.shape[1])\n",
    "\n",
    "    width_mean = np.mean(width_means)\n",
    "    length_mean = np.mean(length_means)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_stats(image_arrays):\n",
    "    widths = [array.shape[0] for array in image_arrays]\n",
    "    lengths = [array.shape[1] for array in image_arrays]\n",
    "    width_mean = np.mean(widths)\n",
    "    length_mean = np.mean(lengths)\n",
    "    width_max = np.max(widths)\n",
    "    length_max = np.max(lengths)\n",
    "    return length_mean, length_max, width_max, width_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images2(img_dir, type, height):\n",
    "    ''' Type as int 0 no_fire 1 fire\n",
    "        desired height of image as int \n",
    "        img_dir as str folder name where images stored'''\n",
    "\n",
    "    #get list of images \n",
    "    dir = os.getcwd()\n",
    "    rootdir = '{}/assets/{}'.format(dir, img_dir)\n",
    "    data = []\n",
    "    try:\n",
    "        images = os.listdir(rootdir)\n",
    "        image_file = [file for file in images if '.DS_Store' not in file]\n",
    "        try:\n",
    "            image_arrays = [np.asarray(resize_image(Image.open(f'{rootdir}/{image}'))) for image in image_file]\n",
    "            label_arrays = []\n",
    "            for array in image_arrays:\n",
    "                label_arrays.append([type])\n",
    "            image_labels = label_arrays\n",
    "            data.extend(list(zip(image_arrays, image_labels)))\n",
    "        except:\n",
    "            for subpath in os.listdir(rootdir):\n",
    "                d = os.path.join(rootdir, subpath)\n",
    "                images = os.listdir(d)\n",
    "                image_file = [file for file in images if '.DS_Store' not in file]\n",
    "                try:\n",
    "                    image_arrays = [np.asarray(resize_image(Image.open(f'{d}/{image}'))) for image in image_file]\n",
    "                    label_arrays = []\n",
    "                    for array in image_arrays:\n",
    "                        label_arrays.append([type])\n",
    "                    image_labels = label_arrays\n",
    "                    data.extend(list(zip(image_arrays, image_labels)))\n",
    "                except:\n",
    "                    for subpath in os.listdir(d):\n",
    "                        d2 = os.path.join(d,subpath)\n",
    "                        images = os.listdir(d2)\n",
    "                        print('d2 section')\n",
    "                        image_file = [file for file in images if '.DS_Store' not in file]\n",
    "                        if len(image_file)>1:\n",
    "                            try:\n",
    "                                print('final try')\n",
    "                                image_arrays = [np.asarray(resize_image(Image.open(f'{d2}/{image}'))) for image in image_file]\n",
    "                                label_arrays = []\n",
    "                                for array in image_arrays:\n",
    "                                    label_arrays.append([type])\n",
    "                                image_labels = label_arrays\n",
    "                                data.extend(list(zip(image_arrays, image_labels)))\n",
    "                                print(data)\n",
    "                            except:\n",
    "                                pass\n",
    "                        else:\n",
    "                            pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #get_labels\n",
    "    print('data')\n",
    "    print(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_dir, type, height, aug=False):\n",
    "    ''' Type as int 0 no_fire 1 fire\n",
    "        desired height of image as int \n",
    "        img_dir as str folder name where images stored'''\n",
    "\n",
    "    #get list of images\n",
    "    if aug:\n",
    "        image_file = img_dir\n",
    "        image_arrays = [np.asarray(resize_image(image)) for image in image_file]\n",
    "    else:\n",
    "        dir = os.getcwd()\n",
    "        images = os.listdir('{}/assets/{}'.format(dir, img_dir))\n",
    "        image_file = [file for file in images if '.DS_Store' not in file]\n",
    "        image_arrays = [np.asarray(resize_image(Image.open('{}/assets/{}/{}'.format(dir,img_dir, image)))) for image in image_file]\n",
    "        paths = ['{}/assets/{}/{}'.format(dir,img_dir, image) for image in image_file]\n",
    "#         print(paths) #for gitignore\n",
    "    \n",
    "    #get_labels\n",
    "    label_arrays = []\n",
    "    for array in image_arrays:\n",
    "        label_arrays.append([type])\n",
    "    image_labels = label_arrays\n",
    "\n",
    "    data = list(zip(image_arrays, image_labels))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeImgs (datasets,folders,subfolders,smokeTypes,timeOfDay):\n",
    "    data = []\n",
    "    for dataset in datasets:\n",
    "        if dataset.str.contains('-'):\n",
    "            for smokeType in smokeTypes:\n",
    "                for time in timeOfDay:\n",
    "                    data.extend(load_images(f'{dataset}/{smokeType}/{time}', 1, 100))   \n",
    "        else:\n",
    "            data.extend(load_images({dataset}, 1, 100))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wildfire_train_set_Unprocessed = load_images2('wildfire_train_set - Unprocessed', 1, 100)\n",
    "# wildfire_test_set = load_images2('wildfire_test_set', 1, 100)\n",
    "# mountain_test_set = load_images2('mountain_test_set', 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_test_set = load_images('wildfire_test_set', 1, 100)\n",
    "mountain_test_set = load_images('mountain_test_set', 0, 100)\n",
    "nofire_unprocessed = load_images('wildfire_train_set - Base Forest - Unprocessed',0,100)\n",
    "nofire_processed = load_images('wildfire_train_set - Base Forest - Processed',0,100)\n",
    "smokeTypes = ['Heavy Smoke','Light Smoke']\n",
    "timeOfDay = ['Night','Day','Morning']\n",
    "\n",
    "data = []\n",
    "data.extend(wildfire_test_set)\n",
    "data.extend(mountain_test_set)\n",
    "data.extend(nofire_unprocessed)\n",
    "data.extend(nofire_processed)\n",
    "for smokeType in smokeTypes:\n",
    "    for time in timeOfDay:\n",
    "        wildfire_train_set_Unprocessed = load_images(f'wildfire_train_set - Unprocessed/{smokeType}/{time}', 1, 100)\n",
    "        data.extend(wildfire_train_set_Unprocessed)\n",
    "        wildfire_train_set_Processed = load_images(f'wildfire_train_set - Processed and Pruned/{smokeType}/{time}', 1, 100)\n",
    "        data.extend(wildfire_train_set_Processed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageLabelAssembly(data, augment=False):\n",
    "\n",
    "    images, labels = zip(*data)\n",
    "\n",
    "    length_mean, length_max, width_max, width_mean = get_image_stats(images)\n",
    "\n",
    "    #crop and pad images\n",
    "    images_cropped = pad_images(images, width_max, length_max)\n",
    "    images_final = crop_images(images_cropped, width_mean, length_mean)\n",
    "\n",
    "    #convert all imagees to RGB some are ARGB\n",
    "    images_final = [np.array(Image.fromarray(image).convert('RGB')) for image in images_final]\n",
    "\n",
    "    if augment:\n",
    "        data_augmentation = keras.Sequential(\n",
    "          [\n",
    "            layers.RandomFlip(\"vertical\",\n",
    "                              input_shape=input_shape),\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.1),\n",
    "          ])\n",
    "        \n",
    "#         # plt.figure(figsize=(10, 10))\n",
    "#         augmented_images = []\n",
    "#         augmented_labels = []\n",
    "#         # for images in train_images:\n",
    "#         for i in range(len(train_images[:9])):\n",
    "#             augmented_image = np.array(data_augmentation(tf.convert_to_tensor(images_final[i], dtype=tf.float32)))\n",
    "#             augmented_label = labels[i]\n",
    "#             augmented_images.append(data_augmentation(augmented_image))\n",
    "#             augmented_labels.append(augmented_label)\n",
    "#             ax = plt.subplot(3, 3, i + 1)\n",
    "#             plt.imshow(augmented_image).numpy().astype(\"uint8\")\n",
    "#             plt.axis(\"off\")\n",
    "            \n",
    "#         plt.figure(figsize=(10, 10))\n",
    "#         for i in range(9):\n",
    "#             augmented_image = data_augmentation(tf.convert_to_tensor(images_final, dtype=tf.float32)[i])\n",
    "#             ax = plt.subplot(3, 3, i + 1)\n",
    "#             plt.imshow(augmented_image)\n",
    "#             plt.axis(\"off\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#     augmented = list(zip(augmented_images, augmented_labels))\n",
    "    data = list(zip(images_final, labels))\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = imageLabelAssembly(data, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npess\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "def test_train_split(data):\n",
    "    # randomize the images\n",
    "    import random \n",
    "    random.seed(42)\n",
    "    random.shuffle(data)\n",
    "\n",
    "    #split into train, test, dev\n",
    "    data_len = len(data)\n",
    "    train, dev, test = np.split(data, [int(data_len*.8),int(data_len*.9)])\n",
    "    train_images, train_labels = zip(*train)\n",
    "    dev_images, dev_labels = zip(*dev)\n",
    "    test_images, test_labels = zip(*test)\n",
    "    \n",
    "    return train_images, train_labels, dev_images, dev_labels, test_images, test_labels\n",
    "train_images, train_labels, dev_images, dev_labels, test_images, test_labels = test_train_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the images\n",
    "train_images, dev_images, test_images = np.array(train_images) / 255.0, \\\n",
    "                                        np.array(dev_images) / 255.0, \\\n",
    "                                        np.array(test_images) / 255.0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing label application\n",
    "def plot_images(images, labels):\n",
    "    import math\n",
    "\n",
    "    p_size = math.floor(math.sqrt(len(images)))\n",
    "\n",
    "    class_names = ['no_fire','fire']\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(p_size**2):\n",
    "        plt.subplot(p_size,p_size,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i])\n",
    "        plt.xlabel(class_names[labels[i][0]])\n",
    "    \n",
    "# plot_images(train_images, train_labels)\n",
    "# plot_images(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_images.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_images.shape)\n",
    "# print(np.asarray(train_labels).reshape(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = tf.data.Dataset.from_tensor_slices((train_images, np.asarray(train_labels).reshape(-1)))\n",
    "# test_images = tf.data.Dataset.from_tensor_slices((test_images, np.asarray(test_labels).reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.convert_to_tensor(train_images, dtype=tf.float32)\n",
    "train_labels = tf.convert_to_tensor(train_labels, dtype=tf.float32)\n",
    "test_images = tf.convert_to_tensor(test_images, dtype=tf.float32)\n",
    "test_labels = tf.convert_to_tensor(test_labels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 182, 32)       896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 91, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 89, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 42, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3612736   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 3,669,706\n",
      "Trainable params: 3,669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))#(100, 163, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.summary()\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 32s 380ms/step - loss: 0.5752 - accuracy: 0.7204 - val_loss: 0.3417 - val_accuracy: 0.8537\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 32s 380ms/step - loss: 0.2660 - accuracy: 0.8828 - val_loss: 0.1792 - val_accuracy: 0.9284\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 31s 371ms/step - loss: 0.1461 - accuracy: 0.9436 - val_loss: 0.1237 - val_accuracy: 0.9612\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 31s 370ms/step - loss: 0.0821 - accuracy: 0.9694 - val_loss: 0.0806 - val_accuracy: 0.9642\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 33s 388ms/step - loss: 0.1387 - accuracy: 0.9500 - val_loss: 0.1392 - val_accuracy: 0.9463\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 33s 388ms/step - loss: 0.0394 - accuracy: 0.9869 - val_loss: 0.0420 - val_accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 32s 380ms/step - loss: 0.0419 - accuracy: 0.9851 - val_loss: 0.0579 - val_accuracy: 0.9821\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 32s 376ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.0413 - val_accuracy: 0.9881\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 32s 379ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.0443 - val_accuracy: 0.9881\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 32s 376ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=epochs, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history).reset_index()\n",
    "history_df = history_df.rename(columns={'index':'epoch'})\n",
    "accuracy_df = pd.melt(history_df, id_vars=['epoch'], value_vars=['accuracy', 'val_accuracy'])\n",
    "loss_df = pd.melt(history_df, id_vars=['epoch'], value_vars=['loss', 'val_loss'])\n",
    "history_df = pd.melt(history_df, id_vars=['epoch'], value_vars=['accuracy', 'val_accuracy', 'loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-8bf5fb87b93a4338827dac6f520ac28c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8bf5fb87b93a4338827dac6f520ac28c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8bf5fb87b93a4338827dac6f520ac28c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelColor\": \"#696969\", \"labelFont\": \"Cambria\", \"labelFontSize\": 14, \"titleColor\": \"#696969\", \"titleFont\": \"Cambria\", \"titleFontSize\": 16}, \"title\": {\"anchor\": \"start\", \"color\": \"#232b2b\", \"font\": \"Cambria\", \"fontSize\": 30, \"offset\": 20}}, \"data\": {\"name\": \"data-d5f6ab8e8b5441f1d8e98b97a00983db\"}, \"mark\": {\"type\": \"line\", \"size\": 3}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"variable\", \"legend\": {\"labelColor\": \"#696969\", \"labelFont\": \"Cambria\", \"labelFontSize\": 14, \"title\": null}, \"scale\": {\"range\": [\"#6f0000\", \"#696969\", \"#6f0000\", \"#696969\"]}}, \"x\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"tickCount\": 10, \"title\": \"Epoch\"}, \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"format\": \"%\", \"title\": \"Accuracy/Loss\"}, \"field\": \"value\"}}, \"height\": 300, \"title\": \"Model performance\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-d5f6ab8e8b5441f1d8e98b97a00983db\": [{\"epoch\": 0, \"variable\": \"accuracy\", \"value\": 0.7204180955886841}, {\"epoch\": 1, \"variable\": \"accuracy\", \"value\": 0.8827921152114868}, {\"epoch\": 2, \"variable\": \"accuracy\", \"value\": 0.9436357021331787}, {\"epoch\": 3, \"variable\": \"accuracy\", \"value\": 0.9693915843963623}, {\"epoch\": 4, \"variable\": \"accuracy\", \"value\": 0.9499813318252563}, {\"epoch\": 5, \"variable\": \"accuracy\", \"value\": 0.9869354367256165}, {\"epoch\": 6, \"variable\": \"accuracy\", \"value\": 0.9850690364837646}, {\"epoch\": 7, \"variable\": \"accuracy\", \"value\": 0.9910414218902588}, {\"epoch\": 8, \"variable\": \"accuracy\", \"value\": 0.9966405630111694}, {\"epoch\": 9, \"variable\": \"accuracy\", \"value\": 1.0}, {\"epoch\": 0, \"variable\": \"val_accuracy\", \"value\": 0.8537313342094421}, {\"epoch\": 1, \"variable\": \"val_accuracy\", \"value\": 0.9283581972122192}, {\"epoch\": 2, \"variable\": \"val_accuracy\", \"value\": 0.9611940383911133}, {\"epoch\": 3, \"variable\": \"val_accuracy\", \"value\": 0.9641790986061096}, {\"epoch\": 4, \"variable\": \"val_accuracy\", \"value\": 0.9462686777114868}, {\"epoch\": 5, \"variable\": \"val_accuracy\", \"value\": 0.9850746393203735}, {\"epoch\": 6, \"variable\": \"val_accuracy\", \"value\": 0.9820895791053772}, {\"epoch\": 7, \"variable\": \"val_accuracy\", \"value\": 0.9880596995353699}, {\"epoch\": 8, \"variable\": \"val_accuracy\", \"value\": 0.9880596995353699}, {\"epoch\": 9, \"variable\": \"val_accuracy\", \"value\": 0.9820895791053772}, {\"epoch\": 0, \"variable\": \"loss\", \"value\": 0.5752302408218384}, {\"epoch\": 1, \"variable\": \"loss\", \"value\": 0.2660144865512848}, {\"epoch\": 2, \"variable\": \"loss\", \"value\": 0.14611764252185822}, {\"epoch\": 3, \"variable\": \"loss\", \"value\": 0.08209993690252304}, {\"epoch\": 4, \"variable\": \"loss\", \"value\": 0.138718843460083}, {\"epoch\": 5, \"variable\": \"loss\", \"value\": 0.0394320972263813}, {\"epoch\": 6, \"variable\": \"loss\", \"value\": 0.04194343090057373}, {\"epoch\": 7, \"variable\": \"loss\", \"value\": 0.024448364973068237}, {\"epoch\": 8, \"variable\": \"loss\", \"value\": 0.012844845652580261}, {\"epoch\": 9, \"variable\": \"loss\", \"value\": 0.003384623909369111}, {\"epoch\": 0, \"variable\": \"val_loss\", \"value\": 0.34168097376823425}, {\"epoch\": 1, \"variable\": \"val_loss\", \"value\": 0.17916536331176758}, {\"epoch\": 2, \"variable\": \"val_loss\", \"value\": 0.12368927896022797}, {\"epoch\": 3, \"variable\": \"val_loss\", \"value\": 0.08059248328208923}, {\"epoch\": 4, \"variable\": \"val_loss\", \"value\": 0.13918091356754303}, {\"epoch\": 5, \"variable\": \"val_loss\", \"value\": 0.04200232774019241}, {\"epoch\": 6, \"variable\": \"val_loss\", \"value\": 0.05787916108965874}, {\"epoch\": 7, \"variable\": \"val_loss\", \"value\": 0.04130218178033829}, {\"epoch\": 8, \"variable\": \"val_loss\", \"value\": 0.04431181773543358}, {\"epoch\": 9, \"variable\": \"val_loss\", \"value\": 0.05868510529398918}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceChart = alt.Chart(history_df,title='Model performance').mark_line(size=3).encode(\n",
    "    x=alt.X('epoch',axis=alt.Axis(title='Epoch', grid=False,tickCount=10)),\n",
    "    y=alt.Y('value',axis=alt.Axis(title='Accuracy/Loss',format='%')),\n",
    "    color=alt.Color('variable',scale=alt.Scale(range=['#6f0000','#696969','#6f0000','#696969']),\n",
    "    legend=alt.Legend(title=None,labelFont='Cambria',labelColor='#696969',labelFontSize=14))\n",
    "    ).properties(\n",
    "    width=800,\n",
    "    height=300\n",
    "    ).configure_title(fontSize=30,color='#232b2b',font='Cambria',anchor='start',offset=20\n",
    "    ).configure_axis(labelColor='#696969',labelFont='Cambria',labelFontSize=14,titleFont='Cambria',titleFontSize=16,titleColor='#696969'\n",
    "    )#.configure_legend(labelFontStyle='Cambria',labelFontSize=12)\n",
    "\n",
    "performanceChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = alt.Chart(accuracy_df).mark_line().encode(\n",
    "#     x=alt.X('epoch',axis=alt.Axis(title='Epoch', grid=False)),\n",
    "#     y=alt.Y('value',axis=alt.Axis(title='Accuracy')),\n",
    "#     color=alt.Color('variable'))\n",
    "\n",
    "# loss = alt.Chart(loss_df).mark_line().encode(\n",
    "#     x=alt.X('epoch',axis=alt.Axis(title='Epoch', grid=False)),\n",
    "#     y=alt.Y('value',axis=alt.Axis(title='Loss')),\n",
    "#     color=alt.Color('variable'))\n",
    "\n",
    "# alt.vconcat(accuracy,loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment / uncomment layers orrrr iterate through all combinations?\n",
    "augment_layers =[\n",
    "        layers.RandomFlip(\"vertical\",input_shape=input_shape),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        #other options we can run with.. black and white, saturation, brightness, etc...\n",
    "        layers.RandomContrast(1.0, seed=100),\n",
    "        ]\n",
    "\n",
    "# tf.keras.layers.Resizing, tf.keras.layers.Rescaling, tf.keras.layers.RandomFlip, and tf.keras.layers.RandomRotation,\n",
    "\n",
    "def augment (augment_layers):\n",
    "    return keras.Sequential(augment_layers)\n",
    "\n",
    "data_augmentation = augment(augment_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 100, 184, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 100, 184, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 184, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 92, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 92, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 25, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               2261120   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,285,349\n",
      "Trainable params: 2,285,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 22s 253ms/step - loss: 0.7555 - accuracy: 0.4979 - val_loss: 0.6943 - val_accuracy: 0.4985\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.6972 - accuracy: 0.5073 - val_loss: 0.6792 - val_accuracy: 0.5104\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 22s 256ms/step - loss: 0.6901 - accuracy: 0.5412 - val_loss: 0.6609 - val_accuracy: 0.6328\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 22s 259ms/step - loss: 0.6427 - accuracy: 0.6301 - val_loss: 0.5932 - val_accuracy: 0.7224\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.6373 - accuracy: 0.6181 - val_loss: 0.5599 - val_accuracy: 0.7463\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.5982 - accuracy: 0.6614 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.5895 - accuracy: 0.6771 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.6052 - accuracy: 0.6581 - val_loss: 0.5731 - val_accuracy: 0.7313\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.5787 - accuracy: 0.6939 - val_loss: 0.6492 - val_accuracy: 0.6209\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.6042 - accuracy: 0.6652 - val_loss: 0.5166 - val_accuracy: 0.7463\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "  train_images,train_labels,\n",
    "  validation_data=(test_images, test_labels),\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-6e7326cbc6d547e6ab43b9a5b0062e8d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6e7326cbc6d547e6ab43b9a5b0062e8d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6e7326cbc6d547e6ab43b9a5b0062e8d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelColor\": \"#696969\", \"labelFont\": \"Cambria\", \"labelFontSize\": 14, \"titleColor\": \"#696969\", \"titleFont\": \"Cambria\", \"titleFontSize\": 16}, \"title\": {\"anchor\": \"start\", \"color\": \"#232b2b\", \"font\": \"Cambria\", \"fontSize\": 30, \"offset\": 20}}, \"data\": {\"name\": \"data-c00601e8ba2c81359edeb08e16483fcf\"}, \"mark\": {\"type\": \"line\", \"size\": 3}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"variable\", \"legend\": {\"labelColor\": \"#696969\", \"labelFont\": \"Cambria\", \"labelFontSize\": 14, \"title\": null}, \"scale\": {\"range\": [\"#6f0000\", \"#696969\", \"#ff7b7b\", \"#999999\"]}}, \"x\": {\"type\": \"quantitative\", \"axis\": {\"grid\": false, \"tickCount\": 10, \"title\": \"Epoch\"}, \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"format\": \"%\", \"title\": \"Accuracy/Loss\"}, \"field\": \"value\"}}, \"height\": 300, \"title\": \"Model performance\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-c00601e8ba2c81359edeb08e16483fcf\": [{\"epoch\": 0, \"variable\": \"accuracy\", \"value\": 0.49794700741767883}, {\"epoch\": 1, \"variable\": \"accuracy\", \"value\": 0.5072788596153259}, {\"epoch\": 2, \"variable\": \"accuracy\", \"value\": 0.5412467122077942}, {\"epoch\": 3, \"variable\": \"accuracy\", \"value\": 0.630085825920105}, {\"epoch\": 4, \"variable\": \"accuracy\", \"value\": 0.6181411147117615}, {\"epoch\": 5, \"variable\": \"accuracy\", \"value\": 0.6614408493041992}, {\"epoch\": 6, \"variable\": \"accuracy\", \"value\": 0.6771183013916016}, {\"epoch\": 7, \"variable\": \"accuracy\", \"value\": 0.6580813527107239}, {\"epoch\": 8, \"variable\": \"accuracy\", \"value\": 0.6939156651496887}, {\"epoch\": 9, \"variable\": \"accuracy\", \"value\": 0.6651735901832581}, {\"epoch\": 0, \"variable\": \"val_accuracy\", \"value\": 0.49850746989250183}, {\"epoch\": 1, \"variable\": \"val_accuracy\", \"value\": 0.5104477405548096}, {\"epoch\": 2, \"variable\": \"val_accuracy\", \"value\": 0.6328358054161072}, {\"epoch\": 3, \"variable\": \"val_accuracy\", \"value\": 0.7223880887031555}, {\"epoch\": 4, \"variable\": \"val_accuracy\", \"value\": 0.746268630027771}, {\"epoch\": 5, \"variable\": \"val_accuracy\", \"value\": 0.7552238702774048}, {\"epoch\": 6, \"variable\": \"val_accuracy\", \"value\": 0.7552238702774048}, {\"epoch\": 7, \"variable\": \"val_accuracy\", \"value\": 0.7313432693481445}, {\"epoch\": 8, \"variable\": \"val_accuracy\", \"value\": 0.620895504951477}, {\"epoch\": 9, \"variable\": \"val_accuracy\", \"value\": 0.746268630027771}, {\"epoch\": 0, \"variable\": \"loss\", \"value\": 0.7554534077644348}, {\"epoch\": 1, \"variable\": \"loss\", \"value\": 0.6972190737724304}, {\"epoch\": 2, \"variable\": \"loss\", \"value\": 0.6900633573532104}, {\"epoch\": 3, \"variable\": \"loss\", \"value\": 0.642693281173706}, {\"epoch\": 4, \"variable\": \"loss\", \"value\": 0.6373314261436462}, {\"epoch\": 5, \"variable\": \"loss\", \"value\": 0.5982140302658081}, {\"epoch\": 6, \"variable\": \"loss\", \"value\": 0.5894834399223328}, {\"epoch\": 7, \"variable\": \"loss\", \"value\": 0.6051817536354065}, {\"epoch\": 8, \"variable\": \"loss\", \"value\": 0.5786868929862976}, {\"epoch\": 9, \"variable\": \"loss\", \"value\": 0.604245126247406}, {\"epoch\": 0, \"variable\": \"val_loss\", \"value\": 0.6942760348320007}, {\"epoch\": 1, \"variable\": \"val_loss\", \"value\": 0.6791697144508362}, {\"epoch\": 2, \"variable\": \"val_loss\", \"value\": 0.6609213352203369}, {\"epoch\": 3, \"variable\": \"val_loss\", \"value\": 0.593248724937439}, {\"epoch\": 4, \"variable\": \"val_loss\", \"value\": 0.5598862171173096}, {\"epoch\": 5, \"variable\": \"val_loss\", \"value\": 0.5434542298316956}, {\"epoch\": 6, \"variable\": \"val_loss\", \"value\": 0.5411758422851562}, {\"epoch\": 7, \"variable\": \"val_loss\", \"value\": 0.573074221611023}, {\"epoch\": 8, \"variable\": \"val_loss\", \"value\": 0.6491750478744507}, {\"epoch\": 9, \"variable\": \"val_loss\", \"value\": 0.5166016221046448}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history).reset_index()\n",
    "history_df = history_df.rename(columns={'index':'epoch'})\n",
    "accuracy_df = pd.melt(history_df, id_vars=['epoch'], value_vars=['accuracy', 'val_accuracy'])\n",
    "loss_df = pd.melt(history_df, id_vars=['epoch'], value_vars=['loss', 'val_loss'])\n",
    "history_df = pd.melt(history_df, id_vars=['epoch'], value_vars=['accuracy', 'val_accuracy', 'loss', 'val_loss'])\n",
    "\n",
    "performanceChart = alt.Chart(history_df,title='Model performance').mark_line(size=3).encode(\n",
    "    x=alt.X('epoch',axis=alt.Axis(title='Epoch', grid=False,tickCount=10)),\n",
    "    y=alt.Y('value',axis=alt.Axis(title='Accuracy/Loss',format='%')),\n",
    "    color=alt.Color('variable',scale=alt.Scale(range=['#6f0000','#696969','#ff7b7b','#999999']),\n",
    "    legend=alt.Legend(title=None,labelFont='Cambria',labelColor='#696969',labelFontSize=14))\n",
    "    ).properties(\n",
    "    width=800,\n",
    "    height=300\n",
    "    ).configure_title(fontSize=30,color='#232b2b',font='Cambria',anchor='start',offset=20\n",
    "    ).configure_axis(labelColor='#696969',labelFont='Cambria',labelFontSize=14,titleFont='Cambria',titleFontSize=16,titleColor='#696969'\n",
    "    )#.configure_legend(labelFontStyle='Cambria',labelFontSize=12)\n",
    "\n",
    "performanceChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_images, steps=len(test_images), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_labels, y_pred=np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment='top',\n",
    "            color=\"black\" if cm[i, j] > thresh else \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[139  29]\n",
      " [ 56 111]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_fire','fire']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.82738095 0.17261905]\n",
      " [0.33532934 0.66467066]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, normalize=True, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No fire</td>\n",
       "      <td>No fire</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fire</td>\n",
       "      <td>No fire</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No fire</td>\n",
       "      <td>Fire</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Fire</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Labels variable  value\n",
       "0  No fire  No fire    139\n",
       "1     Fire  No fire     56\n",
       "2  No fire     Fire     29\n",
       "3     Fire     Fire    111"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmDf = pd.DataFrame(cm)\n",
    "cmDf.columns = ['No fire','Fire']\n",
    "cmDf.index = ['No fire','Fire']\n",
    "cmDf.reset_index(inplace=True)\n",
    "cmDf = cmDf.rename(columns={'index':'Labels'})\n",
    "cmDf = pd.melt(cmDf, id_vars=['Labels'], value_vars=['No fire','Fire'])\n",
    "cmDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-8f6478d0c2724bab8cc4d5adc593946f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8f6478d0c2724bab8cc4d5adc593946f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8f6478d0c2724bab8cc4d5adc593946f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-59f56fe009ea893c61973bceb404d70f\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"value\"}, \"x\": {\"type\": \"nominal\", \"field\": \"Labels\"}, \"y\": {\"type\": \"nominal\", \"field\": \"variable\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-59f56fe009ea893c61973bceb404d70f\": [{\"Labels\": \"No fire\", \"variable\": \"No fire\", \"value\": 139}, {\"Labels\": \"Fire\", \"variable\": \"No fire\", \"value\": 56}, {\"Labels\": \"No fire\", \"variable\": \"Fire\", \"value\": 29}, {\"Labels\": \"Fire\", \"variable\": \"Fire\", \"value\": 111}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(cmDf).mark_rect().encode(\n",
    "    x='Labels',\n",
    "    y='variable',\n",
    "    color='value'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 16, 32, 64]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd','Nadam','RMSprop','Adagrad']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "METRICS = [\n",
    "    hp.Metric(\n",
    "        \"epoch_accuracy\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"accuracy (val.)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"epoch_loss\",\n",
    "        group=\"validation\",\n",
    "        display_name=\"loss (val.)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_accuracy\",\n",
    "        group=\"train\",\n",
    "        display_name=\"accuracy (train)\",\n",
    "    ),\n",
    "    hp.Metric(\n",
    "        \"batch_loss\",\n",
    "        group=\"train\",\n",
    "        display_name=\"loss (train)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    metrics=METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment / uncomment layers orrrr iterate through all combinations?\n",
    "augment_layers =[\n",
    "        layers.RandomFlip(\"vertical\",input_shape=input_shape),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        #other options we can run with.. black and white, saturation, brightness, etc...\n",
    "#         layers.RandomContrast(1.0, seed=100),\n",
    "        ]\n",
    "\n",
    "# tf.keras.layers.Resizing, tf.keras.layers.Rescaling, tf.keras.layers.RandomFlip, and tf.keras.layers.RandomRotation,\n",
    "\n",
    "def augment (augment_layers):\n",
    "    return keras.Sequential(augment_layers)\n",
    "\n",
    "data_augmentation = augment(augment_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/hparams/hparams_demo.py#L88\n",
    "\n",
    "def train_test_model(hparams,epochs,augmentModel=False):\n",
    "    \n",
    "    if augmentModel:\n",
    "        data_augmentation = augment(augment_layers)\n",
    "    else:\n",
    "        data_augmentation = ''\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "#       metrics=['accuracy'],\n",
    "      metrics=['accuracy',f1_m,precision_m, recall_m]\n",
    "    )\n",
    "    #############################\n",
    "    #trying to drill into recall#\n",
    "    #############################\n",
    "    \n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=epochs) # Run with 1 epoch to speed things up for demo purposes\n",
    "#     _, accuracy = model.evaluate(test_images, test_labels)\n",
    "    loss, accuracy, f1_score, precision, recall = model.evaluate(test_images, test_labels)\n",
    "\n",
    "#     tf.print(\"recall:\", type(recall), output_stream=sys.stdout)\n",
    "    return loss, accuracy, f1_score, precision, recall\n",
    "\n",
    "def run(run_dir, hparams, epochs, augmentModel=False):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "#         accuracy = train_test_model(hparams,epochs,augmentModel)\n",
    "#         print(tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1))\n",
    "#         print(list(tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)))\n",
    "\n",
    "        model = train_test_model(hparams,epochs,augmentModel=True)\n",
    "        \n",
    "        \n",
    "#         print(tf.summary.scalar(METRIC, accuracy, step=1))\n",
    "#         print(list(tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)))\n",
    "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "#     metrics=METRICS\n",
    "        \n",
    "    \n",
    "    \n",
    "# def run(run_dir, hparams):\n",
    "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
    "#     hp.hparams(hparams)  # record the values used in this trial\n",
    "#     accuracy = create_model(hparams)\n",
    "#     #converting to tf scalar\n",
    "#     accuracy= tf.reshape(tf.convert_to_tensor(accuracy), []).numpy()\n",
    "#     tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "\n",
    "# def run(data, base_logdir, session_id, hparams):\n",
    "#     \"\"\"Run a training/validation session.\n",
    "#     Flags must have been parsed for this function to behave.\n",
    "#     Args:\n",
    "#       data: The data as loaded by `prepare_data()`.\n",
    "#       base_logdir: The top-level logdir to which to write summary data.\n",
    "#       session_id: A unique string ID for this session.\n",
    "#       hparams: A dict mapping hyperparameters in `HPARAMS` to values.\n",
    "#     \"\"\"\n",
    "#     model = model_fn(hparams=hparams, seed=session_id)\n",
    "#     logdir = os.path.join(base_logdir, session_id)\n",
    "\n",
    "#     callback = tf.keras.callbacks.TensorBoard(\n",
    "#         logdir,\n",
    "#         update_freq=flags.FLAGS.summary_freq,\n",
    "#         profile_batch=0,  # workaround for issue #2084\n",
    "#     )\n",
    "#     hparams_callback = hp.KerasCallback(logdir, hparams)\n",
    "#     ((x_train, y_train), (x_test, y_test)) = data\n",
    "#     result = model.fit(\n",
    "#         x=x_train,\n",
    "#         y=y_train,\n",
    "#         epochs=flags.FLAGS.num_epochs,\n",
    "#         shuffle=False,\n",
    "#         validation_data=(x_test, y_test),\n",
    "#         callbacks=[callback, hparams_callback],\n",
    "#     )\n",
    "\n",
    "# def run_all(logdir, verbose=False):\n",
    "def run_all(run_dir, verbose=False):\n",
    "    \"\"\"Perform random search over the hyperparameter space.\n",
    "    Arguments:\n",
    "      logdir: The top-level directory into which to write data. This\n",
    "        directory should be empty or nonexistent.\n",
    "      verbose: If true, print out each run's name as it begins.\n",
    "    \"\"\"\n",
    "#     data = prepare_data()\n",
    "    rng = random.Random(0)\n",
    "\n",
    "    with tf.summary.create_file_writer(logdir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=METRICS)\n",
    "\n",
    "    sessions_per_group = 2\n",
    "    num_sessions = flags.FLAGS.num_session_groups * sessions_per_group\n",
    "    session_index = 0  # across all session groups\n",
    "    for group_index in range(flags.FLAGS.num_session_groups):\n",
    "#     for num_units in HP_NUM_UNITS.domain.values:\n",
    "        hparams = {h: h.domain.sample_uniform(rng) for h in HPARAMS}\n",
    "        hparams_string = str(hparams)\n",
    "        for repeat_index in range(sessions_per_group):\n",
    "            session_id = str(session_index)\n",
    "            session_index += 1\n",
    "            if verbose:\n",
    "                print(\n",
    "                    \"--- Running training session %d/%d\"\n",
    "                    % (session_index, num_sessions)\n",
    "                )\n",
    "                print(hparams_string)\n",
    "                print(\"--- repeat #: %d\" % (repeat_index + 1))\n",
    "#             run(\n",
    "#                 data=data,\n",
    "#                 base_logdir=logdir,\n",
    "#                 session_id=session_id,\n",
    "#                 hparams=hparams,\n",
    "#             )\n",
    "            run(\n",
    "                run_dir=run_dir,\n",
    "                hparams=hparams,\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 25s 288ms/step - loss: 2.2858 - accuracy: 0.5017 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 25s 292ms/step - loss: 2.2641 - accuracy: 0.5069 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 2.2412 - accuracy: 0.5080 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 2.2048 - accuracy: 0.5084 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 2.1574 - accuracy: 0.4670 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 2.1117 - accuracy: 0.4640 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 2.0765 - accuracy: 0.4651 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 2.0442 - accuracy: 0.5047 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 2.0130 - accuracy: 0.5099 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 1.9861 - accuracy: 0.5065 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 1.9559 - accuracy: 0.5084 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 1.9351 - accuracy: 0.5073 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 1.9098 - accuracy: 0.5062 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 1.8951 - accuracy: 0.5080 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 1.8715 - accuracy: 0.5069 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 1.8528 - accuracy: 0.5080 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 1.8282 - accuracy: 0.5080 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 1.8103 - accuracy: 0.5077 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.7930 - accuracy: 0.5073 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.7668 - accuracy: 0.5077 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 1.7500 - accuracy: 0.5080 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.7398 - accuracy: 0.5039 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 1.7186 - accuracy: 0.5047 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 1.7054 - accuracy: 0.5103 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 1.6643 - accuracy: 0.5133 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 1.6571 - accuracy: 0.5118 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 1.6384 - accuracy: 0.5103 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 1.6254 - accuracy: 0.5054 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 1.6156 - accuracy: 0.5009 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 1.5960 - accuracy: 0.5084 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 1.5406 - accuracy: 0.4985 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 238ms/step - loss: 1.2949 - accuracy: 0.4449 - f1_m: 0.4662 - precision_m: 0.4858 - recall_m: 0.5762\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.9253 - accuracy: 0.4841 - f1_m: 0.5536 - precision_m: 0.4957 - recall_m: 0.7434\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.8265 - accuracy: 0.5125 - f1_m: 0.6376 - precision_m: 0.5100 - recall_m: 0.9065\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7925 - accuracy: 0.4994 - f1_m: 0.6542 - precision_m: 0.5147 - recall_m: 0.9237\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7645 - accuracy: 0.5345 - f1_m: 0.6595 - precision_m: 0.5143 - recall_m: 0.9385\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.7042 - accuracy: 0.6032 - f1_m: 0.6629 - precision_m: 0.5148 - recall_m: 0.9494\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6710 - accuracy: 0.6185 - f1_m: 0.6670 - precision_m: 0.5136 - recall_m: 0.9681\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.6613 - accuracy: 0.6338 - f1_m: 0.6644 - precision_m: 0.5117 - recall_m: 0.9714\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6484 - accuracy: 0.6334 - f1_m: 0.6597 - precision_m: 0.5074 - recall_m: 0.9670\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6392 - accuracy: 0.6439 - f1_m: 0.6672 - precision_m: 0.5097 - recall_m: 0.9824\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6307 - accuracy: 0.6458 - f1_m: 0.6679 - precision_m: 0.5098 - recall_m: 0.9847\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6217 - accuracy: 0.6543 - f1_m: 0.6659 - precision_m: 0.5079 - recall_m: 0.9822\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6192 - accuracy: 0.6562 - f1_m: 0.6664 - precision_m: 0.5089 - recall_m: 0.9842\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6076 - accuracy: 0.6614 - f1_m: 0.6658 - precision_m: 0.5075 - recall_m: 0.9868\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5980 - accuracy: 0.6846 - f1_m: 0.6643 - precision_m: 0.5067 - recall_m: 0.9880\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5946 - accuracy: 0.6614 - f1_m: 0.6659 - precision_m: 0.5073 - recall_m: 0.9851\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5758 - accuracy: 0.6812 - f1_m: 0.6682 - precision_m: 0.5087 - recall_m: 0.9932\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5753 - accuracy: 0.6820 - f1_m: 0.6649 - precision_m: 0.5083 - recall_m: 0.9827\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.6083 - accuracy: 0.6726 - f1_m: 0.6623 - precision_m: 0.5059 - recall_m: 0.9841\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5498 - accuracy: 0.7159 - f1_m: 0.6682 - precision_m: 0.5090 - recall_m: 0.9891\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5449 - accuracy: 0.7171 - f1_m: 0.6656 - precision_m: 0.5087 - recall_m: 0.9884\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5451 - accuracy: 0.7122 - f1_m: 0.6664 - precision_m: 0.5083 - recall_m: 0.9874\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5367 - accuracy: 0.7074 - f1_m: 0.6653 - precision_m: 0.5064 - recall_m: 0.9886\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5382 - accuracy: 0.7200 - f1_m: 0.6646 - precision_m: 0.5063 - recall_m: 0.9831\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5108 - accuracy: 0.7465 - f1_m: 0.6693 - precision_m: 0.5092 - recall_m: 0.9934\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5248 - accuracy: 0.7264 - f1_m: 0.6663 - precision_m: 0.5073 - recall_m: 0.9866\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.4919 - accuracy: 0.7521 - f1_m: 0.6673 - precision_m: 0.5083 - recall_m: 0.9900\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5084 - accuracy: 0.7503 - f1_m: 0.6646 - precision_m: 0.5065 - recall_m: 0.9870\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4866 - accuracy: 0.7570 - f1_m: 0.6682 - precision_m: 0.5085 - recall_m: 0.9899\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4931 - accuracy: 0.7536 - f1_m: 0.6668 - precision_m: 0.5089 - recall_m: 0.9903\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.3984 - accuracy: 0.8328 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 243ms/step - loss: 1.8489 - accuracy: 0.0153 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.2910 - accuracy: 0.4453 - f1_m: 0.1161 - precision_m: 0.1106 - recall_m: 0.1479\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8820 - accuracy: 0.5259 - f1_m: 0.5278 - precision_m: 0.4720 - recall_m: 0.7436\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7852 - accuracy: 0.5144 - f1_m: 0.6271 - precision_m: 0.5192 - recall_m: 0.8887\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7421 - accuracy: 0.5226 - f1_m: 0.6578 - precision_m: 0.5055 - recall_m: 0.9646\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7177 - accuracy: 0.5498 - f1_m: 0.6574 - precision_m: 0.5032 - recall_m: 0.9686\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.6883 - accuracy: 0.6032 - f1_m: 0.6600 - precision_m: 0.5033 - recall_m: 0.9720\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6597 - accuracy: 0.6297 - f1_m: 0.6596 - precision_m: 0.5035 - recall_m: 0.9749\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6468 - accuracy: 0.6237 - f1_m: 0.6650 - precision_m: 0.5076 - recall_m: 0.9866\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6525 - accuracy: 0.6376 - f1_m: 0.6591 - precision_m: 0.5044 - recall_m: 0.9702\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6467 - accuracy: 0.6275 - f1_m: 0.6616 - precision_m: 0.5068 - recall_m: 0.9770\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6391 - accuracy: 0.6346 - f1_m: 0.6621 - precision_m: 0.5050 - recall_m: 0.9768\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6352 - accuracy: 0.6387 - f1_m: 0.6626 - precision_m: 0.5070 - recall_m: 0.9769\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6356 - accuracy: 0.6461 - f1_m: 0.6572 - precision_m: 0.5027 - recall_m: 0.9663\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6234 - accuracy: 0.6487 - f1_m: 0.6624 - precision_m: 0.5061 - recall_m: 0.9777\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6205 - accuracy: 0.6473 - f1_m: 0.6607 - precision_m: 0.5058 - recall_m: 0.9689\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6221 - accuracy: 0.6514 - f1_m: 0.6620 - precision_m: 0.5082 - recall_m: 0.9730\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6147 - accuracy: 0.6573 - f1_m: 0.6616 - precision_m: 0.5062 - recall_m: 0.9726\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6102 - accuracy: 0.6525 - f1_m: 0.6641 - precision_m: 0.5072 - recall_m: 0.9750\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6003 - accuracy: 0.6708 - f1_m: 0.6612 - precision_m: 0.5064 - recall_m: 0.9729\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5731 - accuracy: 0.6823 - f1_m: 0.6634 - precision_m: 0.5072 - recall_m: 0.9770\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5754 - accuracy: 0.6827 - f1_m: 0.6635 - precision_m: 0.5083 - recall_m: 0.9748\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5606 - accuracy: 0.7014 - f1_m: 0.6665 - precision_m: 0.5095 - recall_m: 0.9795\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5562 - accuracy: 0.7137 - f1_m: 0.6623 - precision_m: 0.5080 - recall_m: 0.9732\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5489 - accuracy: 0.6988 - f1_m: 0.6610 - precision_m: 0.5067 - recall_m: 0.9715\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5432 - accuracy: 0.7081 - f1_m: 0.6608 - precision_m: 0.5071 - recall_m: 0.9675\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5350 - accuracy: 0.7062 - f1_m: 0.6633 - precision_m: 0.5075 - recall_m: 0.9784\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5420 - accuracy: 0.7227 - f1_m: 0.6661 - precision_m: 0.5094 - recall_m: 0.9764\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5364 - accuracy: 0.7148 - f1_m: 0.6672 - precision_m: 0.5101 - recall_m: 0.9804\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5274 - accuracy: 0.7253 - f1_m: 0.6655 - precision_m: 0.5089 - recall_m: 0.9810\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 0.4275 - accuracy: 0.8179 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 242ms/step - loss: 2.0412 - accuracy: 0.2826 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 1.3117 - accuracy: 0.4979 - f1_m: 0.4719 - precision_m: 0.3747 - recall_m: 0.6507\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8373 - accuracy: 0.4961 - f1_m: 0.6202 - precision_m: 0.5036 - recall_m: 0.8656\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.8334 - accuracy: 0.4935 - f1_m: 0.6489 - precision_m: 0.5151 - recall_m: 0.9030\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8375 - accuracy: 0.5043 - f1_m: 0.6377 - precision_m: 0.5054 - recall_m: 0.8831\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.8224 - accuracy: 0.4972 - f1_m: 0.6368 - precision_m: 0.5084 - recall_m: 0.8838\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 21s 244ms/step - loss: 0.8189 - accuracy: 0.4965 - f1_m: 0.6473 - precision_m: 0.5089 - recall_m: 0.9074\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8245 - accuracy: 0.4968 - f1_m: 0.6297 - precision_m: 0.5025 - recall_m: 0.8815\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8215 - accuracy: 0.4901 - f1_m: 0.6364 - precision_m: 0.5057 - recall_m: 0.8871\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8224 - accuracy: 0.5151 - f1_m: 0.6391 - precision_m: 0.5062 - recall_m: 0.8878\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.8073 - accuracy: 0.4879 - f1_m: 0.6427 - precision_m: 0.5053 - recall_m: 0.9023\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7955 - accuracy: 0.5189 - f1_m: 0.6491 - precision_m: 0.5099 - recall_m: 0.9165\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7988 - accuracy: 0.5144 - f1_m: 0.6409 - precision_m: 0.5046 - recall_m: 0.8991\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7948 - accuracy: 0.5017 - f1_m: 0.6448 - precision_m: 0.5084 - recall_m: 0.8994\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7932 - accuracy: 0.5073 - f1_m: 0.6420 - precision_m: 0.5057 - recall_m: 0.8949\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7956 - accuracy: 0.4916 - f1_m: 0.6466 - precision_m: 0.5117 - recall_m: 0.8991\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7958 - accuracy: 0.5125 - f1_m: 0.6367 - precision_m: 0.5034 - recall_m: 0.8901\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7818 - accuracy: 0.4838 - f1_m: 0.6497 - precision_m: 0.5123 - recall_m: 0.9088\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7794 - accuracy: 0.5174 - f1_m: 0.6465 - precision_m: 0.5086 - recall_m: 0.9047\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7831 - accuracy: 0.4979 - f1_m: 0.6507 - precision_m: 0.5142 - recall_m: 0.9097\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7747 - accuracy: 0.5050 - f1_m: 0.6475 - precision_m: 0.5093 - recall_m: 0.9072\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7800 - accuracy: 0.4987 - f1_m: 0.6397 - precision_m: 0.5056 - recall_m: 0.8852\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7680 - accuracy: 0.5121 - f1_m: 0.6367 - precision_m: 0.5038 - recall_m: 0.8893\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7661 - accuracy: 0.4931 - f1_m: 0.6444 - precision_m: 0.5074 - recall_m: 0.8971\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7657 - accuracy: 0.5065 - f1_m: 0.6401 - precision_m: 0.5050 - recall_m: 0.8931\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7642 - accuracy: 0.5028 - f1_m: 0.6309 - precision_m: 0.5025 - recall_m: 0.8673\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7590 - accuracy: 0.5159 - f1_m: 0.6239 - precision_m: 0.5074 - recall_m: 0.8543\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7541 - accuracy: 0.5017 - f1_m: 0.6386 - precision_m: 0.5056 - recall_m: 0.8904\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7557 - accuracy: 0.5185 - f1_m: 0.6433 - precision_m: 0.5076 - recall_m: 0.8992\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7437 - accuracy: 0.5162 - f1_m: 0.6403 - precision_m: 0.5036 - recall_m: 0.9001\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.6913 - accuracy: 0.6299 - f1_m: 0.6300 - precision_m: 0.4839 - recall_m: 0.9170\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 8, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 243ms/step - loss: 1.3598 - accuracy: 0.4685 - f1_m: 0.2872 - precision_m: 0.2767 - recall_m: 0.3885\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.8574 - accuracy: 0.4894 - f1_m: 0.6362 - precision_m: 0.5027 - recall_m: 0.8862\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.8335 - accuracy: 0.5069 - f1_m: 0.6360 - precision_m: 0.5007 - recall_m: 0.8913\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8396 - accuracy: 0.5002 - f1_m: 0.6423 - precision_m: 0.5060 - recall_m: 0.8952\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8454 - accuracy: 0.5054 - f1_m: 0.6220 - precision_m: 0.4916 - recall_m: 0.8689\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.8368 - accuracy: 0.4905 - f1_m: 0.6274 - precision_m: 0.4957 - recall_m: 0.8744\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.8289 - accuracy: 0.5062 - f1_m: 0.6452 - precision_m: 0.5095 - recall_m: 0.9052\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.8295 - accuracy: 0.5174 - f1_m: 0.6307 - precision_m: 0.4984 - recall_m: 0.8794\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8247 - accuracy: 0.5252 - f1_m: 0.6387 - precision_m: 0.5048 - recall_m: 0.8912\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8148 - accuracy: 0.4860 - f1_m: 0.6226 - precision_m: 0.4912 - recall_m: 0.8738\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.8119 - accuracy: 0.4909 - f1_m: 0.6180 - precision_m: 0.4872 - recall_m: 0.8645\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8238 - accuracy: 0.4860 - f1_m: 0.6329 - precision_m: 0.4996 - recall_m: 0.8786\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8206 - accuracy: 0.5006 - f1_m: 0.6262 - precision_m: 0.4961 - recall_m: 0.8717\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.8024 - accuracy: 0.5133 - f1_m: 0.6483 - precision_m: 0.5102 - recall_m: 0.9107\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8069 - accuracy: 0.4882 - f1_m: 0.6486 - precision_m: 0.5110 - recall_m: 0.9084\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.8029 - accuracy: 0.5013 - f1_m: 0.6344 - precision_m: 0.5015 - recall_m: 0.8875\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7959 - accuracy: 0.4856 - f1_m: 0.6396 - precision_m: 0.5029 - recall_m: 0.8989\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7909 - accuracy: 0.4968 - f1_m: 0.6296 - precision_m: 0.4929 - recall_m: 0.8851\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7961 - accuracy: 0.5039 - f1_m: 0.6463 - precision_m: 0.5093 - recall_m: 0.9045\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7954 - accuracy: 0.4991 - f1_m: 0.6388 - precision_m: 0.5033 - recall_m: 0.8923\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7898 - accuracy: 0.4950 - f1_m: 0.6423 - precision_m: 0.5050 - recall_m: 0.8978\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7902 - accuracy: 0.5088 - f1_m: 0.6392 - precision_m: 0.5047 - recall_m: 0.8945\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7950 - accuracy: 0.4931 - f1_m: 0.6422 - precision_m: 0.5085 - recall_m: 0.8991\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7865 - accuracy: 0.5006 - f1_m: 0.6130 - precision_m: 0.4836 - recall_m: 0.8557\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7837 - accuracy: 0.4916 - f1_m: 0.6481 - precision_m: 0.5104 - recall_m: 0.9085\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7820 - accuracy: 0.5118 - f1_m: 0.6247 - precision_m: 0.4917 - recall_m: 0.8761\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7857 - accuracy: 0.5054 - f1_m: 0.6376 - precision_m: 0.5041 - recall_m: 0.8882\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7881 - accuracy: 0.4897 - f1_m: 0.6361 - precision_m: 0.5034 - recall_m: 0.8836\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7807 - accuracy: 0.5181 - f1_m: 0.6302 - precision_m: 0.4993 - recall_m: 0.8786\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7813 - accuracy: 0.5006 - f1_m: 0.6496 - precision_m: 0.5127 - recall_m: 0.9015\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.7012 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 238ms/step - loss: 2.2799 - accuracy: 0.5009 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 2.2360 - accuracy: 0.4987 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 2.1455 - accuracy: 0.4192 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 2.0020 - accuracy: 0.3707 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 1.8758 - accuracy: 0.3789 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.7813 - accuracy: 0.4274 - f1_m: 0.1257 - precision_m: 0.3929 - recall_m: 0.0790\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 1.7190 - accuracy: 0.4487 - f1_m: 0.1693 - precision_m: 0.4889 - recall_m: 0.1078\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 1.6568 - accuracy: 0.4573 - f1_m: 0.2137 - precision_m: 0.4991 - recall_m: 0.1418\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 22s 257ms/step - loss: 1.6144 - accuracy: 0.4584 - f1_m: 0.2552 - precision_m: 0.5667 - recall_m: 0.1702\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 25s 301ms/step - loss: 1.6065 - accuracy: 0.4632 - f1_m: 0.2143 - precision_m: 0.4838 - recall_m: 0.1443\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 31s 374ms/step - loss: 1.5808 - accuracy: 0.4946 - f1_m: 0.2270 - precision_m: 0.5080 - recall_m: 0.1519\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 31s 368ms/step - loss: 1.5681 - accuracy: 0.5058 - f1_m: 0.2389 - precision_m: 0.5241 - recall_m: 0.1683\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 25s 292ms/step - loss: 1.5415 - accuracy: 0.4901 - f1_m: 0.2287 - precision_m: 0.5090 - recall_m: 0.1574\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 25s 295ms/step - loss: 1.4948 - accuracy: 0.4897 - f1_m: 0.2282 - precision_m: 0.5062 - recall_m: 0.1657\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 25s 298ms/step - loss: 1.5000 - accuracy: 0.5021 - f1_m: 0.2248 - precision_m: 0.4834 - recall_m: 0.1519\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 1.4529 - accuracy: 0.5155 - f1_m: 0.2567 - precision_m: 0.5548 - recall_m: 0.1822\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.4640 - accuracy: 0.5043 - f1_m: 0.3263 - precision_m: 0.5487 - recall_m: 0.2638\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 1.4314 - accuracy: 0.5062 - f1_m: 0.2942 - precision_m: 0.5030 - recall_m: 0.2428\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 1.3918 - accuracy: 0.5207 - f1_m: 0.3676 - precision_m: 0.5375 - recall_m: 0.3317\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 1.4239 - accuracy: 0.4819 - f1_m: 0.3117 - precision_m: 0.5074 - recall_m: 0.2595\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 1.3804 - accuracy: 0.5069 - f1_m: 0.3215 - precision_m: 0.5201 - recall_m: 0.2707\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 1.4018 - accuracy: 0.4894 - f1_m: 0.3379 - precision_m: 0.4989 - recall_m: 0.2961\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 1.3736 - accuracy: 0.5002 - f1_m: 0.4300 - precision_m: 0.5413 - recall_m: 0.4215\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.3742 - accuracy: 0.5032 - f1_m: 0.4197 - precision_m: 0.4981 - recall_m: 0.4110\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 1.3688 - accuracy: 0.4860 - f1_m: 0.4140 - precision_m: 0.5088 - recall_m: 0.4113\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 1.3477 - accuracy: 0.5062 - f1_m: 0.4412 - precision_m: 0.5034 - recall_m: 0.4384\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 1.3488 - accuracy: 0.4946 - f1_m: 0.4493 - precision_m: 0.5204 - recall_m: 0.4306\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 1.3222 - accuracy: 0.5006 - f1_m: 0.4700 - precision_m: 0.5052 - recall_m: 0.4868\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 1.3361 - accuracy: 0.5106 - f1_m: 0.5580 - precision_m: 0.5188 - recall_m: 0.6372\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.2741 - accuracy: 0.5166 - f1_m: 0.5400 - precision_m: 0.5352 - recall_m: 0.6043\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 1.0152 - accuracy: 0.4985 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 241ms/step - loss: 1.7268 - accuracy: 0.3792 - f1_m: 0.1749 - precision_m: 0.3024 - recall_m: 0.1590\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 1.2306 - accuracy: 0.4961 - f1_m: 0.3815 - precision_m: 0.4989 - recall_m: 0.4006\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 1.0912 - accuracy: 0.4767 - f1_m: 0.4466 - precision_m: 0.5130 - recall_m: 0.4581\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 1.0098 - accuracy: 0.4942 - f1_m: 0.5438 - precision_m: 0.5198 - recall_m: 0.6713\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.9234 - accuracy: 0.5207 - f1_m: 0.5985 - precision_m: 0.5060 - recall_m: 0.8057\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8613 - accuracy: 0.5401 - f1_m: 0.6319 - precision_m: 0.5073 - recall_m: 0.8698\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8209 - accuracy: 0.5905 - f1_m: 0.6474 - precision_m: 0.5032 - recall_m: 0.9278\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7702 - accuracy: 0.5909 - f1_m: 0.6376 - precision_m: 0.4961 - recall_m: 0.9129\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7326 - accuracy: 0.6084 - f1_m: 0.6449 - precision_m: 0.4993 - recall_m: 0.9275\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.6118 - f1_m: 0.6475 - precision_m: 0.4995 - recall_m: 0.93 - 20s 240ms/step - loss: 0.7147 - accuracy: 0.6118 - f1_m: 0.6475 - precision_m: 0.4995 - recall_m: 0.9346\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7157 - accuracy: 0.6028 - f1_m: 0.6483 - precision_m: 0.5032 - recall_m: 0.9276\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6973 - accuracy: 0.6054 - f1_m: 0.6492 - precision_m: 0.5028 - recall_m: 0.9384\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6851 - accuracy: 0.6155 - f1_m: 0.6557 - precision_m: 0.5056 - recall_m: 0.9521\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6934 - accuracy: 0.6084 - f1_m: 0.6598 - precision_m: 0.5093 - recall_m: 0.9508\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6936 - accuracy: 0.6215 - f1_m: 0.6514 - precision_m: 0.5059 - recall_m: 0.9367\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6966 - accuracy: 0.6107 - f1_m: 0.6548 - precision_m: 0.5073 - recall_m: 0.9383\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6690 - accuracy: 0.6275 - f1_m: 0.6581 - precision_m: 0.5096 - recall_m: 0.9514\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6788 - accuracy: 0.6185 - f1_m: 0.6555 - precision_m: 0.5071 - recall_m: 0.9477\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6680 - accuracy: 0.6271 - f1_m: 0.6561 - precision_m: 0.5082 - recall_m: 0.9472\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6694 - accuracy: 0.6230 - f1_m: 0.6575 - precision_m: 0.5097 - recall_m: 0.9483\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6593 - accuracy: 0.6342 - f1_m: 0.6567 - precision_m: 0.5079 - recall_m: 0.9442\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6516 - accuracy: 0.6342 - f1_m: 0.6595 - precision_m: 0.5109 - recall_m: 0.9521\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6531 - accuracy: 0.6334 - f1_m: 0.6559 - precision_m: 0.5087 - recall_m: 0.9391\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6476 - accuracy: 0.6394 - f1_m: 0.6587 - precision_m: 0.5097 - recall_m: 0.9510\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6523 - accuracy: 0.6286 - f1_m: 0.6531 - precision_m: 0.5070 - recall_m: 0.9377\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6442 - accuracy: 0.6417 - f1_m: 0.6587 - precision_m: 0.5124 - recall_m: 0.9452\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6389 - accuracy: 0.6495 - f1_m: 0.6588 - precision_m: 0.5106 - recall_m: 0.9448\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.6353 - f1_m: 0.6568 - precision_m: 0.5112 - recall_m: 0.94 - 20s 237ms/step - loss: 0.6475 - accuracy: 0.6353 - f1_m: 0.6568 - precision_m: 0.5112 - recall_m: 0.9423\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6344 - accuracy: 0.6465 - f1_m: 0.6512 - precision_m: 0.5075 - recall_m: 0.9308\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6357 - accuracy: 0.6405 - f1_m: 0.6598 - precision_m: 0.5115 - recall_m: 0.9454\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 0.5382 - accuracy: 0.7522 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 235ms/step - loss: 0.9783 - accuracy: 0.4853 - f1_m: 0.5857 - precision_m: 0.4981 - recall_m: 0.7509\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 0.8052 - accuracy: 0.5084 - f1_m: 0.6433 - precision_m: 0.5147 - recall_m: 0.8814\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.7831 - accuracy: 0.4793 - f1_m: 0.6392 - precision_m: 0.5064 - recall_m: 0.8889\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 0.7573 - accuracy: 0.4923 - f1_m: 0.6496 - precision_m: 0.5066 - recall_m: 0.9303\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 0.7467 - accuracy: 0.5095 - f1_m: 0.6580 - precision_m: 0.5091 - recall_m: 0.9493\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 19s 232ms/step - loss: 0.7133 - accuracy: 0.5592 - f1_m: 0.6658 - precision_m: 0.5114 - recall_m: 0.9714\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.6971 - accuracy: 0.6002 - f1_m: 0.6544 - precision_m: 0.5029 - recall_m: 0.9557\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.6812 - accuracy: 0.6178 - f1_m: 0.6583 - precision_m: 0.5039 - recall_m: 0.9627\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 0.6802 - accuracy: 0.6066 - f1_m: 0.6590 - precision_m: 0.5049 - recall_m: 0.9655\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.6661 - accuracy: 0.6252 - f1_m: 0.6625 - precision_m: 0.5077 - recall_m: 0.9738\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.6672 - accuracy: 0.6159 - f1_m: 0.6593 - precision_m: 0.5052 - recall_m: 0.9668\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.6566 - accuracy: 0.6174 - f1_m: 0.6619 - precision_m: 0.5075 - recall_m: 0.9767\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.6542 - accuracy: 0.6152 - f1_m: 0.6667 - precision_m: 0.5102 - recall_m: 0.9814\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.6455 - accuracy: 0.6334 - f1_m: 0.6646 - precision_m: 0.5086 - recall_m: 0.9777\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.6429 - accuracy: 0.6316 - f1_m: 0.6646 - precision_m: 0.5095 - recall_m: 0.9779\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 0.6373 - accuracy: 0.6234 - f1_m: 0.6612 - precision_m: 0.5063 - recall_m: 0.9726\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.6354 - accuracy: 0.6290 - f1_m: 0.6653 - precision_m: 0.5103 - recall_m: 0.9779\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.6365 - accuracy: 0.6301 - f1_m: 0.6635 - precision_m: 0.5084 - recall_m: 0.9700\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.6271 - accuracy: 0.6417 - f1_m: 0.6682 - precision_m: 0.5124 - recall_m: 0.9804\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 19s 232ms/step - loss: 0.6222 - accuracy: 0.6525 - f1_m: 0.6632 - precision_m: 0.5089 - recall_m: 0.9699\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.6191 - accuracy: 0.6417 - f1_m: 0.6635 - precision_m: 0.5098 - recall_m: 0.9720\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 0.6131 - accuracy: 0.6473 - f1_m: 0.6663 - precision_m: 0.5117 - recall_m: 0.9719\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 0.5938 - accuracy: 0.6861 - f1_m: 0.6695 - precision_m: 0.5136 - recall_m: 0.9801\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.5981 - accuracy: 0.6809 - f1_m: 0.6645 - precision_m: 0.5118 - recall_m: 0.9657\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.5845 - accuracy: 0.6797 - f1_m: 0.6665 - precision_m: 0.5136 - recall_m: 0.9753\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.5793 - accuracy: 0.6823 - f1_m: 0.6646 - precision_m: 0.5112 - recall_m: 0.9684\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 19s 229ms/step - loss: 0.5686 - accuracy: 0.7040 - f1_m: 0.6633 - precision_m: 0.5097 - recall_m: 0.9671\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 19s 231ms/step - loss: 0.5806 - accuracy: 0.6984 - f1_m: 0.6660 - precision_m: 0.5155 - recall_m: 0.9605\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.5527 - accuracy: 0.7115 - f1_m: 0.6637 - precision_m: 0.5103 - recall_m: 0.9702\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 0.5552 - accuracy: 0.7256 - f1_m: 0.6642 - precision_m: 0.5134 - recall_m: 0.9586\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 0.4811 - accuracy: 0.7821 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 20s 225ms/step - loss: 1.3788 - accuracy: 0.4244 - f1_m: 0.3294 - precision_m: 0.4391 - recall_m: 0.2942\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 19s 222ms/step - loss: 1.0244 - accuracy: 0.4923 - f1_m: 0.5649 - precision_m: 0.5071 - recall_m: 0.6861\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 19s 221ms/step - loss: 0.8985 - accuracy: 0.4853 - f1_m: 0.6285 - precision_m: 0.5121 - recall_m: 0.8428\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 19s 224ms/step - loss: 0.8401 - accuracy: 0.5039 - f1_m: 0.6294 - precision_m: 0.5106 - recall_m: 0.8386\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 19s 222ms/step - loss: 0.8035 - accuracy: 0.5200 - f1_m: 0.6470 - precision_m: 0.5165 - recall_m: 0.8861\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 18s 220ms/step - loss: 0.7609 - accuracy: 0.5424 - f1_m: 0.6445 - precision_m: 0.5081 - recall_m: 0.8986\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 19s 222ms/step - loss: 0.7073 - accuracy: 0.6025 - f1_m: 0.6507 - precision_m: 0.5074 - recall_m: 0.9265\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 19s 220ms/step - loss: 0.6886 - accuracy: 0.6069 - f1_m: 0.6587 - precision_m: 0.5126 - recall_m: 0.9434\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.6795 - accuracy: 0.5991 - f1_m: 0.6507 - precision_m: 0.5068 - recall_m: 0.9321\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 18s 220ms/step - loss: 0.6583 - accuracy: 0.6237 - f1_m: 0.6628 - precision_m: 0.5123 - recall_m: 0.9572\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 18s 220ms/step - loss: 0.6415 - accuracy: 0.6394 - f1_m: 0.6614 - precision_m: 0.5087 - recall_m: 0.9625\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.6406 - accuracy: 0.6349 - f1_m: 0.6642 - precision_m: 0.5122 - recall_m: 0.9621\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 18s 220ms/step - loss: 0.6219 - accuracy: 0.6398 - f1_m: 0.6594 - precision_m: 0.5076 - recall_m: 0.9684\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.6136 - accuracy: 0.6555 - f1_m: 0.6584 - precision_m: 0.5060 - recall_m: 0.9660\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 0.6082 - accuracy: 0.6487 - f1_m: 0.6682 - precision_m: 0.5120 - recall_m: 0.9800\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 0.6114 - accuracy: 0.6570 - f1_m: 0.6600 - precision_m: 0.5080 - recall_m: 0.9697\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 0.5987 - accuracy: 0.6734 - f1_m: 0.6656 - precision_m: 0.5104 - recall_m: 0.9715\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.5939 - accuracy: 0.6659 - f1_m: 0.6613 - precision_m: 0.5060 - recall_m: 0.9723\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 0.6087 - accuracy: 0.6398 - f1_m: 0.6660 - precision_m: 0.5126 - recall_m: 0.9814\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 0.5865 - accuracy: 0.6726 - f1_m: 0.6606 - precision_m: 0.5063 - recall_m: 0.9651\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.5906 - accuracy: 0.6697 - f1_m: 0.6639 - precision_m: 0.5095 - recall_m: 0.9764\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.5843 - accuracy: 0.6771 - f1_m: 0.6590 - precision_m: 0.5062 - recall_m: 0.9667\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 18s 220ms/step - loss: 0.5816 - accuracy: 0.6831 - f1_m: 0.6647 - precision_m: 0.5101 - recall_m: 0.9756\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 18s 220ms/step - loss: 0.5747 - accuracy: 0.6782 - f1_m: 0.6661 - precision_m: 0.5086 - recall_m: 0.9823\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.5748 - accuracy: 0.6913 - f1_m: 0.6640 - precision_m: 0.5087 - recall_m: 0.9750\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 18s 218ms/step - loss: 0.5780 - accuracy: 0.6734 - f1_m: 0.6656 - precision_m: 0.5095 - recall_m: 0.9773\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 0.5720 - accuracy: 0.6823 - f1_m: 0.6613 - precision_m: 0.5068 - recall_m: 0.9696\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 0.5655 - accuracy: 0.6917 - f1_m: 0.6615 - precision_m: 0.5064 - recall_m: 0.9704\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 18s 218ms/step - loss: 0.5642 - accuracy: 0.6943 - f1_m: 0.6628 - precision_m: 0.5073 - recall_m: 0.9727\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 18s 218ms/step - loss: 0.5853 - accuracy: 0.6685 - f1_m: 0.6633 - precision_m: 0.5093 - recall_m: 0.9708\n",
      "11/11 [==============================] - 1s 43ms/step - loss: 0.4978 - accuracy: 0.7672 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 8, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 240ms/step - loss: 1.2573 - accuracy: 0.4965 - f1_m: 0.3800 - precision_m: 0.3430 - recall_m: 0.4828\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7731 - accuracy: 0.4976 - f1_m: 0.6509 - precision_m: 0.5110 - recall_m: 0.9148\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7354 - accuracy: 0.5054 - f1_m: 0.6520 - precision_m: 0.5088 - recall_m: 0.9279\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7217 - accuracy: 0.5065 - f1_m: 0.6547 - precision_m: 0.5072 - recall_m: 0.9397\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7219 - accuracy: 0.4894 - f1_m: 0.6572 - precision_m: 0.5079 - recall_m: 0.9542\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7086 - accuracy: 0.5095 - f1_m: 0.6586 - precision_m: 0.5083 - recall_m: 0.9546\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7120 - accuracy: 0.5006 - f1_m: 0.6575 - precision_m: 0.5061 - recall_m: 0.9570\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7099 - accuracy: 0.5125 - f1_m: 0.6579 - precision_m: 0.5065 - recall_m: 0.9593\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7052 - accuracy: 0.5121 - f1_m: 0.6653 - precision_m: 0.5106 - recall_m: 0.9689\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7063 - accuracy: 0.5106 - f1_m: 0.6617 - precision_m: 0.5072 - recall_m: 0.9667\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7081 - accuracy: 0.5054 - f1_m: 0.6615 - precision_m: 0.5067 - recall_m: 0.9721\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7047 - accuracy: 0.5073 - f1_m: 0.6595 - precision_m: 0.5070 - recall_m: 0.9591\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7057 - accuracy: 0.5035 - f1_m: 0.6632 - precision_m: 0.5079 - recall_m: 0.9740\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7082 - accuracy: 0.4849 - f1_m: 0.6586 - precision_m: 0.5059 - recall_m: 0.9659\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7044 - accuracy: 0.5043 - f1_m: 0.6603 - precision_m: 0.5067 - recall_m: 0.9623\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7044 - accuracy: 0.5006 - f1_m: 0.6633 - precision_m: 0.5071 - recall_m: 0.9777\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7062 - accuracy: 0.4946 - f1_m: 0.6633 - precision_m: 0.5093 - recall_m: 0.9717\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7030 - accuracy: 0.5133 - f1_m: 0.6609 - precision_m: 0.5079 - recall_m: 0.9737\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7051 - accuracy: 0.4961 - f1_m: 0.6568 - precision_m: 0.5044 - recall_m: 0.9614\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7032 - accuracy: 0.5047 - f1_m: 0.6654 - precision_m: 0.5098 - recall_m: 0.9777\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7050 - accuracy: 0.5103 - f1_m: 0.6599 - precision_m: 0.5069 - recall_m: 0.9630\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6995 - accuracy: 0.5088 - f1_m: 0.6677 - precision_m: 0.5094 - recall_m: 0.9822\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7052 - accuracy: 0.4923 - f1_m: 0.6610 - precision_m: 0.5092 - recall_m: 0.9660\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7017 - accuracy: 0.5091 - f1_m: 0.6657 - precision_m: 0.5095 - recall_m: 0.9768\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7033 - accuracy: 0.4905 - f1_m: 0.6616 - precision_m: 0.5068 - recall_m: 0.9709\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7031 - accuracy: 0.4965 - f1_m: 0.6642 - precision_m: 0.5082 - recall_m: 0.9773\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7019 - accuracy: 0.5002 - f1_m: 0.6624 - precision_m: 0.5073 - recall_m: 0.9704\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7053 - accuracy: 0.4931 - f1_m: 0.6652 - precision_m: 0.5089 - recall_m: 0.9822\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7039 - accuracy: 0.4793 - f1_m: 0.6617 - precision_m: 0.5064 - recall_m: 0.9695\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7037 - accuracy: 0.5073 - f1_m: 0.6622 - precision_m: 0.5076 - recall_m: 0.9743\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.6937 - accuracy: 0.5015 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 237ms/step - loss: 2.2318 - accuracy: 0.4834 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 1.7405 - accuracy: 0.4897 - f1_m: 0.0020 - precision_m: 0.0119 - recall_m: 0.0011   \n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 1.0566 - accuracy: 0.4991 - f1_m: 0.4007 - precision_m: 0.5384 - recall_m: 0.4272\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.8795 - accuracy: 0.5118 - f1_m: 0.5531 - precision_m: 0.5083 - recall_m: 0.6653\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.8684 - accuracy: 0.4909 - f1_m: 0.6252 - precision_m: 0.5119 - recall_m: 0.8267\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.8469 - accuracy: 0.4979 - f1_m: 0.5952 - precision_m: 0.4972 - recall_m: 0.8094\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.8258 - accuracy: 0.5095 - f1_m: 0.6640 - precision_m: 0.5063 - recall_m: 0.9831\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.8424 - accuracy: 0.4879 - f1_m: 0.6492 - precision_m: 0.5038 - recall_m: 0.9403\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.8170 - accuracy: 0.4968 - f1_m: 0.6266 - precision_m: 0.5143 - recall_m: 0.8709\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.8094 - accuracy: 0.5062 - f1_m: 0.6532 - precision_m: 0.5076 - recall_m: 0.9508\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.8185 - accuracy: 0.4897 - f1_m: 0.6640 - precision_m: 0.5082 - recall_m: 0.9790\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.8067 - accuracy: 0.5144 - f1_m: 0.6389 - precision_m: 0.5053 - recall_m: 0.9223\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.8156 - accuracy: 0.4979 - f1_m: 0.6532 - precision_m: 0.5103 - recall_m: 0.9479\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.7994 - accuracy: 0.4931 - f1_m: 0.6328 - precision_m: 0.5026 - recall_m: 0.9091\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.8166 - accuracy: 0.4864 - f1_m: 0.6640 - precision_m: 0.5082 - recall_m: 0.9770\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.8078 - accuracy: 0.5032 - f1_m: 0.6463 - precision_m: 0.5045 - recall_m: 0.9423\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.8007 - accuracy: 0.4976 - f1_m: 0.6666 - precision_m: 0.5086 - recall_m: 0.9887\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.8060 - accuracy: 0.4867 - f1_m: 0.6668 - precision_m: 0.5097 - recall_m: 0.9876\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.8013 - accuracy: 0.4916 - f1_m: 0.6592 - precision_m: 0.5110 - recall_m: 0.9672\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.8057 - accuracy: 0.4841 - f1_m: 0.6652 - precision_m: 0.5077 - recall_m: 0.9840\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7859 - accuracy: 0.5002 - f1_m: 0.6599 - precision_m: 0.5094 - recall_m: 0.9652\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.7900 - accuracy: 0.5002 - f1_m: 0.6188 - precision_m: 0.5096 - recall_m: 0.8693\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.7883 - accuracy: 0.4950 - f1_m: 0.6637 - precision_m: 0.5065 - recall_m: 0.9871\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7770 - accuracy: 0.5077 - f1_m: 0.6572 - precision_m: 0.5076 - recall_m: 0.9679\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.7904 - accuracy: 0.4860 - f1_m: 0.6483 - precision_m: 0.5068 - recall_m: 0.9402\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.7858 - accuracy: 0.4748 - f1_m: 0.6688 - precision_m: 0.5130 - recall_m: 0.9860\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.7854 - accuracy: 0.4905 - f1_m: 0.6596 - precision_m: 0.5097 - recall_m: 0.9597\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.7891 - accuracy: 0.4823 - f1_m: 0.6630 - precision_m: 0.5070 - recall_m: 0.9789\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.7755 - accuracy: 0.4860 - f1_m: 0.6640 - precision_m: 0.5067 - recall_m: 0.9832\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7814 - accuracy: 0.4789 - f1_m: 0.6568 - precision_m: 0.5080 - recall_m: 0.9516\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.7021 - accuracy: 0.5015 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 249ms/step - loss: 1.0368 - accuracy: 0.5017 - f1_m: 0.5499 - precision_m: 0.4643 - recall_m: 0.7427\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8550 - accuracy: 0.4897 - f1_m: 0.6381 - precision_m: 0.5090 - recall_m: 0.9048\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7812 - accuracy: 0.5028 - f1_m: 0.6548 - precision_m: 0.5109 - recall_m: 0.9435\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7515 - accuracy: 0.5032 - f1_m: 0.6560 - precision_m: 0.5088 - recall_m: 0.9524\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7146 - accuracy: 0.5435 - f1_m: 0.6603 - precision_m: 0.5079 - recall_m: 0.9612\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6688 - accuracy: 0.6103 - f1_m: 0.6646 - precision_m: 0.5081 - recall_m: 0.9767\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6314 - accuracy: 0.6476 - f1_m: 0.6615 - precision_m: 0.5064 - recall_m: 0.9819\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6173 - accuracy: 0.6581 - f1_m: 0.6667 - precision_m: 0.5079 - recall_m: 0.9916\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5931 - accuracy: 0.6823 - f1_m: 0.6656 - precision_m: 0.5066 - recall_m: 0.9907\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5733 - accuracy: 0.6954 - f1_m: 0.6683 - precision_m: 0.5081 - recall_m: 0.9917\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5527 - accuracy: 0.7171 - f1_m: 0.6681 - precision_m: 0.5075 - recall_m: 0.9955\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5638 - accuracy: 0.6976 - f1_m: 0.6681 - precision_m: 0.5071 - recall_m: 0.9953s - loss: 0.5638 - accuracy: 0.6976 - f1_m: 0.6681 - precision_m: 0.5071 - recall_m: 0.99\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5477 - accuracy: 0.7193 - f1_m: 0.6646 - precision_m: 0.5057 - recall_m: 0.9899\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5312 - accuracy: 0.7290 - f1_m: 0.6667 - precision_m: 0.5074 - recall_m: 0.9969\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5303 - accuracy: 0.7256 - f1_m: 0.6688 - precision_m: 0.5081 - recall_m: 0.9969\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5216 - accuracy: 0.7439 - f1_m: 0.6678 - precision_m: 0.5078 - recall_m: 0.9950\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5054 - accuracy: 0.7559 - f1_m: 0.6698 - precision_m: 0.5080 - recall_m: 0.9964\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5058 - accuracy: 0.7454 - f1_m: 0.6678 - precision_m: 0.5076 - recall_m: 0.9978\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4878 - accuracy: 0.7607 - f1_m: 0.6670 - precision_m: 0.5074 - recall_m: 0.9944\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4731 - accuracy: 0.7716 - f1_m: 0.6670 - precision_m: 0.5073 - recall_m: 0.9958\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.4559 - accuracy: 0.7813 - f1_m: 0.6668 - precision_m: 0.5071 - recall_m: 0.9959\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.4476 - accuracy: 0.7887 - f1_m: 0.6701 - precision_m: 0.5088 - recall_m: 0.9991\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4364 - accuracy: 0.7958 - f1_m: 0.6688 - precision_m: 0.5080 - recall_m: 0.9956\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.4469 - accuracy: 0.7962 - f1_m: 0.6682 - precision_m: 0.5070 - recall_m: 0.9959\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.4344 - accuracy: 0.7973 - f1_m: 0.6681 - precision_m: 0.5086 - recall_m: 0.9973\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4122 - accuracy: 0.8070 - f1_m: 0.6690 - precision_m: 0.5076 - recall_m: 0.9986\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.4095 - accuracy: 0.8134 - f1_m: 0.6678 - precision_m: 0.5077 - recall_m: 0.9958\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4044 - accuracy: 0.8122 - f1_m: 0.6692 - precision_m: 0.5081 - recall_m: 0.9970\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.3868 - accuracy: 0.8264 - f1_m: 0.6687 - precision_m: 0.5075 - recall_m: 0.9988\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_m: 0.6676 - precision_m: 0.5075 - recall_m: 0.9970\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 0.3212 - accuracy: 0.8657 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-12\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 240ms/step - loss: 1.2498 - accuracy: 0.4651 - f1_m: 0.4133 - precision_m: 0.4524 - recall_m: 0.4922\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.9410 - accuracy: 0.5021 - f1_m: 0.5744 - precision_m: 0.5118 - recall_m: 0.7904\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.8324 - accuracy: 0.5058 - f1_m: 0.5961 - precision_m: 0.5125 - recall_m: 0.8285\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7798 - accuracy: 0.5050 - f1_m: 0.6511 - precision_m: 0.5089 - recall_m: 0.9519\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7596 - accuracy: 0.5024 - f1_m: 0.6432 - precision_m: 0.5064 - recall_m: 0.9389\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7349 - accuracy: 0.5017 - f1_m: 0.6503 - precision_m: 0.4998 - recall_m: 0.9579\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7059 - accuracy: 0.5405 - f1_m: 0.6670 - precision_m: 0.5075 - recall_m: 0.9909\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6843 - accuracy: 0.5767 - f1_m: 0.6685 - precision_m: 0.5094 - recall_m: 0.9915\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6630 - accuracy: 0.6088 - f1_m: 0.6657 - precision_m: 0.5065 - recall_m: 0.9871\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6474 - accuracy: 0.6249 - f1_m: 0.6634 - precision_m: 0.5052 - recall_m: 0.9818\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6419 - accuracy: 0.6219 - f1_m: 0.6598 - precision_m: 0.5040 - recall_m: 0.9761\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6203 - accuracy: 0.6394 - f1_m: 0.6655 - precision_m: 0.5071 - recall_m: 0.9869\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6137 - accuracy: 0.6514 - f1_m: 0.6614 - precision_m: 0.5045 - recall_m: 0.9780\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5959 - accuracy: 0.6760 - f1_m: 0.6613 - precision_m: 0.5054 - recall_m: 0.9793\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5811 - accuracy: 0.6835 - f1_m: 0.6612 - precision_m: 0.5044 - recall_m: 0.9841\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5768 - accuracy: 0.6932 - f1_m: 0.6616 - precision_m: 0.5054 - recall_m: 0.9828\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5726 - accuracy: 0.6947 - f1_m: 0.6659 - precision_m: 0.5067 - recall_m: 0.9887\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.5762 - accuracy: 0.6954 - f1_m: 0.6635 - precision_m: 0.5057 - recall_m: 0.9869\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.5717 - accuracy: 0.7036 - f1_m: 0.6654 - precision_m: 0.5055 - recall_m: 0.9887\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.5609 - accuracy: 0.7077 - f1_m: 0.6651 - precision_m: 0.5075 - recall_m: 0.9894\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.5625 - accuracy: 0.7044 - f1_m: 0.6646 - precision_m: 0.5062 - recall_m: 0.9906\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.5616 - accuracy: 0.7103 - f1_m: 0.6618 - precision_m: 0.5050 - recall_m: 0.9835\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.5639 - accuracy: 0.7029 - f1_m: 0.6652 - precision_m: 0.5057 - recall_m: 0.9872\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5557 - accuracy: 0.7186 - f1_m: 0.6662 - precision_m: 0.5074 - recall_m: 0.9898\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.5491 - accuracy: 0.7260 - f1_m: 0.6662 - precision_m: 0.5077 - recall_m: 0.9941\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5517 - accuracy: 0.7186 - f1_m: 0.6649 - precision_m: 0.5071 - recall_m: 0.9889\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5414 - accuracy: 0.7350 - f1_m: 0.6650 - precision_m: 0.5073 - recall_m: 0.9928\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5342 - accuracy: 0.7372 - f1_m: 0.6652 - precision_m: 0.5069 - recall_m: 0.9896\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.5391 - accuracy: 0.7346 - f1_m: 0.6645 - precision_m: 0.5060 - recall_m: 0.9870\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.5326 - accuracy: 0.7275 - f1_m: 0.6684 - precision_m: 0.5080 - recall_m: 0.9902\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.4960 - accuracy: 0.7612 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-13\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 240ms/step - loss: 0.9213 - accuracy: 0.4890 - f1_m: 0.5976 - precision_m: 0.4699 - recall_m: 0.8464\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7399 - accuracy: 0.5114 - f1_m: 0.6572 - precision_m: 0.5069 - recall_m: 0.9513\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7335 - accuracy: 0.5080 - f1_m: 0.6532 - precision_m: 0.5049 - recall_m: 0.9472\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7062 - accuracy: 0.5256 - f1_m: 0.6702 - precision_m: 0.5133 - recall_m: 0.9819\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6516 - accuracy: 0.6278 - f1_m: 0.6651 - precision_m: 0.5076 - recall_m: 0.9852\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6167 - accuracy: 0.6540 - f1_m: 0.6664 - precision_m: 0.5080 - recall_m: 0.9887\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5872 - accuracy: 0.6704 - f1_m: 0.6689 - precision_m: 0.5080 - recall_m: 0.9971\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5874 - accuracy: 0.6782 - f1_m: 0.6684 - precision_m: 0.5083 - recall_m: 0.9951\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5693 - accuracy: 0.6861 - f1_m: 0.6703 - precision_m: 0.5098 - recall_m: 0.9962\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.5510 - accuracy: 0.7126 - f1_m: 0.6677 - precision_m: 0.5080 - recall_m: 0.9987\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5527 - accuracy: 0.7014 - f1_m: 0.6673 - precision_m: 0.5080 - recall_m: 0.9952\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5352 - accuracy: 0.7107 - f1_m: 0.6689 - precision_m: 0.5084 - recall_m: 0.9982\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5209 - accuracy: 0.7193 - f1_m: 0.6696 - precision_m: 0.5088 - recall_m: 0.9973\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5189 - accuracy: 0.7346 - f1_m: 0.6685 - precision_m: 0.5086 - recall_m: 0.9973s - loss: 0.5189 - accuracy: 0.7346 - f1_m: 0.6685 - precision_m: 0.5086 - recall_m: 0.99\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5155 - accuracy: 0.7238 - f1_m: 0.6690 - precision_m: 0.5084 - recall_m: 0.9986\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5253 - accuracy: 0.7260 - f1_m: 0.6675 - precision_m: 0.5075 - recall_m: 0.9954\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5074 - accuracy: 0.7387 - f1_m: 0.6685 - precision_m: 0.5082 - recall_m: 0.9965\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5010 - accuracy: 0.7465 - f1_m: 0.6679 - precision_m: 0.5072 - recall_m: 0.9983\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.4898 - accuracy: 0.7555 - f1_m: 0.6685 - precision_m: 0.5085 - recall_m: 0.9991\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.4954 - accuracy: 0.7424 - f1_m: 0.6692 - precision_m: 0.5080 - recall_m: 0.9967\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.4665 - accuracy: 0.7652 - f1_m: 0.6675 - precision_m: 0.5072 - recall_m: 0.9981\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.4570 - accuracy: 0.7798 - f1_m: 0.6683 - precision_m: 0.5072 - recall_m: 0.9970\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.4521 - accuracy: 0.7708 - f1_m: 0.6678 - precision_m: 0.5076 - recall_m: 0.9987\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4599 - accuracy: 0.7730 - f1_m: 0.6688 - precision_m: 0.5093 - recall_m: 0.9971\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.4320 - accuracy: 0.7910 - f1_m: 0.6673 - precision_m: 0.5074 - recall_m: 0.9991\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4314 - accuracy: 0.7958 - f1_m: 0.6693 - precision_m: 0.5088 - recall_m: 0.9987\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.4233 - accuracy: 0.7962 - f1_m: 0.6686 - precision_m: 0.5075 - recall_m: 0.9986\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.4169 - accuracy: 0.8055 - f1_m: 0.6676 - precision_m: 0.5077 - recall_m: 0.9985\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4172 - accuracy: 0.8078 - f1_m: 0.6685 - precision_m: 0.5075 - recall_m: 0.9984\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.4314 - accuracy: 0.7984 - f1_m: 0.6685 - precision_m: 0.5076 - recall_m: 0.9993\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.3339 - accuracy: 0.8806 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 251ms/step - loss: 1.3375 - accuracy: 0.4856 - f1_m: 0.3415 - precision_m: 0.3009 - recall_m: 0.4440\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7599 - accuracy: 0.4737 - f1_m: 0.6522 - precision_m: 0.5063 - recall_m: 0.9395\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7214 - accuracy: 0.4983 - f1_m: 0.6644 - precision_m: 0.5114 - recall_m: 0.9645\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.7137 - accuracy: 0.5091 - f1_m: 0.6671 - precision_m: 0.5113 - recall_m: 0.9722\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7127 - accuracy: 0.5095 - f1_m: 0.6624 - precision_m: 0.5101 - recall_m: 0.9657\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7128 - accuracy: 0.5077 - f1_m: 0.6667 - precision_m: 0.5117 - recall_m: 0.9773\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.7102 - accuracy: 0.5032 - f1_m: 0.6591 - precision_m: 0.5068 - recall_m: 0.9613\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7102 - accuracy: 0.4890 - f1_m: 0.6605 - precision_m: 0.5066 - recall_m: 0.9656\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7135 - accuracy: 0.4994 - f1_m: 0.6603 - precision_m: 0.5082 - recall_m: 0.9671\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7067 - accuracy: 0.5058 - f1_m: 0.6628 - precision_m: 0.5078 - recall_m: 0.9756\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7050 - accuracy: 0.4931 - f1_m: 0.6617 - precision_m: 0.5076 - recall_m: 0.9675\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7058 - accuracy: 0.4841 - f1_m: 0.6651 - precision_m: 0.5093 - recall_m: 0.9765\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7060 - accuracy: 0.5140 - f1_m: 0.6674 - precision_m: 0.5129 - recall_m: 0.9757\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.7039 - accuracy: 0.5013 - f1_m: 0.6624 - precision_m: 0.5088 - recall_m: 0.9719\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7053 - accuracy: 0.4976 - f1_m: 0.6630 - precision_m: 0.5089 - recall_m: 0.9741\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7053 - accuracy: 0.4823 - f1_m: 0.6603 - precision_m: 0.5082 - recall_m: 0.9614\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.7043 - accuracy: 0.4935 - f1_m: 0.6602 - precision_m: 0.5062 - recall_m: 0.9734\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.7050 - accuracy: 0.4819 - f1_m: 0.6601 - precision_m: 0.5061 - recall_m: 0.9685\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7011 - accuracy: 0.5017 - f1_m: 0.6660 - precision_m: 0.5090 - recall_m: 0.9796\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.7025 - accuracy: 0.4897 - f1_m: 0.6639 - precision_m: 0.5070 - recall_m: 0.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7036 - accuracy: 0.4860 - f1_m: 0.6626 - precision_m: 0.5074 - recall_m: 0.9730\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7018 - accuracy: 0.5121 - f1_m: 0.6650 - precision_m: 0.5082 - recall_m: 0.9816\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.7033 - accuracy: 0.4774 - f1_m: 0.6650 - precision_m: 0.5098 - recall_m: 0.9756\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6999 - accuracy: 0.5039 - f1_m: 0.6629 - precision_m: 0.5079 - recall_m: 0.9779\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7043 - accuracy: 0.4916 - f1_m: 0.6623 - precision_m: 0.5064 - recall_m: 0.9794\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7006 - accuracy: 0.4946 - f1_m: 0.6653 - precision_m: 0.5080 - recall_m: 0.9840\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7031 - accuracy: 0.4882 - f1_m: 0.6581 - precision_m: 0.5050 - recall_m: 0.9701\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7024 - accuracy: 0.4923 - f1_m: 0.6660 - precision_m: 0.5090 - recall_m: 0.9836\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7014 - accuracy: 0.4946 - f1_m: 0.6634 - precision_m: 0.5079 - recall_m: 0.9790\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6998 - accuracy: 0.4845 - f1_m: 0.6651 - precision_m: 0.5089 - recall_m: 0.9787\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.7068 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 243ms/step - loss: 2.1017 - accuracy: 0.4927 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 1.2231 - accuracy: 0.4920 - f1_m: 0.2532 - precision_m: 0.2696 - recall_m: 0.2610\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.8687 - accuracy: 0.4886 - f1_m: 0.5796 - precision_m: 0.5130 - recall_m: 0.6858\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7893 - accuracy: 0.5106 - f1_m: 0.5892 - precision_m: 0.5060 - recall_m: 0.7292\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7963 - accuracy: 0.4625 - f1_m: 0.5800 - precision_m: 0.5012 - recall_m: 0.7210\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7951 - accuracy: 0.4778 - f1_m: 0.5955 - precision_m: 0.4985 - recall_m: 0.7748\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7821 - accuracy: 0.4830 - f1_m: 0.6250 - precision_m: 0.5047 - recall_m: 0.84 - 21s 244ms/step - loss: 0.7821 - accuracy: 0.4830 - f1_m: 0.6250 - precision_m: 0.5047 - recall_m: 0.8455\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7707 - accuracy: 0.4965 - f1_m: 0.6403 - precision_m: 0.5115 - recall_m: 0.8783\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7719 - accuracy: 0.5050 - f1_m: 0.6407 - precision_m: 0.5098 - recall_m: 0.8834\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7738 - accuracy: 0.4909 - f1_m: 0.6421 - precision_m: 0.5071 - recall_m: 0.8995\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7747 - accuracy: 0.4882 - f1_m: 0.6507 - precision_m: 0.5104 - recall_m: 0.9208\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7740 - accuracy: 0.4826 - f1_m: 0.6433 - precision_m: 0.5048 - recall_m: 0.9102\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7723 - accuracy: 0.4994 - f1_m: 0.6478 - precision_m: 0.5078 - recall_m: 0.9175s - loss: 0.7723 - accuracy: 0.4994 - f1_m: 0.6478 - precision_m: 0.5078 - recall_m: 0.91\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7632 - accuracy: 0.4923 - f1_m: 0.6419 - precision_m: 0.5076 - recall_m: 0.9053\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7641 - accuracy: 0.5073 - f1_m: 0.6435 - precision_m: 0.5047 - recall_m: 0.9062\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7736 - accuracy: 0.4838 - f1_m: 0.6524 - precision_m: 0.5088 - recall_m: 0.9268\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7527 - accuracy: 0.5114 - f1_m: 0.6591 - precision_m: 0.5117 - recall_m: 0.9465\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7740 - accuracy: 0.4882 - f1_m: 0.6391 - precision_m: 0.5013 - recall_m: 0.8987\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7613 - accuracy: 0.4983 - f1_m: 0.6529 - precision_m: 0.5085 - recall_m: 0.9293\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7671 - accuracy: 0.4856 - f1_m: 0.6537 - precision_m: 0.5073 - recall_m: 0.9392\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7680 - accuracy: 0.4849 - f1_m: 0.6466 - precision_m: 0.5061 - recall_m: 0.9143\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7603 - accuracy: 0.4946 - f1_m: 0.6508 - precision_m: 0.5060 - recall_m: 0.9344\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7532 - accuracy: 0.5106 - f1_m: 0.6538 - precision_m: 0.5075 - recall_m: 0.9347\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7585 - accuracy: 0.5073 - f1_m: 0.6539 - precision_m: 0.5087 - recall_m: 0.9355\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7566 - accuracy: 0.4946 - f1_m: 0.6462 - precision_m: 0.5026 - recall_m: 0.9253\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7623 - accuracy: 0.4875 - f1_m: 0.6522 - precision_m: 0.5090 - recall_m: 0.9289\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7621 - accuracy: 0.4972 - f1_m: 0.6491 - precision_m: 0.5045 - recall_m: 0.9315\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7492 - accuracy: 0.5196 - f1_m: 0.6535 - precision_m: 0.5048 - recall_m: 0.9471\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7546 - accuracy: 0.4957 - f1_m: 0.6497 - precision_m: 0.5053 - recall_m: 0.9240\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7553 - accuracy: 0.4968 - f1_m: 0.6515 - precision_m: 0.5071 - recall_m: 0.9298\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.6944 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 246ms/step - loss: 0.9892 - accuracy: 0.4666 - f1_m: 0.5406 - precision_m: 0.4665 - recall_m: 0.6940\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.8053 - accuracy: 0.5166 - f1_m: 0.6389 - precision_m: 0.5065 - recall_m: 0.8901\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7877 - accuracy: 0.4976 - f1_m: 0.6348 - precision_m: 0.5095 - recall_m: 0.8600\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.7527 - accuracy: 0.5024 - f1_m: 0.6481 - precision_m: 0.5123 - recall_m: 0.9064\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7443 - accuracy: 0.4972 - f1_m: 0.6581 - precision_m: 0.5109 - recall_m: 0.9435\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7178 - accuracy: 0.5125 - f1_m: 0.6644 - precision_m: 0.5092 - recall_m: 0.9736\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7094 - accuracy: 0.5110 - f1_m: 0.6623 - precision_m: 0.5088 - recall_m: 0.9667\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7103 - accuracy: 0.4965 - f1_m: 0.6637 - precision_m: 0.5092 - recall_m: 0.9768\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7058 - accuracy: 0.4994 - f1_m: 0.6634 - precision_m: 0.5094 - recall_m: 0.9718\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7091 - accuracy: 0.4871 - f1_m: 0.6581 - precision_m: 0.5051 - recall_m: 0.9621\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7051 - accuracy: 0.5114 - f1_m: 0.6648 - precision_m: 0.5090 - recall_m: 0.9790\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7082 - accuracy: 0.5248 - f1_m: 0.6626 - precision_m: 0.5080 - recall_m: 0.9722\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6992 - accuracy: 0.5162 - f1_m: 0.6657 - precision_m: 0.5078 - recall_m: 0.9859\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7775 - accuracy: 0.5155 - f1_m: 0.6397 - precision_m: 0.4903 - recall_m: 0.9362\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7030 - accuracy: 0.5062 - f1_m: 0.6578 - precision_m: 0.5064 - recall_m: 0.9675\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7070 - accuracy: 0.5293 - f1_m: 0.6655 - precision_m: 0.5095 - recall_m: 0.9819\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7094 - accuracy: 0.4938 - f1_m: 0.6597 - precision_m: 0.5042 - recall_m: 0.9731\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7039 - accuracy: 0.4897 - f1_m: 0.6636 - precision_m: 0.5064 - recall_m: 0.9801\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7054 - accuracy: 0.5088 - f1_m: 0.6672 - precision_m: 0.5090 - recall_m: 0.9814\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7034 - accuracy: 0.5054 - f1_m: 0.6675 - precision_m: 0.5085 - recall_m: 0.9887\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7062 - accuracy: 0.5006 - f1_m: 0.6641 - precision_m: 0.5076 - recall_m: 0.9808\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7047 - accuracy: 0.5140 - f1_m: 0.6637 - precision_m: 0.5068 - recall_m: 0.9833\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7060 - accuracy: 0.4920 - f1_m: 0.6645 - precision_m: 0.5065 - recall_m: 0.9855\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7088 - accuracy: 0.5050 - f1_m: 0.6649 - precision_m: 0.5089 - recall_m: 0.9783\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7039 - accuracy: 0.5103 - f1_m: 0.6646 - precision_m: 0.5084 - recall_m: 0.9858\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7056 - accuracy: 0.5032 - f1_m: 0.6605 - precision_m: 0.5059 - recall_m: 0.9737\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7035 - accuracy: 0.5021 - f1_m: 0.6677 - precision_m: 0.5099 - recall_m: 0.9852\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7021 - accuracy: 0.4987 - f1_m: 0.6646 - precision_m: 0.5078 - recall_m: 0.9850\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7033 - accuracy: 0.5147 - f1_m: 0.6659 - precision_m: 0.5089 - recall_m: 0.9863\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7004 - accuracy: 0.5271 - f1_m: 0.6656 - precision_m: 0.5089 - recall_m: 0.9824\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 0.6894 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 243ms/step - loss: 0.8119 - accuracy: 0.4860 - f1_m: 0.6244 - precision_m: 0.5002 - recall_m: 0.8792\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7197 - accuracy: 0.4767 - f1_m: 0.6618 - precision_m: 0.5086 - recall_m: 0.9663\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7086 - accuracy: 0.4882 - f1_m: 0.6651 - precision_m: 0.5110 - recall_m: 0.9734\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7017 - accuracy: 0.5159 - f1_m: 0.6650 - precision_m: 0.5100 - recall_m: 0.9760\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7017 - accuracy: 0.4983 - f1_m: 0.6654 - precision_m: 0.5097 - recall_m: 0.9777\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7015 - accuracy: 0.4972 - f1_m: 0.6631 - precision_m: 0.5079 - recall_m: 0.9727\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6993 - accuracy: 0.5035 - f1_m: 0.6652 - precision_m: 0.5078 - recall_m: 0.9804\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6967 - accuracy: 0.5237 - f1_m: 0.6650 - precision_m: 0.5073 - recall_m: 0.9827\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6984 - accuracy: 0.4953 - f1_m: 0.6625 - precision_m: 0.5071 - recall_m: 0.9762\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6983 - accuracy: 0.4912 - f1_m: 0.6683 - precision_m: 0.5102 - recall_m: 0.9879\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6968 - accuracy: 0.5121 - f1_m: 0.6653 - precision_m: 0.5073 - recall_m: 0.9839\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6841 - accuracy: 0.5543 - f1_m: 0.6673 - precision_m: 0.5067 - recall_m: 0.9929\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6584 - accuracy: 0.6110 - f1_m: 0.6674 - precision_m: 0.5091 - recall_m: 0.9895\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6415 - accuracy: 0.6346 - f1_m: 0.6625 - precision_m: 0.5058 - recall_m: 0.9829\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6120 - accuracy: 0.6667 - f1_m: 0.6655 - precision_m: 0.5067 - recall_m: 0.9871\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6072 - accuracy: 0.6689 - f1_m: 0.6677 - precision_m: 0.5091 - recall_m: 0.9906\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5972 - accuracy: 0.6816 - f1_m: 0.6643 - precision_m: 0.5048 - recall_m: 0.9861\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6031 - accuracy: 0.6794 - f1_m: 0.6679 - precision_m: 0.5097 - recall_m: 0.9915\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5806 - accuracy: 0.6868 - f1_m: 0.6666 - precision_m: 0.5071 - recall_m: 0.9901\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5780 - accuracy: 0.6932 - f1_m: 0.6680 - precision_m: 0.5084 - recall_m: 0.9923\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5746 - accuracy: 0.6988 - f1_m: 0.6701 - precision_m: 0.5101 - recall_m: 0.9951\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5712 - accuracy: 0.6988 - f1_m: 0.6670 - precision_m: 0.5085 - recall_m: 0.9890\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5581 - accuracy: 0.7096 - f1_m: 0.6675 - precision_m: 0.5086 - recall_m: 0.9911\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5669 - accuracy: 0.6969 - f1_m: 0.6651 - precision_m: 0.5073 - recall_m: 0.9881\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5582 - accuracy: 0.7081 - f1_m: 0.6681 - precision_m: 0.5083 - recall_m: 0.9914\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5523 - accuracy: 0.7088 - f1_m: 0.6676 - precision_m: 0.5083 - recall_m: 0.9936\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5365 - accuracy: 0.7253 - f1_m: 0.6662 - precision_m: 0.5076 - recall_m: 0.9899\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5326 - accuracy: 0.7327 - f1_m: 0.6659 - precision_m: 0.5070 - recall_m: 0.9881\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5318 - accuracy: 0.7350 - f1_m: 0.6662 - precision_m: 0.5078 - recall_m: 0.9867\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5204 - accuracy: 0.7361 - f1_m: 0.6672 - precision_m: 0.5077 - recall_m: 0.9874\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.4552 - accuracy: 0.7940 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 242ms/step - loss: 0.9604 - accuracy: 0.4938 - f1_m: 0.5726 - precision_m: 0.4549 - recall_m: 0.7932\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7456 - accuracy: 0.5095 - f1_m: 0.6537 - precision_m: 0.5086 - recall_m: 0.9367\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7327 - accuracy: 0.5039 - f1_m: 0.6574 - precision_m: 0.5085 - recall_m: 0.9501\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7168 - accuracy: 0.5080 - f1_m: 0.6603 - precision_m: 0.5067 - recall_m: 0.9610\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7079 - accuracy: 0.4976 - f1_m: 0.6620 - precision_m: 0.5065 - recall_m: 0.9728\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7029 - accuracy: 0.5054 - f1_m: 0.6615 - precision_m: 0.5058 - recall_m: 0.9695\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7004 - accuracy: 0.5069 - f1_m: 0.6628 - precision_m: 0.5076 - recall_m: 0.9762\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7051 - accuracy: 0.4882 - f1_m: 0.6582 - precision_m: 0.5054 - recall_m: 0.9611\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6976 - accuracy: 0.5114 - f1_m: 0.6640 - precision_m: 0.5080 - recall_m: 0.9782\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6981 - accuracy: 0.4991 - f1_m: 0.6691 - precision_m: 0.5085 - recall_m: 0.9912\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6992 - accuracy: 0.4957 - f1_m: 0.6647 - precision_m: 0.5064 - recall_m: 0.9830\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6982 - accuracy: 0.4946 - f1_m: 0.6610 - precision_m: 0.5065 - recall_m: 0.9765\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7003 - accuracy: 0.4935 - f1_m: 0.6611 - precision_m: 0.5059 - recall_m: 0.9743\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6957 - accuracy: 0.5069 - f1_m: 0.6666 - precision_m: 0.5071 - recall_m: 0.9919\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6975 - accuracy: 0.5017 - f1_m: 0.6679 - precision_m: 0.5070 - recall_m: 0.9912\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6968 - accuracy: 0.4991 - f1_m: 0.6670 - precision_m: 0.5081 - recall_m: 0.9910\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6970 - accuracy: 0.5118 - f1_m: 0.6644 - precision_m: 0.5070 - recall_m: 0.9872\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6965 - accuracy: 0.5047 - f1_m: 0.6690 - precision_m: 0.5084 - recall_m: 0.9960\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6965 - accuracy: 0.5080 - f1_m: 0.6671 - precision_m: 0.5080 - recall_m: 0.9923s - loss: 0.6965 - accuracy: 0.5080 - f1_m: 0.6671 - precision_m: 0.5080 - recall_m: 0.99\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6952 - accuracy: 0.5110 - f1_m: 0.6669 - precision_m: 0.5071 - recall_m: 0.9923\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6978 - accuracy: 0.4905 - f1_m: 0.6664 - precision_m: 0.5083 - recall_m: 0.9914\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.6970 - accuracy: 0.5065 - f1_m: 0.6691 - precision_m: 0.5097 - recall_m: 0.9919\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6965 - accuracy: 0.5054 - f1_m: 0.6663 - precision_m: 0.5073 - recall_m: 0.9942\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6999 - accuracy: 0.4752 - f1_m: 0.6638 - precision_m: 0.5078 - recall_m: 0.9841\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6975 - accuracy: 0.5099 - f1_m: 0.6659 - precision_m: 0.5076 - recall_m: 0.9908\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6944 - accuracy: 0.5062 - f1_m: 0.6683 - precision_m: 0.5085 - recall_m: 0.9934\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6960 - accuracy: 0.4983 - f1_m: 0.6699 - precision_m: 0.5096 - recall_m: 0.9971\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6982 - accuracy: 0.4994 - f1_m: 0.6676 - precision_m: 0.5080 - recall_m: 0.9916\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6955 - accuracy: 0.5032 - f1_m: 0.6670 - precision_m: 0.5087 - recall_m: 0.9875\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6953 - accuracy: 0.5039 - f1_m: 0.6633 - precision_m: 0.5068 - recall_m: 0.9904\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.7053 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 1.8560 - accuracy: 0.4882 - f1_m: 0.1193 - precision_m: 0.1164 - recall_m: 0.1326\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.8217 - accuracy: 0.5050 - f1_m: 0.6317 - precision_m: 0.5119 - recall_m: 0.8544\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7362 - accuracy: 0.5121 - f1_m: 0.6453 - precision_m: 0.5103 - recall_m: 0.8990\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7325 - accuracy: 0.4923 - f1_m: 0.6474 - precision_m: 0.5061 - recall_m: 0.9175\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7372 - accuracy: 0.4789 - f1_m: 0.6455 - precision_m: 0.5059 - recall_m: 0.9205\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7238 - accuracy: 0.5080 - f1_m: 0.6501 - precision_m: 0.5055 - recall_m: 0.9274\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7288 - accuracy: 0.4979 - f1_m: 0.6457 - precision_m: 0.5045 - recall_m: 0.9215\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7287 - accuracy: 0.4950 - f1_m: 0.6559 - precision_m: 0.5103 - recall_m: 0.9372\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7175 - accuracy: 0.5166 - f1_m: 0.6526 - precision_m: 0.5070 - recall_m: 0.9310\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7140 - accuracy: 0.5211 - f1_m: 0.6551 - precision_m: 0.5059 - recall_m: 0.9492\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7164 - accuracy: 0.5006 - f1_m: 0.6597 - precision_m: 0.5100 - recall_m: 0.9533\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7191 - accuracy: 0.4909 - f1_m: 0.6585 - precision_m: 0.5109 - recall_m: 0.9435\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7172 - accuracy: 0.5125 - f1_m: 0.6500 - precision_m: 0.5047 - recall_m: 0.9349\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7173 - accuracy: 0.4968 - f1_m: 0.6594 - precision_m: 0.5077 - recall_m: 0.9588\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7165 - accuracy: 0.5047 - f1_m: 0.6577 - precision_m: 0.5088 - recall_m: 0.9493\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7227 - accuracy: 0.4983 - f1_m: 0.6509 - precision_m: 0.5049 - recall_m: 0.9347\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7148 - accuracy: 0.5211 - f1_m: 0.6568 - precision_m: 0.5068 - recall_m: 0.9532\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7142 - accuracy: 0.5050 - f1_m: 0.6620 - precision_m: 0.5100 - recall_m: 0.9637s - loss: 0.7142 - accuracy: 0.5050 - f1_m: 0.6620 - precision_m: 0.5100 - recall_m: 0.96\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7111 - accuracy: 0.4860 - f1_m: 0.6646 - precision_m: 0.5100 - recall_m: 0.9697\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7189 - accuracy: 0.4756 - f1_m: 0.6590 - precision_m: 0.5077 - recall_m: 0.9565\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7131 - accuracy: 0.4953 - f1_m: 0.6542 - precision_m: 0.5045 - recall_m: 0.9436\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7188 - accuracy: 0.5009 - f1_m: 0.6547 - precision_m: 0.5049 - recall_m: 0.9551\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7168 - accuracy: 0.4826 - f1_m: 0.6487 - precision_m: 0.5030 - recall_m: 0.9357\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7162 - accuracy: 0.4894 - f1_m: 0.6592 - precision_m: 0.5113 - recall_m: 0.9457\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7114 - accuracy: 0.5043 - f1_m: 0.6628 - precision_m: 0.5113 - recall_m: 0.9614\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7153 - accuracy: 0.5050 - f1_m: 0.6608 - precision_m: 0.5078 - recall_m: 0.9651\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7124 - accuracy: 0.4879 - f1_m: 0.6639 - precision_m: 0.5111 - recall_m: 0.9646\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7126 - accuracy: 0.4935 - f1_m: 0.6556 - precision_m: 0.5051 - recall_m: 0.9576\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7140 - accuracy: 0.4998 - f1_m: 0.6595 - precision_m: 0.5078 - recall_m: 0.9619\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7125 - accuracy: 0.4916 - f1_m: 0.6569 - precision_m: 0.5069 - recall_m: 0.9533\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.6938 - accuracy: 0.5015 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 242ms/step - loss: 2.2348 - accuracy: 0.4912 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 1.7261 - accuracy: 0.4882 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.9468 - accuracy: 0.4879 - f1_m: 0.3356 - precision_m: 0.5017 - recall_m: 0.3096\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8046 - accuracy: 0.4729 - f1_m: 0.5992 - precision_m: 0.5163 - recall_m: 0.7455\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7768 - accuracy: 0.4916 - f1_m: 0.6366 - precision_m: 0.5099 - recall_m: 0.8754\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7592 - accuracy: 0.5021 - f1_m: 0.6426 - precision_m: 0.5057 - recall_m: 0.8971\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7660 - accuracy: 0.4856 - f1_m: 0.6479 - precision_m: 0.5069 - recall_m: 0.9197\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7518 - accuracy: 0.4931 - f1_m: 0.6500 - precision_m: 0.5076 - recall_m: 0.9253\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7446 - accuracy: 0.4994 - f1_m: 0.6572 - precision_m: 0.5113 - recall_m: 0.9403\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7420 - accuracy: 0.4994 - f1_m: 0.6516 - precision_m: 0.5041 - recall_m: 0.9377\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7455 - accuracy: 0.5017 - f1_m: 0.6556 - precision_m: 0.5046 - recall_m: 0.9538\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7405 - accuracy: 0.4961 - f1_m: 0.6542 - precision_m: 0.5064 - recall_m: 0.9483\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7432 - accuracy: 0.4953 - f1_m: 0.6622 - precision_m: 0.5084 - recall_m: 0.9621\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7335 - accuracy: 0.5002 - f1_m: 0.6634 - precision_m: 0.5097 - recall_m: 0.9727\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7357 - accuracy: 0.5047 - f1_m: 0.6563 - precision_m: 0.5063 - recall_m: 0.9533\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7390 - accuracy: 0.4920 - f1_m: 0.6521 - precision_m: 0.5087 - recall_m: 0.9335\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7431 - accuracy: 0.4972 - f1_m: 0.6510 - precision_m: 0.5046 - recall_m: 0.9354\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7281 - accuracy: 0.4927 - f1_m: 0.6562 - precision_m: 0.5041 - recall_m: 0.9634\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7312 - accuracy: 0.5002 - f1_m: 0.6582 - precision_m: 0.5075 - recall_m: 0.9631\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7271 - accuracy: 0.4976 - f1_m: 0.6616 - precision_m: 0.5092 - recall_m: 0.9691s - loss: 0.7271 - accuracy: 0.4976 - f1_m: 0.6616 - precision_m: 0.5092 - recall_m: 0.96\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7238 - accuracy: 0.4927 - f1_m: 0.6623 - precision_m: 0.5081 - recall_m: 0.9738\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7290 - accuracy: 0.4860 - f1_m: 0.6573 - precision_m: 0.5072 - recall_m: 0.9541\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7313 - accuracy: 0.5013 - f1_m: 0.6611 - precision_m: 0.5067 - recall_m: 0.9711\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7318 - accuracy: 0.4942 - f1_m: 0.6572 - precision_m: 0.5070 - recall_m: 0.9549\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7283 - accuracy: 0.4886 - f1_m: 0.6590 - precision_m: 0.5048 - recall_m: 0.9650\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7230 - accuracy: 0.5024 - f1_m: 0.6576 - precision_m: 0.5080 - recall_m: 0.9587\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7222 - accuracy: 0.5069 - f1_m: 0.6633 - precision_m: 0.5078 - recall_m: 0.9748\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7163 - accuracy: 0.5103 - f1_m: 0.6588 - precision_m: 0.5053 - recall_m: 0.9650\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7223 - accuracy: 0.5017 - f1_m: 0.6628 - precision_m: 0.5094 - recall_m: 0.9703\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7128 - accuracy: 0.5155 - f1_m: 0.6655 - precision_m: 0.5086 - recall_m: 0.9846\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.6958 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 252ms/step - loss: 0.8773 - accuracy: 0.4920 - f1_m: 0.5997 - precision_m: 0.4686 - recall_m: 0.8572\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7330 - accuracy: 0.4998 - f1_m: 0.6577 - precision_m: 0.5084 - recall_m: 0.9540\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7004 - accuracy: 0.5386 - f1_m: 0.6564 - precision_m: 0.5050 - recall_m: 0.9616\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.6371 - accuracy: 0.6361 - f1_m: 0.6682 - precision_m: 0.5091 - recall_m: 0.9907\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.6003 - accuracy: 0.6734 - f1_m: 0.6680 - precision_m: 0.5090 - recall_m: 0.9951\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.5661 - accuracy: 0.7003 - f1_m: 0.6668 - precision_m: 0.5076 - recall_m: 0.9947\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.5381 - accuracy: 0.7271 - f1_m: 0.6683 - precision_m: 0.5074 - recall_m: 0.9986\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.5442 - accuracy: 0.7223 - f1_m: 0.6685 - precision_m: 0.5075 - recall_m: 0.9990\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.5303 - accuracy: 0.7312 - f1_m: 0.6682 - precision_m: 0.5080 - recall_m: 0.9986\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.5137 - accuracy: 0.7424 - f1_m: 0.6691 - precision_m: 0.5079 - recall_m: 0.9977\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4993 - accuracy: 0.7563 - f1_m: 0.6690 - precision_m: 0.5075 - recall_m: 0.9993\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.5023 - accuracy: 0.7495 - f1_m: 0.6672 - precision_m: 0.5074 - recall_m: 0.9982\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4839 - accuracy: 0.7667 - f1_m: 0.6689 - precision_m: 0.5076 - recall_m: 0.9993\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4677 - accuracy: 0.7678 - f1_m: 0.6693 - precision_m: 0.5078 - recall_m: 0.9994\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.4661 - accuracy: 0.7730 - f1_m: 0.6671 - precision_m: 0.5070 - recall_m: 0.9985\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4670 - accuracy: 0.7869 - f1_m: 0.6682 - precision_m: 0.5075 - recall_m: 0.9979\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4360 - accuracy: 0.7921 - f1_m: 0.6694 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.4182 - accuracy: 0.8063 - f1_m: 0.6696 - precision_m: 0.5079 - recall_m: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4107 - accuracy: 0.8093 - f1_m: 0.6693 - precision_m: 0.5078 - recall_m: 0.9986\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.3977 - accuracy: 0.8208 - f1_m: 0.6694 - precision_m: 0.5077 - recall_m: 0.9993\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.3945 - accuracy: 0.8257 - f1_m: 0.6665 - precision_m: 0.5084 - recall_m: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.3917 - accuracy: 0.8246 - f1_m: 0.6696 - precision_m: 0.5077 - recall_m: 0.9994\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.3895 - accuracy: 0.8335 - f1_m: 0.6683 - precision_m: 0.5082 - recall_m: 0.9993\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.3688 - accuracy: 0.8387 - f1_m: 0.6703 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.3468 - accuracy: 0.8443 - f1_m: 0.6695 - precision_m: 0.5080 - recall_m: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.3393 - accuracy: 0.8503 - f1_m: 0.6690 - precision_m: 0.5076 - recall_m: 0.9993\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.3410 - accuracy: 0.8514 - f1_m: 0.6698 - precision_m: 0.5083 - recall_m: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.3415 - accuracy: 0.8529 - f1_m: 0.6692 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.3404 - accuracy: 0.8455 - f1_m: 0.6674 - precision_m: 0.5067 - recall_m: 0.9993\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.3293 - accuracy: 0.8567 - f1_m: 0.6685 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 44ms/step - loss: 0.3290 - accuracy: 0.8806 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.8206 - accuracy: 0.5047 - f1_m: 0.6192 - precision_m: 0.4831 - recall_m: 0.8895\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7277 - accuracy: 0.4979 - f1_m: 0.6618 - precision_m: 0.5091 - recall_m: 0.9660\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6982 - accuracy: 0.5386 - f1_m: 0.6621 - precision_m: 0.5059 - recall_m: 0.9797\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6453 - accuracy: 0.6215 - f1_m: 0.6676 - precision_m: 0.5069 - recall_m: 0.9972\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6021 - accuracy: 0.6738 - f1_m: 0.6699 - precision_m: 0.5083 - recall_m: 1.0000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5852 - accuracy: 0.6846 - f1_m: 0.6704 - precision_m: 0.5085 - recall_m: 1.0000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5793 - accuracy: 0.6879 - f1_m: 0.6686 - precision_m: 0.5074 - recall_m: 0.9986\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5638 - accuracy: 0.6984 - f1_m: 0.6692 - precision_m: 0.5077 - recall_m: 0.9993\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5376 - accuracy: 0.7197 - f1_m: 0.6689 - precision_m: 0.5077 - recall_m: 0.9991\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5373 - accuracy: 0.7200 - f1_m: 0.6682 - precision_m: 0.5072 - recall_m: 0.9991\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5203 - accuracy: 0.7350 - f1_m: 0.6682 - precision_m: 0.5070 - recall_m: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5151 - accuracy: 0.7495 - f1_m: 0.6693 - precision_m: 0.5076 - recall_m: 0.9991\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.4984 - accuracy: 0.7559 - f1_m: 0.6684 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4799 - accuracy: 0.7648 - f1_m: 0.6687 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4646 - accuracy: 0.7872 - f1_m: 0.6687 - precision_m: 0.5082 - recall_m: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4564 - accuracy: 0.7831 - f1_m: 0.6679 - precision_m: 0.5070 - recall_m: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 22s 257ms/step - loss: 0.4431 - accuracy: 0.7824 - f1_m: 0.6689 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.4292 - accuracy: 0.8081 - f1_m: 0.6693 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 22s 266ms/step - loss: 0.4174 - accuracy: 0.8141 - f1_m: 0.6685 - precision_m: 0.5072 - recall_m: 0.9995\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.4116 - accuracy: 0.8149 - f1_m: 0.6691 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.4049 - accuracy: 0.8190 - f1_m: 0.6684 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 22s 261ms/step - loss: 0.3851 - accuracy: 0.8287 - f1_m: 0.6679 - precision_m: 0.5077 - recall_m: 0.9994\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 22s 261ms/step - loss: 0.3843 - accuracy: 0.8343 - f1_m: 0.6693 - precision_m: 0.5071 - recall_m: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.3823 - accuracy: 0.8358 - f1_m: 0.6688 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.3841 - accuracy: 0.8346 - f1_m: 0.6696 - precision_m: 0.5083 - recall_m: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.3794 - accuracy: 0.8290 - f1_m: 0.6684 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.3795 - accuracy: 0.8339 - f1_m: 0.6684 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.3647 - accuracy: 0.8429 - f1_m: 0.6674 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.3739 - accuracy: 0.8365 - f1_m: 0.6692 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.3588 - accuracy: 0.8496 - f1_m: 0.6683 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2971 - accuracy: 0.8806 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 240ms/step - loss: 0.8417 - accuracy: 0.4965 - f1_m: 0.6060 - precision_m: 0.4652 - recall_m: 0.8916\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7132 - accuracy: 0.4871 - f1_m: 0.6589 - precision_m: 0.5055 - recall_m: 0.9644\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7021 - accuracy: 0.4987 - f1_m: 0.6634 - precision_m: 0.5054 - recall_m: 0.9853\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7019 - accuracy: 0.5121 - f1_m: 0.6665 - precision_m: 0.5090 - recall_m: 0.9852\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7011 - accuracy: 0.5084 - f1_m: 0.6666 - precision_m: 0.5092 - recall_m: 0.9894\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6987 - accuracy: 0.5017 - f1_m: 0.6703 - precision_m: 0.5116 - recall_m: 0.9955\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6977 - accuracy: 0.4946 - f1_m: 0.6660 - precision_m: 0.5085 - recall_m: 0.9893\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6971 - accuracy: 0.4875 - f1_m: 0.6665 - precision_m: 0.5070 - recall_m: 0.9918\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6937 - accuracy: 0.5207 - f1_m: 0.6657 - precision_m: 0.5072 - recall_m: 0.9901\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6566 - accuracy: 0.6028 - f1_m: 0.6672 - precision_m: 0.5069 - recall_m: 0.9963\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6307 - accuracy: 0.6316 - f1_m: 0.6688 - precision_m: 0.5080 - recall_m: 0.9993\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6004 - accuracy: 0.6588 - f1_m: 0.6684 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5643 - accuracy: 0.6909 - f1_m: 0.6675 - precision_m: 0.5071 - recall_m: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5458 - accuracy: 0.7130 - f1_m: 0.6692 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5408 - accuracy: 0.7245 - f1_m: 0.6690 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5279 - accuracy: 0.7174 - f1_m: 0.6692 - precision_m: 0.5084 - recall_m: 0.9993\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5132 - accuracy: 0.7387 - f1_m: 0.6688 - precision_m: 0.5074 - recall_m: 0.9992\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5164 - accuracy: 0.7357 - f1_m: 0.6695 - precision_m: 0.5084 - recall_m: 0.9994\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5191 - accuracy: 0.7368 - f1_m: 0.6706 - precision_m: 0.5079 - recall_m: 0.9993\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5092 - accuracy: 0.7428 - f1_m: 0.6680 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5050 - accuracy: 0.7432 - f1_m: 0.6675 - precision_m: 0.5077 - recall_m: 0.9993\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4866 - accuracy: 0.7660 - f1_m: 0.6683 - precision_m: 0.5073 - recall_m: 0.9993\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5002 - accuracy: 0.7443 - f1_m: 0.6688 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4824 - accuracy: 0.7585 - f1_m: 0.6696 - precision_m: 0.5081 - recall_m: 0.9993\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.4847 - accuracy: 0.7704 - f1_m: 0.6685 - precision_m: 0.5076 - recall_m: 0.9981\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.4625 - accuracy: 0.7723 - f1_m: 0.6687 - precision_m: 0.5081 - recall_m: 0.9991\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4731 - accuracy: 0.7645 - f1_m: 0.6685 - precision_m: 0.5080 - recall_m: 0.9986s - loss: 0.4731 - accuracy: 0.7645 - f1_m: 0.6685 - precision_m: 0.5080 - recall_m: 0.99\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4662 - accuracy: 0.7786 - f1_m: 0.6670 - precision_m: 0.5082 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.4291 - accuracy: 0.8029 - f1_m: 0.6691 - precision_m: 0.5074 - recall_m: 0.9993\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4182 - accuracy: 0.8025 - f1_m: 0.6677 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.3857 - accuracy: 0.8149 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-24\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 1.1657 - accuracy: 0.4886 - f1_m: 0.3991 - precision_m: 0.3266 - recall_m: 0.5546\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7286 - accuracy: 0.4909 - f1_m: 0.6594 - precision_m: 0.5068 - recall_m: 0.9620\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7132 - accuracy: 0.5002 - f1_m: 0.6607 - precision_m: 0.5070 - recall_m: 0.9701\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7069 - accuracy: 0.5103 - f1_m: 0.6675 - precision_m: 0.5106 - recall_m: 0.9833\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7111 - accuracy: 0.4953 - f1_m: 0.6621 - precision_m: 0.5065 - recall_m: 0.9745\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7054 - accuracy: 0.5032 - f1_m: 0.6623 - precision_m: 0.5076 - recall_m: 0.9724\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7048 - accuracy: 0.4994 - f1_m: 0.6622 - precision_m: 0.5067 - recall_m: 0.9773\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7056 - accuracy: 0.5009 - f1_m: 0.6617 - precision_m: 0.5046 - recall_m: 0.9806\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.7041 - accuracy: 0.4950 - f1_m: 0.6623 - precision_m: 0.5072 - recall_m: 0.9773\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7067 - accuracy: 0.4938 - f1_m: 0.6609 - precision_m: 0.5061 - recall_m: 0.9777\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7044 - accuracy: 0.4979 - f1_m: 0.6644 - precision_m: 0.5094 - recall_m: 0.9780\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.6993 - accuracy: 0.5099 - f1_m: 0.6665 - precision_m: 0.5070 - recall_m: 0.9860\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6994 - accuracy: 0.5140 - f1_m: 0.6686 - precision_m: 0.5096 - recall_m: 0.9897\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7028 - accuracy: 0.4871 - f1_m: 0.6658 - precision_m: 0.5093 - recall_m: 0.9817\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6981 - accuracy: 0.5185 - f1_m: 0.6668 - precision_m: 0.5079 - recall_m: 0.9859\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7023 - accuracy: 0.4950 - f1_m: 0.6662 - precision_m: 0.5085 - recall_m: 0.9839\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7030 - accuracy: 0.4867 - f1_m: 0.6616 - precision_m: 0.5053 - recall_m: 0.9770\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.6986 - accuracy: 0.5080 - f1_m: 0.6688 - precision_m: 0.5088 - recall_m: 0.9925\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7001 - accuracy: 0.5047 - f1_m: 0.6643 - precision_m: 0.5068 - recall_m: 0.9902\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.6995 - accuracy: 0.4867 - f1_m: 0.6690 - precision_m: 0.5099 - recall_m: 0.9872\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.6996 - accuracy: 0.4886 - f1_m: 0.6648 - precision_m: 0.5070 - recall_m: 0.9800\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7022 - accuracy: 0.5084 - f1_m: 0.6638 - precision_m: 0.5084 - recall_m: 0.9864\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.6987 - accuracy: 0.4965 - f1_m: 0.6649 - precision_m: 0.5092 - recall_m: 0.9795\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7028 - accuracy: 0.4901 - f1_m: 0.6635 - precision_m: 0.5072 - recall_m: 0.9836\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.6993 - accuracy: 0.4961 - f1_m: 0.6622 - precision_m: 0.5063 - recall_m: 0.9836\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 24s 291ms/step - loss: 0.6994 - accuracy: 0.4849 - f1_m: 0.6661 - precision_m: 0.5066 - recall_m: 0.9866\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.6999 - accuracy: 0.4856 - f1_m: 0.6625 - precision_m: 0.5059 - recall_m: 0.9827\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.7010 - accuracy: 0.5009 - f1_m: 0.6639 - precision_m: 0.5071 - recall_m: 0.9848\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.6996 - accuracy: 0.4950 - f1_m: 0.6670 - precision_m: 0.5082 - recall_m: 0.9896\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 22s 261ms/step - loss: 0.6982 - accuracy: 0.5032 - f1_m: 0.6652 - precision_m: 0.5069 - recall_m: 0.9873\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.6977 - accuracy: 0.5015 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-25\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 248ms/step - loss: 2.2497 - accuracy: 0.4938 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 1.8701 - accuracy: 0.4912 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 1.2655 - accuracy: 0.4856 - f1_m: 0.0985 - precision_m: 0.2446 - recall_m: 0.0688\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 1.0241 - accuracy: 0.4886 - f1_m: 0.4799 - precision_m: 0.5033 - recall_m: 0.4737\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.9625 - accuracy: 0.4953 - f1_m: 0.5569 - precision_m: 0.5106 - recall_m: 0.6416\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.9145 - accuracy: 0.5077 - f1_m: 0.5725 - precision_m: 0.5037 - recall_m: 0.6934\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.9039 - accuracy: 0.5035 - f1_m: 0.5626 - precision_m: 0.5020 - recall_m: 0.6697\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.8864 - accuracy: 0.4923 - f1_m: 0.6058 - precision_m: 0.5140 - recall_m: 0.7616\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.8641 - accuracy: 0.4946 - f1_m: 0.6035 - precision_m: 0.5127 - recall_m: 0.7599\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.8597 - accuracy: 0.4976 - f1_m: 0.5950 - precision_m: 0.5045 - recall_m: 0.7520\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.8363 - accuracy: 0.5058 - f1_m: 0.5945 - precision_m: 0.4993 - recall_m: 0.7590\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.8383 - accuracy: 0.4938 - f1_m: 0.6177 - precision_m: 0.5093 - recall_m: 0.8109\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.8365 - accuracy: 0.4894 - f1_m: 0.6145 - precision_m: 0.5017 - recall_m: 0.8145\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.8086 - accuracy: 0.5114 - f1_m: 0.6219 - precision_m: 0.5147 - recall_m: 0.8257\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.8086 - accuracy: 0.5043 - f1_m: 0.6421 - precision_m: 0.5114 - recall_m: 0.8856\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.8093 - accuracy: 0.4961 - f1_m: 0.6354 - precision_m: 0.5130 - recall_m: 0.8582\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.8064 - accuracy: 0.4994 - f1_m: 0.6318 - precision_m: 0.5056 - recall_m: 0.8674\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.8106 - accuracy: 0.4853 - f1_m: 0.6369 - precision_m: 0.5108 - recall_m: 0.8658\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.8014 - accuracy: 0.5002 - f1_m: 0.6335 - precision_m: 0.5084 - recall_m: 0.8618\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7984 - accuracy: 0.5039 - f1_m: 0.6391 - precision_m: 0.5087 - recall_m: 0.8824\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7943 - accuracy: 0.4942 - f1_m: 0.6437 - precision_m: 0.5097 - recall_m: 0.8971\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7912 - accuracy: 0.4935 - f1_m: 0.6476 - precision_m: 0.5089 - recall_m: 0.9085\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7795 - accuracy: 0.5125 - f1_m: 0.6534 - precision_m: 0.5127 - recall_m: 0.9216\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7892 - accuracy: 0.4961 - f1_m: 0.6481 - precision_m: 0.5093 - recall_m: 0.9123\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7840 - accuracy: 0.4979 - f1_m: 0.6386 - precision_m: 0.5046 - recall_m: 0.8943\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7770 - accuracy: 0.5054 - f1_m: 0.6307 - precision_m: 0.5011 - recall_m: 0.8697\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7830 - accuracy: 0.4991 - f1_m: 0.6428 - precision_m: 0.5091 - recall_m: 0.9044\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7771 - accuracy: 0.5054 - f1_m: 0.6487 - precision_m: 0.5101 - recall_m: 0.9100\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7772 - accuracy: 0.5035 - f1_m: 0.6474 - precision_m: 0.5065 - recall_m: 0.9161\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7847 - accuracy: 0.4972 - f1_m: 0.6400 - precision_m: 0.5055 - recall_m: 0.8957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 51ms/step - loss: 0.6991 - accuracy: 0.5015 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-26\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 250ms/step - loss: 0.9161 - accuracy: 0.5043 - f1_m: 0.6020 - precision_m: 0.4802 - recall_m: 0.8369\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.7564 - accuracy: 0.4957 - f1_m: 0.6563 - precision_m: 0.5096 - recall_m: 0.9403\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7308 - accuracy: 0.5099 - f1_m: 0.6618 - precision_m: 0.5103 - recall_m: 0.9589\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7073 - accuracy: 0.5338 - f1_m: 0.6608 - precision_m: 0.5090 - recall_m: 0.9619\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.7020 - accuracy: 0.5659 - f1_m: 0.6581 - precision_m: 0.5052 - recall_m: 0.9651\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6376 - accuracy: 0.6432 - f1_m: 0.6678 - precision_m: 0.5080 - recall_m: 0.9927\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.6083 - accuracy: 0.6648 - f1_m: 0.6684 - precision_m: 0.5083 - recall_m: 0.9962\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.5966 - accuracy: 0.6667 - f1_m: 0.6668 - precision_m: 0.5072 - recall_m: 0.9935\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.5655 - accuracy: 0.7029 - f1_m: 0.6692 - precision_m: 0.5087 - recall_m: 0.9972\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5633 - accuracy: 0.6995 - f1_m: 0.6672 - precision_m: 0.5078 - recall_m: 0.9936\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5564 - accuracy: 0.6995 - f1_m: 0.6688 - precision_m: 0.5087 - recall_m: 0.9980\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5436 - accuracy: 0.7044 - f1_m: 0.6689 - precision_m: 0.5086 - recall_m: 0.9945\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5402 - accuracy: 0.7182 - f1_m: 0.6663 - precision_m: 0.5069 - recall_m: 0.9955\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5301 - accuracy: 0.7264 - f1_m: 0.6672 - precision_m: 0.5081 - recall_m: 0.9960\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5199 - accuracy: 0.7357 - f1_m: 0.6697 - precision_m: 0.5087 - recall_m: 0.9993\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5102 - accuracy: 0.7424 - f1_m: 0.6670 - precision_m: 0.5078 - recall_m: 0.9960\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5169 - accuracy: 0.7242 - f1_m: 0.6686 - precision_m: 0.5084 - recall_m: 0.9988\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.5097 - accuracy: 0.7492 - f1_m: 0.6669 - precision_m: 0.5068 - recall_m: 0.9960\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5183 - accuracy: 0.7268 - f1_m: 0.6661 - precision_m: 0.5082 - recall_m: 0.9969\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5159 - accuracy: 0.7297 - f1_m: 0.6682 - precision_m: 0.5078 - recall_m: 0.9981\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5133 - accuracy: 0.7439 - f1_m: 0.6684 - precision_m: 0.5074 - recall_m: 0.9959\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5035 - accuracy: 0.7413 - f1_m: 0.6685 - precision_m: 0.5077 - recall_m: 0.9994\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5029 - accuracy: 0.7488 - f1_m: 0.6692 - precision_m: 0.5074 - recall_m: 0.9981\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5020 - accuracy: 0.7477 - f1_m: 0.6686 - precision_m: 0.5087 - recall_m: 0.9987\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4924 - accuracy: 0.7510 - f1_m: 0.6682 - precision_m: 0.5084 - recall_m: 0.9973\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4913 - accuracy: 0.7577 - f1_m: 0.6685 - precision_m: 0.5076 - recall_m: 0.9960\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4857 - accuracy: 0.7514 - f1_m: 0.6665 - precision_m: 0.5072 - recall_m: 0.9963\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4747 - accuracy: 0.7734 - f1_m: 0.6682 - precision_m: 0.5076 - recall_m: 0.9960\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4668 - accuracy: 0.7701 - f1_m: 0.6689 - precision_m: 0.5074 - recall_m: 0.9991\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.4553 - accuracy: 0.7790 - f1_m: 0.6666 - precision_m: 0.5061 - recall_m: 0.9978\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.4009 - accuracy: 0.8239 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-27\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.8615 - accuracy: 0.4968 - f1_m: 0.6152 - precision_m: 0.4823 - recall_m: 0.8655\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7520 - accuracy: 0.5077 - f1_m: 0.6575 - precision_m: 0.5099 - recall_m: 0.9482\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7223 - accuracy: 0.5024 - f1_m: 0.6603 - precision_m: 0.5090 - recall_m: 0.9642\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7024 - accuracy: 0.5271 - f1_m: 0.6627 - precision_m: 0.5081 - recall_m: 0.9754\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6550 - accuracy: 0.6140 - f1_m: 0.6654 - precision_m: 0.5062 - recall_m: 0.9903\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6329 - accuracy: 0.6346 - f1_m: 0.6683 - precision_m: 0.5082 - recall_m: 0.9968\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6098 - accuracy: 0.6547 - f1_m: 0.6697 - precision_m: 0.5083 - recall_m: 0.9976\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5925 - accuracy: 0.6715 - f1_m: 0.6670 - precision_m: 0.5075 - recall_m: 0.9993\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5769 - accuracy: 0.6913 - f1_m: 0.6674 - precision_m: 0.5070 - recall_m: 0.9963\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.5663 - accuracy: 0.7014 - f1_m: 0.6670 - precision_m: 0.5071 - recall_m: 0.9972\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5620 - accuracy: 0.7062 - f1_m: 0.6690 - precision_m: 0.5081 - recall_m: 0.9993\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.5498 - accuracy: 0.7130 - f1_m: 0.6693 - precision_m: 0.5077 - recall_m: 0.9976\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5437 - accuracy: 0.7227 - f1_m: 0.6674 - precision_m: 0.5072 - recall_m: 0.9969\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5299 - accuracy: 0.7331 - f1_m: 0.6675 - precision_m: 0.5070 - recall_m: 0.9972\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5256 - accuracy: 0.7324 - f1_m: 0.6687 - precision_m: 0.5077 - recall_m: 0.9966\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5164 - accuracy: 0.7458 - f1_m: 0.6675 - precision_m: 0.5065 - recall_m: 0.9954\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.5114 - accuracy: 0.7447 - f1_m: 0.6679 - precision_m: 0.5081 - recall_m: 0.9975\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5057 - accuracy: 0.7536 - f1_m: 0.6690 - precision_m: 0.5079 - recall_m: 0.9993\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4935 - accuracy: 0.7604 - f1_m: 0.6679 - precision_m: 0.5065 - recall_m: 0.9966s - loss: 0.4935 - accuracy: 0.7604 - f1_m: 0.6679 - precision_m: 0.5065 - recall_m: 0.99\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.4959 - accuracy: 0.7559 - f1_m: 0.6678 - precision_m: 0.5075 - recall_m: 0.9958\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.4785 - accuracy: 0.7704 - f1_m: 0.6682 - precision_m: 0.5075 - recall_m: 0.9976\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4749 - accuracy: 0.7801 - f1_m: 0.6683 - precision_m: 0.5081 - recall_m: 0.9987\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4720 - accuracy: 0.7835 - f1_m: 0.6696 - precision_m: 0.5082 - recall_m: 0.9979\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.4553 - accuracy: 0.7958 - f1_m: 0.6686 - precision_m: 0.5086 - recall_m: 0.9971\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4571 - accuracy: 0.7850 - f1_m: 0.6695 - precision_m: 0.5080 - recall_m: 0.9972\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4514 - accuracy: 0.7940 - f1_m: 0.6682 - precision_m: 0.5064 - recall_m: 0.9957\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4418 - accuracy: 0.7969 - f1_m: 0.6665 - precision_m: 0.5075 - recall_m: 0.9954\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4323 - accuracy: 0.8059 - f1_m: 0.6669 - precision_m: 0.5070 - recall_m: 0.9980\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4365 - accuracy: 0.8052 - f1_m: 0.6699 - precision_m: 0.5085 - recall_m: 0.9972\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4267 - accuracy: 0.8081 - f1_m: 0.6674 - precision_m: 0.5074 - recall_m: 0.9975\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.3563 - accuracy: 0.8627 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-28\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 237ms/step - loss: 0.9828 - accuracy: 0.4901 - f1_m: 0.5643 - precision_m: 0.4576 - recall_m: 0.7745\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7790 - accuracy: 0.4946 - f1_m: 0.6479 - precision_m: 0.5065 - recall_m: 0.9175\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7488 - accuracy: 0.5144 - f1_m: 0.6506 - precision_m: 0.5092 - recall_m: 0.9233\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7323 - accuracy: 0.4987 - f1_m: 0.6533 - precision_m: 0.5058 - recall_m: 0.9452\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7170 - accuracy: 0.5196 - f1_m: 0.6611 - precision_m: 0.5096 - recall_m: 0.9583\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7013 - accuracy: 0.5409 - f1_m: 0.6589 - precision_m: 0.5045 - recall_m: 0.9663\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6487 - accuracy: 0.6267 - f1_m: 0.6659 - precision_m: 0.5069 - recall_m: 0.9883\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6159 - accuracy: 0.6510 - f1_m: 0.6684 - precision_m: 0.5080 - recall_m: 0.9920\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5837 - accuracy: 0.6719 - f1_m: 0.6676 - precision_m: 0.5086 - recall_m: 0.9932\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5963 - accuracy: 0.6506 - f1_m: 0.6666 - precision_m: 0.5067 - recall_m: 0.9905\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5766 - accuracy: 0.6909 - f1_m: 0.6685 - precision_m: 0.5084 - recall_m: 0.9933\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5722 - accuracy: 0.6797 - f1_m: 0.6657 - precision_m: 0.5082 - recall_m: 0.9910\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5579 - accuracy: 0.6958 - f1_m: 0.6663 - precision_m: 0.5076 - recall_m: 0.9934\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5469 - accuracy: 0.7025 - f1_m: 0.6697 - precision_m: 0.5090 - recall_m: 0.9961\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5488 - accuracy: 0.7003 - f1_m: 0.6682 - precision_m: 0.5075 - recall_m: 0.9931\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5349 - accuracy: 0.7163 - f1_m: 0.6691 - precision_m: 0.5089 - recall_m: 0.9937\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5379 - accuracy: 0.7144 - f1_m: 0.6674 - precision_m: 0.5079 - recall_m: 0.9942\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5529 - accuracy: 0.6917 - f1_m: 0.6670 - precision_m: 0.5084 - recall_m: 0.9906\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5507 - accuracy: 0.7081 - f1_m: 0.6655 - precision_m: 0.5071 - recall_m: 0.9878\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5380 - accuracy: 0.7174 - f1_m: 0.6662 - precision_m: 0.5081 - recall_m: 0.9887\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5229 - accuracy: 0.7197 - f1_m: 0.6691 - precision_m: 0.5092 - recall_m: 0.9941\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.5308 - accuracy: 0.7297 - f1_m: 0.6678 - precision_m: 0.5082 - recall_m: 0.9922\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5371 - accuracy: 0.7171 - f1_m: 0.6666 - precision_m: 0.5079 - recall_m: 0.9904\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5365 - accuracy: 0.7163 - f1_m: 0.6680 - precision_m: 0.5084 - recall_m: 0.9918\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5276 - accuracy: 0.7200 - f1_m: 0.6677 - precision_m: 0.5078 - recall_m: 0.9928\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5002 - accuracy: 0.7409 - f1_m: 0.6676 - precision_m: 0.5078 - recall_m: 0.9934\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.5150 - accuracy: 0.7297 - f1_m: 0.6691 - precision_m: 0.5081 - recall_m: 0.9965\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5151 - accuracy: 0.7383 - f1_m: 0.6661 - precision_m: 0.5081 - recall_m: 0.9927\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.5067 - accuracy: 0.7305 - f1_m: 0.6668 - precision_m: 0.5078 - recall_m: 0.9952\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.5059 - accuracy: 0.7391 - f1_m: 0.6650 - precision_m: 0.5065 - recall_m: 0.9917\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.4587 - accuracy: 0.7791 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-29\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 241ms/step - loss: 1.1829 - accuracy: 0.5077 - f1_m: 0.4298 - precision_m: 0.3621 - recall_m: 0.5724\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7492 - accuracy: 0.5047 - f1_m: 0.6566 - precision_m: 0.5098 - recall_m: 0.9365\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7221 - accuracy: 0.5084 - f1_m: 0.6544 - precision_m: 0.5086 - recall_m: 0.9377\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7192 - accuracy: 0.4961 - f1_m: 0.6600 - precision_m: 0.5081 - recall_m: 0.9585\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7116 - accuracy: 0.5039 - f1_m: 0.6620 - precision_m: 0.5092 - recall_m: 0.9659\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7128 - accuracy: 0.4823 - f1_m: 0.6584 - precision_m: 0.5067 - recall_m: 0.9596\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7065 - accuracy: 0.4886 - f1_m: 0.6626 - precision_m: 0.5075 - recall_m: 0.9690\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7073 - accuracy: 0.5006 - f1_m: 0.6626 - precision_m: 0.5082 - recall_m: 0.9697\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7073 - accuracy: 0.4950 - f1_m: 0.6630 - precision_m: 0.5078 - recall_m: 0.9712\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7021 - accuracy: 0.5009 - f1_m: 0.6654 - precision_m: 0.5085 - recall_m: 0.9772\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7072 - accuracy: 0.4793 - f1_m: 0.6615 - precision_m: 0.5078 - recall_m: 0.9727\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7067 - accuracy: 0.5002 - f1_m: 0.6602 - precision_m: 0.5074 - recall_m: 0.9722\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.6990 - accuracy: 0.5065 - f1_m: 0.6641 - precision_m: 0.5076 - recall_m: 0.9741\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7049 - accuracy: 0.4897 - f1_m: 0.6614 - precision_m: 0.5064 - recall_m: 0.9760\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7007 - accuracy: 0.4987 - f1_m: 0.6641 - precision_m: 0.5080 - recall_m: 0.9744\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7059 - accuracy: 0.4797 - f1_m: 0.6636 - precision_m: 0.5083 - recall_m: 0.9815\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7015 - accuracy: 0.4946 - f1_m: 0.6631 - precision_m: 0.5075 - recall_m: 0.9751\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6997 - accuracy: 0.5009 - f1_m: 0.6662 - precision_m: 0.5083 - recall_m: 0.9819\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7037 - accuracy: 0.5065 - f1_m: 0.6656 - precision_m: 0.5085 - recall_m: 0.9803\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7005 - accuracy: 0.5028 - f1_m: 0.6636 - precision_m: 0.5064 - recall_m: 0.9778\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7005 - accuracy: 0.5032 - f1_m: 0.6636 - precision_m: 0.5078 - recall_m: 0.9747\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7003 - accuracy: 0.5009 - f1_m: 0.6692 - precision_m: 0.5106 - recall_m: 0.9885\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7030 - accuracy: 0.4927 - f1_m: 0.6645 - precision_m: 0.5087 - recall_m: 0.9786\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7012 - accuracy: 0.4927 - f1_m: 0.6645 - precision_m: 0.5081 - recall_m: 0.9802\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6997 - accuracy: 0.4957 - f1_m: 0.6634 - precision_m: 0.5077 - recall_m: 0.9776\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7021 - accuracy: 0.5021 - f1_m: 0.6645 - precision_m: 0.5087 - recall_m: 0.9805\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7012 - accuracy: 0.5058 - f1_m: 0.6622 - precision_m: 0.5061 - recall_m: 0.9769\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7044 - accuracy: 0.4815 - f1_m: 0.6641 - precision_m: 0.5077 - recall_m: 0.9843\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7013 - accuracy: 0.4886 - f1_m: 0.6649 - precision_m: 0.5088 - recall_m: 0.9777\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7002 - accuracy: 0.4987 - f1_m: 0.6665 - precision_m: 0.5095 - recall_m: 0.9808\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.6950 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-30\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 242ms/step - loss: 2.1393 - accuracy: 0.5095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 1.1269 - accuracy: 0.5099 - f1_m: 0.2052 - precision_m: 0.2546 - recall_m: 0.1960\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7622 - accuracy: 0.4912 - f1_m: 0.6161 - precision_m: 0.5116 - recall_m: 0.8007\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7338 - accuracy: 0.5002 - f1_m: 0.6480 - precision_m: 0.5077 - recall_m: 0.9174\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.7279 - accuracy: 0.4983 - f1_m: 0.6594 - precision_m: 0.5085 - recall_m: 0.9585\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7298 - accuracy: 0.4994 - f1_m: 0.6545 - precision_m: 0.5047 - recall_m: 0.9525\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7246 - accuracy: 0.5039 - f1_m: 0.6640 - precision_m: 0.5097 - recall_m: 0.9667\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7274 - accuracy: 0.4942 - f1_m: 0.6609 - precision_m: 0.5066 - recall_m: 0.9662\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7273 - accuracy: 0.4916 - f1_m: 0.6619 - precision_m: 0.5066 - recall_m: 0.9688\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7286 - accuracy: 0.4834 - f1_m: 0.6578 - precision_m: 0.5057 - recall_m: 0.9632\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7219 - accuracy: 0.4972 - f1_m: 0.6567 - precision_m: 0.5054 - recall_m: 0.9621\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7221 - accuracy: 0.5009 - f1_m: 0.6576 - precision_m: 0.5061 - recall_m: 0.9588\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7141 - accuracy: 0.5013 - f1_m: 0.6552 - precision_m: 0.5029 - recall_m: 0.9605\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7161 - accuracy: 0.5151 - f1_m: 0.6651 - precision_m: 0.5097 - recall_m: 0.9732\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7173 - accuracy: 0.4994 - f1_m: 0.6643 - precision_m: 0.5090 - recall_m: 0.9788\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7182 - accuracy: 0.5125 - f1_m: 0.6659 - precision_m: 0.5091 - recall_m: 0.9823\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.7140 - accuracy: 0.4994 - f1_m: 0.6626 - precision_m: 0.5092 - recall_m: 0.9714\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7137 - accuracy: 0.5002 - f1_m: 0.6664 - precision_m: 0.5094 - recall_m: 0.9791\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.7152 - accuracy: 0.5002 - f1_m: 0.6633 - precision_m: 0.5088 - recall_m: 0.9765\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.7113 - accuracy: 0.5050 - f1_m: 0.6680 - precision_m: 0.5107 - recall_m: 0.9800\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7205 - accuracy: 0.4916 - f1_m: 0.6649 - precision_m: 0.5088 - recall_m: 0.9821\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7155 - accuracy: 0.4931 - f1_m: 0.6649 - precision_m: 0.5093 - recall_m: 0.9783\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7070 - accuracy: 0.5218 - f1_m: 0.6650 - precision_m: 0.5079 - recall_m: 0.9813\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7037 - accuracy: 0.5166 - f1_m: 0.6628 - precision_m: 0.5078 - recall_m: 0.9783\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7175 - accuracy: 0.4998 - f1_m: 0.6624 - precision_m: 0.5066 - recall_m: 0.9775\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7089 - accuracy: 0.5129 - f1_m: 0.6636 - precision_m: 0.5072 - recall_m: 0.9783\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7093 - accuracy: 0.5147 - f1_m: 0.6648 - precision_m: 0.5082 - recall_m: 0.9828\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7113 - accuracy: 0.4935 - f1_m: 0.6641 - precision_m: 0.5059 - recall_m: 0.9781\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7129 - accuracy: 0.4938 - f1_m: 0.6630 - precision_m: 0.5069 - recall_m: 0.9761\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7132 - accuracy: 0.4935 - f1_m: 0.6609 - precision_m: 0.5056 - recall_m: 0.9772\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.6982 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-31\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 23s 261ms/step - loss: 0.8183 - accuracy: 0.4894 - f1_m: 0.6153 - precision_m: 0.4755 - recall_m: 0.8974\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.7080 - accuracy: 0.4998 - f1_m: 0.6640 - precision_m: 0.5053 - recall_m: 0.9845\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 22s 262ms/step - loss: 0.7049 - accuracy: 0.4946 - f1_m: 0.6653 - precision_m: 0.5072 - recall_m: 0.9849\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.6732 - accuracy: 0.5767 - f1_m: 0.6690 - precision_m: 0.5092 - recall_m: 0.9934\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.6254 - accuracy: 0.6432 - f1_m: 0.6684 - precision_m: 0.5080 - recall_m: 0.9980\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.5839 - accuracy: 0.6805 - f1_m: 0.6678 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 22s 259ms/step - loss: 0.5583 - accuracy: 0.6980 - f1_m: 0.6692 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 22s 259ms/step - loss: 0.5429 - accuracy: 0.7130 - f1_m: 0.6701 - precision_m: 0.5078 - recall_m: 0.9991\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.5330 - accuracy: 0.7286 - f1_m: 0.6700 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 22s 259ms/step - loss: 0.5299 - accuracy: 0.7316 - f1_m: 0.6691 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.5004 - accuracy: 0.7499 - f1_m: 0.6690 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.4881 - accuracy: 0.7604 - f1_m: 0.6684 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.4609 - accuracy: 0.7768 - f1_m: 0.6694 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.4470 - accuracy: 0.7846 - f1_m: 0.6694 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 22s 260ms/step - loss: 0.4449 - accuracy: 0.7906 - f1_m: 0.6685 - precision_m: 0.5084 - recall_m: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.4288 - accuracy: 0.7981 - f1_m: 0.6682 - precision_m: 0.5078 - recall_m: 0.9993\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 22s 259ms/step - loss: 0.4076 - accuracy: 0.8126 - f1_m: 0.6690 - precision_m: 0.5082 - recall_m: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 22s 256ms/step - loss: 0.4088 - accuracy: 0.8175 - f1_m: 0.6695 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.4034 - accuracy: 0.8167 - f1_m: 0.6693 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.3956 - accuracy: 0.8253 - f1_m: 0.6683 - precision_m: 0.5075 - recall_m: 0.9992\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 256ms/step - loss: 0.3794 - accuracy: 0.8283 - f1_m: 0.6684 - precision_m: 0.5078 - recall_m: 0.9985\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.3714 - accuracy: 0.8387 - f1_m: 0.6687 - precision_m: 0.5071 - recall_m: 0.9993\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.3762 - accuracy: 0.8384 - f1_m: 0.6686 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.3741 - accuracy: 0.8373 - f1_m: 0.6686 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.3552 - accuracy: 0.8511 - f1_m: 0.6676 - precision_m: 0.5080 - recall_m: 0.9993\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.3486 - accuracy: 0.8503 - f1_m: 0.6686 - precision_m: 0.5071 - recall_m: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.3450 - accuracy: 0.8473 - f1_m: 0.6706 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.3244 - accuracy: 0.8596 - f1_m: 0.6678 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.3334 - accuracy: 0.8611 - f1_m: 0.6691 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.3279 - accuracy: 0.8585 - f1_m: 0.6689 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.3216 - accuracy: 0.8836 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-32\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 253ms/step - loss: 0.7861 - accuracy: 0.4860 - f1_m: 0.6357 - precision_m: 0.4892 - recall_m: 0.9272\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.7072 - accuracy: 0.5159 - f1_m: 0.6690 - precision_m: 0.5113 - recall_m: 0.9834\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.6536 - accuracy: 0.6152 - f1_m: 0.6675 - precision_m: 0.5068 - recall_m: 0.9957\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6258 - accuracy: 0.6469 - f1_m: 0.6688 - precision_m: 0.5082 - recall_m: 1.0000\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6033 - accuracy: 0.6506 - f1_m: 0.6706 - precision_m: 0.5086 - recall_m: 1.0000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.5886 - accuracy: 0.6790 - f1_m: 0.6681 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5615 - accuracy: 0.7066 - f1_m: 0.6694 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5508 - accuracy: 0.7212 - f1_m: 0.6672 - precision_m: 0.5082 - recall_m: 1.0000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.5423 - accuracy: 0.7197 - f1_m: 0.6683 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5359 - accuracy: 0.7324 - f1_m: 0.6675 - precision_m: 0.5071 - recall_m: 0.9994\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5219 - accuracy: 0.7409 - f1_m: 0.6699 - precision_m: 0.5080 - recall_m: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.5076 - accuracy: 0.7473 - f1_m: 0.6690 - precision_m: 0.5079 - recall_m: 0.9991\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.5097 - accuracy: 0.7514 - f1_m: 0.6693 - precision_m: 0.5079 - recall_m: 0.9993\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.5002 - accuracy: 0.7555 - f1_m: 0.6693 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.4782 - accuracy: 0.7663 - f1_m: 0.6692 - precision_m: 0.5077 - recall_m: 0.9994\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 21s 254ms/step - loss: 0.4714 - accuracy: 0.7719 - f1_m: 0.6694 - precision_m: 0.5085 - recall_m: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4537 - accuracy: 0.7891 - f1_m: 0.6684 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.4563 - accuracy: 0.7936 - f1_m: 0.6696 - precision_m: 0.5089 - recall_m: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.4482 - accuracy: 0.7869 - f1_m: 0.6699 - precision_m: 0.5078 - recall_m: 0.9994\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.4286 - accuracy: 0.7966 - f1_m: 0.6682 - precision_m: 0.5075 - recall_m: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.4179 - accuracy: 0.8126 - f1_m: 0.6691 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.4142 - accuracy: 0.8208 - f1_m: 0.6688 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4074 - accuracy: 0.8193 - f1_m: 0.6662 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.3845 - accuracy: 0.8343 - f1_m: 0.6693 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.3944 - accuracy: 0.8253 - f1_m: 0.6700 - precision_m: 0.5080 - recall_m: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.3823 - accuracy: 0.8328 - f1_m: 0.6697 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.3659 - accuracy: 0.8466 - f1_m: 0.6691 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.3833 - accuracy: 0.8350 - f1_m: 0.6685 - precision_m: 0.5080 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.3730 - accuracy: 0.8358 - f1_m: 0.6686 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.3700 - accuracy: 0.8447 - f1_m: 0.6690 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.3173 - accuracy: 0.9015 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-33\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 22s 253ms/step - loss: 0.8279 - accuracy: 0.4867 - f1_m: 0.6145 - precision_m: 0.4712 - recall_m: 0.9075\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.7053 - accuracy: 0.5050 - f1_m: 0.6677 - precision_m: 0.5074 - recall_m: 0.9865\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.7025 - accuracy: 0.5050 - f1_m: 0.6659 - precision_m: 0.5064 - recall_m: 0.9908\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.7020 - accuracy: 0.5043 - f1_m: 0.6647 - precision_m: 0.5077 - recall_m: 0.9840\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 0.6769 - accuracy: 0.5685 - f1_m: 0.6662 - precision_m: 0.5071 - recall_m: 0.9959\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.6376 - accuracy: 0.6189 - f1_m: 0.6693 - precision_m: 0.5080 - recall_m: 0.9984\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.6000 - accuracy: 0.6663 - f1_m: 0.6685 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.5630 - accuracy: 0.6965 - f1_m: 0.6697 - precision_m: 0.5079 - recall_m: 1.0000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.5619 - accuracy: 0.6950 - f1_m: 0.6699 - precision_m: 0.5087 - recall_m: 1.0000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5671 - accuracy: 0.6801 - f1_m: 0.6688 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5311 - accuracy: 0.7253 - f1_m: 0.6688 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5125 - accuracy: 0.7301 - f1_m: 0.6691 - precision_m: 0.5073 - recall_m: 0.9984\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.5181 - accuracy: 0.7387 - f1_m: 0.6689 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.5161 - accuracy: 0.7454 - f1_m: 0.6663 - precision_m: 0.5071 - recall_m: 0.9967\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 22s 264ms/step - loss: 0.5010 - accuracy: 0.7570 - f1_m: 0.6682 - precision_m: 0.5076 - recall_m: 0.9993\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.4998 - accuracy: 0.7592 - f1_m: 0.6685 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.4874 - accuracy: 0.7611 - f1_m: 0.6679 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.4960 - accuracy: 0.7555 - f1_m: 0.6677 - precision_m: 0.5074 - recall_m: 0.9993\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.4877 - accuracy: 0.7727 - f1_m: 0.6703 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.4871 - accuracy: 0.7630 - f1_m: 0.6681 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.4860 - accuracy: 0.7611 - f1_m: 0.6690 - precision_m: 0.5087 - recall_m: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.4864 - accuracy: 0.7656 - f1_m: 0.6699 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.4620 - accuracy: 0.7775 - f1_m: 0.6693 - precision_m: 0.5073 - recall_m: 0.9993\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.4656 - accuracy: 0.7831 - f1_m: 0.6678 - precision_m: 0.5071 - recall_m: 0.9987\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.4569 - accuracy: 0.7850 - f1_m: 0.6691 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 250ms/step - loss: 0.4492 - accuracy: 0.7861 - f1_m: 0.6681 - precision_m: 0.5071 - recall_m: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.4499 - accuracy: 0.7921 - f1_m: 0.6691 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.4381 - accuracy: 0.7992 - f1_m: 0.6685 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 0.4365 - accuracy: 0.8003 - f1_m: 0.6677 - precision_m: 0.5074 - recall_m: 0.9993\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 0.4274 - accuracy: 0.8003 - f1_m: 0.6683 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.3742 - accuracy: 0.8597 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-34\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 243ms/step - loss: 1.0634 - accuracy: 0.5050 - f1_m: 0.4564 - precision_m: 0.3654 - recall_m: 0.6463\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7197 - accuracy: 0.5017 - f1_m: 0.6648 - precision_m: 0.5092 - recall_m: 0.9777\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7160 - accuracy: 0.4987 - f1_m: 0.6609 - precision_m: 0.5061 - recall_m: 0.9754\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7116 - accuracy: 0.4923 - f1_m: 0.6618 - precision_m: 0.5058 - recall_m: 0.9791\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7072 - accuracy: 0.5091 - f1_m: 0.6605 - precision_m: 0.5055 - recall_m: 0.9739\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7030 - accuracy: 0.4923 - f1_m: 0.6619 - precision_m: 0.5065 - recall_m: 0.9706\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7035 - accuracy: 0.4935 - f1_m: 0.6655 - precision_m: 0.5083 - recall_m: 0.9793\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7047 - accuracy: 0.5039 - f1_m: 0.6625 - precision_m: 0.5062 - recall_m: 0.9840\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7012 - accuracy: 0.5062 - f1_m: 0.6642 - precision_m: 0.5068 - recall_m: 0.9807\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7017 - accuracy: 0.4991 - f1_m: 0.6677 - precision_m: 0.5085 - recall_m: 0.9879\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7012 - accuracy: 0.4942 - f1_m: 0.6680 - precision_m: 0.5090 - recall_m: 0.9895\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.6997 - accuracy: 0.5088 - f1_m: 0.6675 - precision_m: 0.5078 - recall_m: 0.9924\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7012 - accuracy: 0.4938 - f1_m: 0.6683 - precision_m: 0.5098 - recall_m: 0.9872\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.7009 - accuracy: 0.4957 - f1_m: 0.6684 - precision_m: 0.5092 - recall_m: 0.9890\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7012 - accuracy: 0.4994 - f1_m: 0.6644 - precision_m: 0.5070 - recall_m: 0.9842\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7004 - accuracy: 0.4976 - f1_m: 0.6681 - precision_m: 0.5098 - recall_m: 0.9915\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.6993 - accuracy: 0.4890 - f1_m: 0.6632 - precision_m: 0.5066 - recall_m: 0.9785\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7007 - accuracy: 0.4841 - f1_m: 0.6658 - precision_m: 0.5076 - recall_m: 0.9879\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.6968 - accuracy: 0.5121 - f1_m: 0.6681 - precision_m: 0.5088 - recall_m: 0.9919\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.6999 - accuracy: 0.5177 - f1_m: 0.6670 - precision_m: 0.5083 - recall_m: 0.9933\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6989 - accuracy: 0.5095 - f1_m: 0.6646 - precision_m: 0.5063 - recall_m: 0.9832\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7004 - accuracy: 0.4849 - f1_m: 0.6647 - precision_m: 0.5069 - recall_m: 0.9837\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6986 - accuracy: 0.5065 - f1_m: 0.6645 - precision_m: 0.5065 - recall_m: 0.9879\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7016 - accuracy: 0.4826 - f1_m: 0.6652 - precision_m: 0.5078 - recall_m: 0.9846\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.6999 - accuracy: 0.4965 - f1_m: 0.6651 - precision_m: 0.5064 - recall_m: 0.9904\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6994 - accuracy: 0.5144 - f1_m: 0.6654 - precision_m: 0.5081 - recall_m: 0.9870\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.6973 - accuracy: 0.5073 - f1_m: 0.6674 - precision_m: 0.5081 - recall_m: 0.9869\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.6975 - accuracy: 0.5006 - f1_m: 0.6649 - precision_m: 0.5058 - recall_m: 0.9886\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.6992 - accuracy: 0.5035 - f1_m: 0.6677 - precision_m: 0.5088 - recall_m: 0.9895\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.6988 - accuracy: 0.5065 - f1_m: 0.6666 - precision_m: 0.5077 - recall_m: 0.9904\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5000 - f1_m: 0.6626 - precision_m: 0.5000 - recall_m: 1.00 - 1s 47ms/step - loss: 0.6939 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-35\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'Adagrad'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 241ms/step - loss: 2.2066 - accuracy: 0.4875 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 1.5791 - accuracy: 0.4923 - f1_m: 0.1138 - precision_m: 0.1753 - recall_m: 0.0975\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.9354 - accuracy: 0.4823 - f1_m: 0.5084 - precision_m: 0.5172 - recall_m: 0.5367\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.8093 - accuracy: 0.5114 - f1_m: 0.6288 - precision_m: 0.5102 - recall_m: 0.8415\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7931 - accuracy: 0.5002 - f1_m: 0.6480 - precision_m: 0.5118 - recall_m: 0.9018\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7746 - accuracy: 0.5106 - f1_m: 0.6522 - precision_m: 0.5112 - recall_m: 0.9186\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7665 - accuracy: 0.5069 - f1_m: 0.6495 - precision_m: 0.5064 - recall_m: 0.9243\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7696 - accuracy: 0.4972 - f1_m: 0.6529 - precision_m: 0.5101 - recall_m: 0.9274\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7667 - accuracy: 0.4927 - f1_m: 0.6500 - precision_m: 0.5070 - recall_m: 0.9239\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7567 - accuracy: 0.5106 - f1_m: 0.6501 - precision_m: 0.5062 - recall_m: 0.9275\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7603 - accuracy: 0.4800 - f1_m: 0.6487 - precision_m: 0.5059 - recall_m: 0.9256\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7528 - accuracy: 0.4931 - f1_m: 0.6492 - precision_m: 0.5064 - recall_m: 0.9258\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7435 - accuracy: 0.4968 - f1_m: 0.6560 - precision_m: 0.5099 - recall_m: 0.9402\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7439 - accuracy: 0.5028 - f1_m: 0.6565 - precision_m: 0.5110 - recall_m: 0.9410\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7346 - accuracy: 0.5181 - f1_m: 0.6498 - precision_m: 0.5036 - recall_m: 0.9332\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7340 - accuracy: 0.5159 - f1_m: 0.6585 - precision_m: 0.5097 - recall_m: 0.9460\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7374 - accuracy: 0.4905 - f1_m: 0.6596 - precision_m: 0.5079 - recall_m: 0.9563\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7329 - accuracy: 0.4968 - f1_m: 0.6580 - precision_m: 0.5083 - recall_m: 0.9509\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7299 - accuracy: 0.5043 - f1_m: 0.6533 - precision_m: 0.5054 - recall_m: 0.9500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7307 - accuracy: 0.5058 - f1_m: 0.6580 - precision_m: 0.5094 - recall_m: 0.9510\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7281 - accuracy: 0.5028 - f1_m: 0.6544 - precision_m: 0.5060 - recall_m: 0.9437\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7337 - accuracy: 0.4994 - f1_m: 0.6593 - precision_m: 0.5101 - recall_m: 0.9559\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7274 - accuracy: 0.4991 - f1_m: 0.6561 - precision_m: 0.5064 - recall_m: 0.9529\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 241ms/step - loss: 0.7300 - accuracy: 0.4927 - f1_m: 0.6496 - precision_m: 0.5025 - recall_m: 0.9359\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7234 - accuracy: 0.5080 - f1_m: 0.6565 - precision_m: 0.5062 - recall_m: 0.9535\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7191 - accuracy: 0.5218 - f1_m: 0.6551 - precision_m: 0.5059 - recall_m: 0.9499\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7235 - accuracy: 0.5006 - f1_m: 0.6607 - precision_m: 0.5097 - recall_m: 0.9588\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7231 - accuracy: 0.5054 - f1_m: 0.6558 - precision_m: 0.5053 - recall_m: 0.9517\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7234 - accuracy: 0.5028 - f1_m: 0.6576 - precision_m: 0.5067 - recall_m: 0.9619\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7205 - accuracy: 0.5054 - f1_m: 0.6584 - precision_m: 0.5077 - recall_m: 0.9599\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.6945 - accuracy: 0.5015 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-36\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'Nadam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 23s 260ms/step - loss: 0.8307 - accuracy: 0.5088 - f1_m: 0.6074 - precision_m: 0.4691 - recall_m: 0.8831\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 22s 256ms/step - loss: 0.7166 - accuracy: 0.4897 - f1_m: 0.6601 - precision_m: 0.5062 - recall_m: 0.9705\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 256ms/step - loss: 0.7037 - accuracy: 0.5136 - f1_m: 0.6631 - precision_m: 0.5063 - recall_m: 0.9835\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.6873 - accuracy: 0.5487 - f1_m: 0.6633 - precision_m: 0.5068 - recall_m: 0.9798\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.6421 - accuracy: 0.6208 - f1_m: 0.6682 - precision_m: 0.5078 - recall_m: 0.9987\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.6146 - accuracy: 0.6487 - f1_m: 0.6676 - precision_m: 0.5075 - recall_m: 0.9975\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.5990 - accuracy: 0.6659 - f1_m: 0.6691 - precision_m: 0.5085 - recall_m: 0.9993\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.5779 - accuracy: 0.6902 - f1_m: 0.6689 - precision_m: 0.5085 - recall_m: 0.9994\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.5507 - accuracy: 0.7182 - f1_m: 0.6676 - precision_m: 0.5082 - recall_m: 0.9991\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.5272 - accuracy: 0.7234 - f1_m: 0.6685 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.5136 - accuracy: 0.7443 - f1_m: 0.6674 - precision_m: 0.5074 - recall_m: 0.9992\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 21s 256ms/step - loss: 0.5201 - accuracy: 0.7283 - f1_m: 0.6690 - precision_m: 0.5079 - recall_m: 0.9978\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 22s 256ms/step - loss: 0.5049 - accuracy: 0.7387 - f1_m: 0.6678 - precision_m: 0.5071 - recall_m: 0.9976\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4992 - accuracy: 0.7458 - f1_m: 0.6690 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.5051 - accuracy: 0.7585 - f1_m: 0.6686 - precision_m: 0.5068 - recall_m: 0.9977\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.4986 - accuracy: 0.7559 - f1_m: 0.6672 - precision_m: 0.5077 - recall_m: 0.9985\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4797 - accuracy: 0.7663 - f1_m: 0.6692 - precision_m: 0.5073 - recall_m: 0.9980\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4750 - accuracy: 0.7686 - f1_m: 0.6681 - precision_m: 0.5070 - recall_m: 0.9984\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 21s 256ms/step - loss: 0.4812 - accuracy: 0.7604 - f1_m: 0.6700 - precision_m: 0.5084 - recall_m: 0.9990\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.4746 - accuracy: 0.7809 - f1_m: 0.6680 - precision_m: 0.5075 - recall_m: 0.9994\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.4634 - accuracy: 0.7772 - f1_m: 0.6676 - precision_m: 0.5077 - recall_m: 0.9980\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.4421 - accuracy: 0.7966 - f1_m: 0.6688 - precision_m: 0.5072 - recall_m: 0.9989\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.4422 - accuracy: 0.7932 - f1_m: 0.6680 - precision_m: 0.5081 - recall_m: 0.9985\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.4100 - accuracy: 0.8141 - f1_m: 0.6690 - precision_m: 0.5076 - recall_m: 0.9992\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.4040 - accuracy: 0.8141 - f1_m: 0.6680 - precision_m: 0.5066 - recall_m: 0.9963\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.4110 - accuracy: 0.8160 - f1_m: 0.6666 - precision_m: 0.5073 - recall_m: 0.9979\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.3945 - accuracy: 0.8234 - f1_m: 0.6697 - precision_m: 0.5076 - recall_m: 0.9991\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 21s 254ms/step - loss: 0.3823 - accuracy: 0.8339 - f1_m: 0.6671 - precision_m: 0.5069 - recall_m: 0.9991\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 21s 253ms/step - loss: 0.3852 - accuracy: 0.8305 - f1_m: 0.6702 - precision_m: 0.5084 - recall_m: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 0.3632 - accuracy: 0.8350 - f1_m: 0.6683 - precision_m: 0.5069 - recall_m: 0.9991\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.3451 - accuracy: 0.8418 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-37\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'RMSprop'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 239ms/step - loss: 0.8319 - accuracy: 0.5189 - f1_m: 0.6252 - precision_m: 0.4943 - recall_m: 0.8955\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.7218 - accuracy: 0.5125 - f1_m: 0.6619 - precision_m: 0.5083 - recall_m: 0.9672\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.6951 - accuracy: 0.5468 - f1_m: 0.6623 - precision_m: 0.5064 - recall_m: 0.9785\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.6375 - accuracy: 0.6320 - f1_m: 0.6683 - precision_m: 0.5074 - recall_m: 0.9973\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.6097 - accuracy: 0.6495 - f1_m: 0.6701 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.5911 - accuracy: 0.6879 - f1_m: 0.6687 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.5766 - accuracy: 0.6913 - f1_m: 0.6686 - precision_m: 0.5078 - recall_m: 0.9985\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.5618 - accuracy: 0.7003 - f1_m: 0.6690 - precision_m: 0.5085 - recall_m: 1.0000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.5552 - accuracy: 0.7074 - f1_m: 0.6686 - precision_m: 0.5080 - recall_m: 0.9988\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.5512 - accuracy: 0.7144 - f1_m: 0.6677 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.5309 - accuracy: 0.7402 - f1_m: 0.6677 - precision_m: 0.5074 - recall_m: 0.9987\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.5240 - accuracy: 0.7398 - f1_m: 0.6695 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 235ms/step - loss: 0.5020 - accuracy: 0.7521 - f1_m: 0.6688 - precision_m: 0.5076 - recall_m: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.4993 - accuracy: 0.7577 - f1_m: 0.6680 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.4813 - accuracy: 0.7637 - f1_m: 0.6686 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.4687 - accuracy: 0.7798 - f1_m: 0.6679 - precision_m: 0.5075 - recall_m: 0.9991\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.4486 - accuracy: 0.7876 - f1_m: 0.6685 - precision_m: 0.5071 - recall_m: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.4452 - accuracy: 0.7925 - f1_m: 0.6694 - precision_m: 0.5069 - recall_m: 0.9991\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.4271 - accuracy: 0.8055 - f1_m: 0.6696 - precision_m: 0.5075 - recall_m: 0.9993\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.4205 - accuracy: 0.8156 - f1_m: 0.6694 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.4083 - accuracy: 0.8152 - f1_m: 0.6685 - precision_m: 0.5075 - recall_m: 0.9992\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.4189 - accuracy: 0.8197 - f1_m: 0.6686 - precision_m: 0.5071 - recall_m: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.4029 - accuracy: 0.8275 - f1_m: 0.6697 - precision_m: 0.5081 - recall_m: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.4013 - accuracy: 0.8137 - f1_m: 0.6681 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.3844 - accuracy: 0.8346 - f1_m: 0.6675 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.3913 - accuracy: 0.8313 - f1_m: 0.6697 - precision_m: 0.5070 - recall_m: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.3812 - accuracy: 0.8320 - f1_m: 0.6698 - precision_m: 0.5078 - recall_m: 0.9994\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.3922 - accuracy: 0.8309 - f1_m: 0.6685 - precision_m: 0.5073 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.3949 - accuracy: 0.8380 - f1_m: 0.6691 - precision_m: 0.5083 - recall_m: 0.9993\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.3706 - accuracy: 0.8414 - f1_m: 0.6682 - precision_m: 0.5077 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.3239 - accuracy: 0.8925 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-38\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.8446 - accuracy: 0.4830 - f1_m: 0.6091 - precision_m: 0.4736 - recall_m: 0.8876\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.7097 - accuracy: 0.5013 - f1_m: 0.6636 - precision_m: 0.5074 - recall_m: 0.9791\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.7049 - accuracy: 0.4950 - f1_m: 0.6638 - precision_m: 0.5070 - recall_m: 0.9798\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7050 - accuracy: 0.4834 - f1_m: 0.6644 - precision_m: 0.5076 - recall_m: 0.9839\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.6973 - accuracy: 0.5155 - f1_m: 0.6674 - precision_m: 0.5085 - recall_m: 0.9910\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.6967 - accuracy: 0.5043 - f1_m: 0.6650 - precision_m: 0.5063 - recall_m: 0.9901\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.6948 - accuracy: 0.5091 - f1_m: 0.6670 - precision_m: 0.5077 - recall_m: 0.9933\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.6848 - accuracy: 0.5461 - f1_m: 0.6689 - precision_m: 0.5084 - recall_m: 0.9964\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.6414 - accuracy: 0.6301 - f1_m: 0.6683 - precision_m: 0.5071 - recall_m: 0.9980\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.6069 - accuracy: 0.6588 - f1_m: 0.6679 - precision_m: 0.5074 - recall_m: 0.9986\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.5679 - accuracy: 0.7029 - f1_m: 0.6693 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5426 - accuracy: 0.7137 - f1_m: 0.6673 - precision_m: 0.5071 - recall_m: 0.9994\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.5411 - accuracy: 0.7171 - f1_m: 0.6684 - precision_m: 0.5070 - recall_m: 0.9979\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.5358 - accuracy: 0.7230 - f1_m: 0.6683 - precision_m: 0.5073 - recall_m: 0.9993\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.5289 - accuracy: 0.7238 - f1_m: 0.6699 - precision_m: 0.5078 - recall_m: 0.9983\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.5114 - accuracy: 0.7391 - f1_m: 0.6699 - precision_m: 0.5072 - recall_m: 0.9993\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.5192 - accuracy: 0.7320 - f1_m: 0.6681 - precision_m: 0.5079 - recall_m: 0.9993\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.5072 - accuracy: 0.7484 - f1_m: 0.6677 - precision_m: 0.5075 - recall_m: 0.9980\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4978 - accuracy: 0.7451 - f1_m: 0.6681 - precision_m: 0.5074 - recall_m: 0.9980\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 0.4912 - accuracy: 0.7551 - f1_m: 0.6686 - precision_m: 0.5085 - recall_m: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4899 - accuracy: 0.7577 - f1_m: 0.6680 - precision_m: 0.5078 - recall_m: 0.9994\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4753 - accuracy: 0.7753 - f1_m: 0.6680 - precision_m: 0.5073 - recall_m: 0.9982\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4705 - accuracy: 0.7697 - f1_m: 0.6697 - precision_m: 0.5078 - recall_m: 0.9993\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4518 - accuracy: 0.7842 - f1_m: 0.6671 - precision_m: 0.5069 - recall_m: 0.9994\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4470 - accuracy: 0.7932 - f1_m: 0.6672 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4329 - accuracy: 0.7958 - f1_m: 0.6686 - precision_m: 0.5077 - recall_m: 0.9995\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.4316 - accuracy: 0.7928 - f1_m: 0.6681 - precision_m: 0.5078 - recall_m: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.4203 - accuracy: 0.8033 - f1_m: 0.6695 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.4304 - accuracy: 0.8025 - f1_m: 0.6697 - precision_m: 0.5082 - recall_m: 0.9992\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 244ms/step - loss: 0.4155 - accuracy: 0.8156 - f1_m: 0.6687 - precision_m: 0.5074 - recall_m: 1.0000\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.3784 - accuracy: 0.8179 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n",
      "--- Starting trial: run-39\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 21s 239ms/step - loss: 1.1079 - accuracy: 0.4983 - f1_m: 0.4517 - precision_m: 0.3755 - recall_m: 0.6322\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 20s 237ms/step - loss: 0.7319 - accuracy: 0.4942 - f1_m: 0.6537 - precision_m: 0.5054 - recall_m: 0.9453\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7171 - accuracy: 0.5062 - f1_m: 0.6573 - precision_m: 0.5066 - recall_m: 0.9625\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7161 - accuracy: 0.4860 - f1_m: 0.6591 - precision_m: 0.5078 - recall_m: 0.9630\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7039 - accuracy: 0.4950 - f1_m: 0.6595 - precision_m: 0.5058 - recall_m: 0.9670\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7072 - accuracy: 0.5002 - f1_m: 0.6612 - precision_m: 0.5066 - recall_m: 0.9763\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7052 - accuracy: 0.5024 - f1_m: 0.6615 - precision_m: 0.5063 - recall_m: 0.9722\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7056 - accuracy: 0.4793 - f1_m: 0.6597 - precision_m: 0.5054 - recall_m: 0.9660\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7015 - accuracy: 0.5043 - f1_m: 0.6601 - precision_m: 0.5045 - recall_m: 0.9693\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7023 - accuracy: 0.4935 - f1_m: 0.6649 - precision_m: 0.5083 - recall_m: 0.9810\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.7000 - accuracy: 0.5091 - f1_m: 0.6654 - precision_m: 0.5076 - recall_m: 0.9825\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.7055 - accuracy: 0.4849 - f1_m: 0.6654 - precision_m: 0.5091 - recall_m: 0.9790\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7006 - accuracy: 0.5043 - f1_m: 0.6650 - precision_m: 0.5081 - recall_m: 0.9821\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.7025 - accuracy: 0.4961 - f1_m: 0.6604 - precision_m: 0.5051 - recall_m: 0.9733\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7008 - accuracy: 0.5028 - f1_m: 0.6616 - precision_m: 0.5056 - recall_m: 0.9723\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7003 - accuracy: 0.4961 - f1_m: 0.6628 - precision_m: 0.5058 - recall_m: 0.9770\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7003 - accuracy: 0.4957 - f1_m: 0.6672 - precision_m: 0.5085 - recall_m: 0.9848\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7044 - accuracy: 0.4983 - f1_m: 0.6623 - precision_m: 0.5063 - recall_m: 0.9828s - loss: 0.7044 - accuracy: 0.4983 - f1_m: 0.6623 - precision_m: 0.5063 - recall_m: 0.98\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7006 - accuracy: 0.5009 - f1_m: 0.6631 - precision_m: 0.5069 - recall_m: 0.9800\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7031 - accuracy: 0.4950 - f1_m: 0.6626 - precision_m: 0.5072 - recall_m: 0.9803\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6997 - accuracy: 0.4998 - f1_m: 0.6649 - precision_m: 0.5068 - recall_m: 0.9822\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7037 - accuracy: 0.4942 - f1_m: 0.6619 - precision_m: 0.5069 - recall_m: 0.9806\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7003 - accuracy: 0.5017 - f1_m: 0.6668 - precision_m: 0.5094 - recall_m: 0.9838\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.7008 - accuracy: 0.5058 - f1_m: 0.6646 - precision_m: 0.5085 - recall_m: 0.9821\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6993 - accuracy: 0.5133 - f1_m: 0.6647 - precision_m: 0.5076 - recall_m: 0.9827\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.7013 - accuracy: 0.4923 - f1_m: 0.6651 - precision_m: 0.5076 - recall_m: 0.9845\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.7004 - accuracy: 0.4946 - f1_m: 0.6653 - precision_m: 0.5084 - recall_m: 0.9800\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6998 - accuracy: 0.4931 - f1_m: 0.6661 - precision_m: 0.5087 - recall_m: 0.9797\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 0.7005 - accuracy: 0.4867 - f1_m: 0.6694 - precision_m: 0.5106 - recall_m: 0.9886\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.6991 - accuracy: 0.5047 - f1_m: 0.6625 - precision_m: 0.5060 - recall_m: 0.9772\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.6982 - accuracy: 0.4985 - f1_m: 0.6602 - precision_m: 0.4970 - recall_m: 1.0000\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "epochs = 30\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "#             for metrics in METRICS:\n",
    "            hparams = {\n",
    "              HP_NUM_UNITS: num_units,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams, epochs, augmentModel=True)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/hparam_tuning\n",
    "# docker run -it -p 8888:8888 -p 6006:6006 \\\n",
    "# tensorflow/tensorflow:nightly-py3-jupyter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 184, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape = train_images.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # create model object\n",
    "    model = keras.Sequential([\n",
    "    #adding first convolutional layer    \n",
    "    keras.layers.Conv2D(\n",
    "        #adding filter \n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        # adding filter size or kernel size\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        #activation function\n",
    "        activation='relu',\n",
    "        input_shape=input_shape),\n",
    "    # adding second convolutional layer \n",
    "    keras.layers.Conv2D(\n",
    "        #adding filter \n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        #adding filter size or kernel size\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        #activation function\n",
    "        activation='relu'\n",
    "    ),\n",
    "    # adding flatten layer    \n",
    "    keras.layers.Flatten(),\n",
    "    # adding dense layer    \n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    # output layer    \n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    #compilation of model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 182, 32)       896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 180, 32)       9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 552960)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                17694752  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 17,705,226\n",
      "Trainable params: 17,705,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#importing random search\n",
    "from kerastuner import RandomSearch\n",
    "\n",
    "#creating randomsearch object\n",
    "tuner = RandomSearch(build_model,\n",
    "                    objective='val_accuracy',\n",
    "                    max_trials = 5)\n",
    "# search best parameter\n",
    "tuner.search(train_images,train_labels,epochs=3,validation_data=(train_images,train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 182, 48)       1344      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 94, 178, 64)       76864     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1070848)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                34267168  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 34,345,706\n",
      "Trainable params: 34,345,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (1070848, 32) and (1076864, 32) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-44bb91bfee43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mget_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \"\"\"\n\u001b[0;32m    390\u001b[0m         \u001b[1;31m# Method only exists in this class for the docstring override.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTuner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_deepcopy_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36mget_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m    281\u001b[0m         \u001b[0mbest_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest_trials\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m    281\u001b[0m         \u001b[0mbest_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest_trials\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmaybe_distribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             model.load_weights(\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_checkpoint_fname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m             )\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2329\u001b[0m     \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_detect_save_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2331\u001b[1;33m       \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2332\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2333\u001b[0m         raise NotImplementedError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1381\u001b[0m         options=options)\n\u001b[0;32m   1382\u001b[0m     base.CheckpointPosition(\n\u001b[1;32m-> 1383\u001b[1;33m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[1;31m# Attached dependencies are not attached to the root, so should be restored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    979\u001b[0m     restore_ops.extend(\n\u001b[0;32m    980\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[1;32m--> 981\u001b[1;33m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[0;32m    982\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[1;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[0;32m    350\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[0;32m    351\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[1;32m--> 352\u001b[1;33m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0m\u001b[0;32m    353\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    337\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    321\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m           \u001b[0mrestore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    114\u001b[0m                                           structured_restored_tensors):\n\u001b[0;32m    115\u001b[0m       restore_ops[saveable.name] = saveable.restore(\n\u001b[1;32m--> 116\u001b[1;33m           restored_tensors, restored_shapes=None)\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    130\u001b[0m       \u001b[0mrestored_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[1;32m--> 132\u001b[1;33m           self.handle_op, self._var_shape, restored_tensor)\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mshape_safe_assign_variable_handle\u001b[1;34m(handle, shape, value, name)\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m   \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m   return gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m    311\u001b[0m       handle, value_tensor, name=name)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \"\"\"\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (1070848, 32) and (1076864, 32) are incompatible"
     ]
    }
   ],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(test_images,test_labels,\n",
    "          epochs=10,\n",
    "          validation_split=0.1,\n",
    "          initial_epoch=3)\n",
    "_, accuracy = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a7e1b17602ce2ea468a951908af7bc23f5fb404bcd43f493b2f049dccd7860b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
